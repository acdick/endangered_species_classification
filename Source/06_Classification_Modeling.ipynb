{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifiers as clf\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle(\"../Data/X_train.pkl\")\n",
    "X_test  = pd.read_pickle(\"../Data/X_test.pkl\")\n",
    "y_train = pd.read_pickle(\"../Data/y_train.pkl\")\n",
    "y_test  = pd.read_pickle(\"../Data/y_test.pkl\")\n",
    "\n",
    "X_train_smote = pd.read_pickle(\"../Data/X_train_smote.pkl\")\n",
    "y_train_smote = pd.read_pickle(\"../Data/y_train_smote.pkl\")\n",
    "\n",
    "X_train_under = pd.read_pickle(\"../Data/X_train_under.pkl\")\n",
    "y_train_under = pd.read_pickle(\"../Data/y_train_under.pkl\")\n",
    "\n",
    "y_labels = pd.read_pickle('../Data/y_labels.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model Hyper Parameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter grid search for all classifiers\n",
    "classifiers = []\n",
    "\n",
    "# dummy classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_dummy_classifier(dict(\n",
    "        strategy=['most_frequent','stratified','uniform'])))\n",
    "\n",
    "# logistic regression\n",
    "classifiers.append(\n",
    "    clf.grid_search_logistic_regression([dict(\n",
    "        C=[1e-2,1e0,1e1,1e2,1e4,1e6,1e12],\n",
    "        penalty=['l1', 'l2'],\n",
    "        fit_intercept=[True, False],\n",
    "        multi_class=['ovr'],\n",
    "        solver=['liblinear']),\n",
    "        dict(\n",
    "        C=[1e-2,1e0,1e1,1e2,1e4,1e6,1e12],\n",
    "        penalty=['l2'],\n",
    "        fit_intercept=[True, False],\n",
    "        multi_class=['multinomial'],\n",
    "        solver=['newton-cg'])]))\n",
    "\n",
    "# multinomial naive bayes classifer\n",
    "classifiers.append(\n",
    "    clf.grid_search_multinomial_nb(dict(\n",
    "        alpha=[0.0,0.2,0.4,0.6,0.8,1.0],\n",
    "        fit_prior=[True,False])))\n",
    "\n",
    "# k nearest neighbors classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_k_neighbors_classifier(dict(\n",
    "        n_neighbors=list(range(3,20,4)),\n",
    "        weights=['uniform', 'distance'],\n",
    "        algorithm=['ball_tree','kd_tree'],\n",
    "        leaf_size=list(range(10,31,10)),\n",
    "        p=[1,2])))\n",
    "\n",
    "# decision tree classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_decision_tree_classifier(dict(\n",
    "        criterion=['gini','entropy'],\n",
    "        max_depth=list(range(1,8,3)),\n",
    "        min_samples_split=list(range(2,6,3)),\n",
    "        min_samples_leaf=list(range(1,5,3)),\n",
    "        max_features=list(range(300,601,300)),\n",
    "        min_impurity_decrease=[0.01,0.03])))\n",
    "\n",
    "# random forest classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_random_forest_classifier(dict(\n",
    "        n_estimators=list(range(100,301,100)),\n",
    "        criterion=['gini','entropy'],\n",
    "        max_depth=list(range(1,8,3)),\n",
    "        min_samples_split=list(range(2,6,3)),\n",
    "        min_samples_leaf=list(range(1,5,3)),\n",
    "        max_features=list(range(300,601,300)),\n",
    "        min_impurity_decrease=[0.01,0.03])))\n",
    "\n",
    "# ada boost classifer\n",
    "classifiers.append(\n",
    "    clf.grid_search_ada_boost_classifier(dict(\n",
    "        n_estimators=list(range(50,501,50)),\n",
    "        learning_rate=[0.1,0.5,1.0,2.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model:  Imbalanced Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1163s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 32.3min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed: 36.8min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed: 38.7min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed: 40.9min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 43.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Decision Tree\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1202s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 202 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 232 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 266 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 338 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 460 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:   13.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Random Forest\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   44.6s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1293 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1397 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 14.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Ada Boost\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balance</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Fit Time</th>\n",
       "      <th>Score Time</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275770</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.020391</td>\n",
       "      <td>0.038792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.534247</td>\n",
       "      <td>0.342899</td>\n",
       "      <td>0.318229</td>\n",
       "      <td>0.323173</td>\n",
       "      <td>0.014031</td>\n",
       "      <td>0.017121</td>\n",
       "      <td>0.031151</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'uniform'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.340868</td>\n",
       "      <td>0.336295</td>\n",
       "      <td>0.327415</td>\n",
       "      <td>0.292747</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.017953</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.544292</td>\n",
       "      <td>0.339577</td>\n",
       "      <td>0.339593</td>\n",
       "      <td>0.339569</td>\n",
       "      <td>0.014031</td>\n",
       "      <td>0.017121</td>\n",
       "      <td>0.031151</td>\n",
       "      <td>[[544, 97, 128], [94, 18, 28], [124, 28, 34]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275770</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.129970</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275770</td>\n",
       "      <td>0.084963</td>\n",
       "      <td>0.045544</td>\n",
       "      <td>0.130507</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275770</td>\n",
       "      <td>0.079071</td>\n",
       "      <td>0.037160</td>\n",
       "      <td>0.116231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275770</td>\n",
       "      <td>0.068594</td>\n",
       "      <td>0.037665</td>\n",
       "      <td>0.106259</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.746119</td>\n",
       "      <td>0.647832</td>\n",
       "      <td>0.492661</td>\n",
       "      <td>0.526445</td>\n",
       "      <td>0.265630</td>\n",
       "      <td>0.037240</td>\n",
       "      <td>0.302870</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743836</td>\n",
       "      <td>0.642274</td>\n",
       "      <td>0.485224</td>\n",
       "      <td>0.517756</td>\n",
       "      <td>0.097978</td>\n",
       "      <td>0.036570</td>\n",
       "      <td>0.134548</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.745890</td>\n",
       "      <td>0.647057</td>\n",
       "      <td>0.492767</td>\n",
       "      <td>0.526391</td>\n",
       "      <td>0.221556</td>\n",
       "      <td>0.034027</td>\n",
       "      <td>0.255584</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743151</td>\n",
       "      <td>0.638072</td>\n",
       "      <td>0.484417</td>\n",
       "      <td>0.516358</td>\n",
       "      <td>0.091158</td>\n",
       "      <td>0.036832</td>\n",
       "      <td>0.127990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 10.0, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.744292</td>\n",
       "      <td>0.619001</td>\n",
       "      <td>0.518454</td>\n",
       "      <td>0.547130</td>\n",
       "      <td>1.842099</td>\n",
       "      <td>0.039481</td>\n",
       "      <td>1.881580</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 10.0, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.745205</td>\n",
       "      <td>0.622738</td>\n",
       "      <td>0.517977</td>\n",
       "      <td>0.547343</td>\n",
       "      <td>0.131990</td>\n",
       "      <td>0.038504</td>\n",
       "      <td>0.170494</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 10.0, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.744521</td>\n",
       "      <td>0.619836</td>\n",
       "      <td>0.518562</td>\n",
       "      <td>0.547415</td>\n",
       "      <td>1.728800</td>\n",
       "      <td>0.031568</td>\n",
       "      <td>1.760368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 10.0, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.744977</td>\n",
       "      <td>0.622220</td>\n",
       "      <td>0.517869</td>\n",
       "      <td>0.547190</td>\n",
       "      <td>0.134426</td>\n",
       "      <td>0.038371</td>\n",
       "      <td>0.172797</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743379</td>\n",
       "      <td>0.615111</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.547573</td>\n",
       "      <td>2.571615</td>\n",
       "      <td>0.033480</td>\n",
       "      <td>2.605095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743379</td>\n",
       "      <td>0.615256</td>\n",
       "      <td>0.519203</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.163744</td>\n",
       "      <td>0.032840</td>\n",
       "      <td>0.196584</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743379</td>\n",
       "      <td>0.615111</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.547573</td>\n",
       "      <td>2.796374</td>\n",
       "      <td>0.032315</td>\n",
       "      <td>2.828689</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743607</td>\n",
       "      <td>0.615690</td>\n",
       "      <td>0.519657</td>\n",
       "      <td>0.547536</td>\n",
       "      <td>0.156304</td>\n",
       "      <td>0.033222</td>\n",
       "      <td>0.189526</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 10000.0, 'fit_intercept': True, 'multi_c...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.742237</td>\n",
       "      <td>0.611903</td>\n",
       "      <td>0.520476</td>\n",
       "      <td>0.547563</td>\n",
       "      <td>0.143763</td>\n",
       "      <td>0.033656</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 10000.0, 'fit_intercept': True, 'multi_c...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743379</td>\n",
       "      <td>0.615120</td>\n",
       "      <td>0.520179</td>\n",
       "      <td>0.547935</td>\n",
       "      <td>0.243438</td>\n",
       "      <td>0.035717</td>\n",
       "      <td>0.279155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 10000.0, 'fit_intercept': False, 'multi_...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.742237</td>\n",
       "      <td>0.611903</td>\n",
       "      <td>0.520476</td>\n",
       "      <td>0.547563</td>\n",
       "      <td>0.150109</td>\n",
       "      <td>0.037584</td>\n",
       "      <td>0.187693</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 10000.0, 'fit_intercept': False, 'multi_...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743379</td>\n",
       "      <td>0.615120</td>\n",
       "      <td>0.520179</td>\n",
       "      <td>0.547935</td>\n",
       "      <td>0.233062</td>\n",
       "      <td>0.034796</td>\n",
       "      <td>0.267859</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.742009</td>\n",
       "      <td>0.611001</td>\n",
       "      <td>0.520368</td>\n",
       "      <td>0.547295</td>\n",
       "      <td>0.122793</td>\n",
       "      <td>0.035594</td>\n",
       "      <td>0.158387</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743379</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.520179</td>\n",
       "      <td>0.547773</td>\n",
       "      <td>0.287278</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.325706</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.742237</td>\n",
       "      <td>0.611849</td>\n",
       "      <td>0.520336</td>\n",
       "      <td>0.547406</td>\n",
       "      <td>0.115437</td>\n",
       "      <td>0.037392</td>\n",
       "      <td>0.152829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743379</td>\n",
       "      <td>0.614785</td>\n",
       "      <td>0.520179</td>\n",
       "      <td>0.547851</td>\n",
       "      <td>0.250478</td>\n",
       "      <td>0.034610</td>\n",
       "      <td>0.285088</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.741781</td>\n",
       "      <td>0.611055</td>\n",
       "      <td>0.519773</td>\n",
       "      <td>0.546786</td>\n",
       "      <td>0.115291</td>\n",
       "      <td>0.036866</td>\n",
       "      <td>0.152157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743379</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.520179</td>\n",
       "      <td>0.547773</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.035868</td>\n",
       "      <td>0.314438</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.739269</td>\n",
       "      <td>0.687501</td>\n",
       "      <td>0.429451</td>\n",
       "      <td>0.446540</td>\n",
       "      <td>2.511457</td>\n",
       "      <td>0.347905</td>\n",
       "      <td>2.859362</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 150}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743836</td>\n",
       "      <td>0.660859</td>\n",
       "      <td>0.450364</td>\n",
       "      <td>0.474468</td>\n",
       "      <td>3.709873</td>\n",
       "      <td>0.490354</td>\n",
       "      <td>4.200227</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.742009</td>\n",
       "      <td>0.644556</td>\n",
       "      <td>0.460661</td>\n",
       "      <td>0.487706</td>\n",
       "      <td>4.934107</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>5.595124</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 250}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743379</td>\n",
       "      <td>0.637078</td>\n",
       "      <td>0.473384</td>\n",
       "      <td>0.502731</td>\n",
       "      <td>6.161559</td>\n",
       "      <td>0.792977</td>\n",
       "      <td>6.954536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.744521</td>\n",
       "      <td>0.624886</td>\n",
       "      <td>0.490248</td>\n",
       "      <td>0.520288</td>\n",
       "      <td>7.388120</td>\n",
       "      <td>0.945272</td>\n",
       "      <td>8.333393</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 350}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.744749</td>\n",
       "      <td>0.622726</td>\n",
       "      <td>0.497186</td>\n",
       "      <td>0.527397</td>\n",
       "      <td>8.625741</td>\n",
       "      <td>1.085753</td>\n",
       "      <td>9.711494</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 400}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743836</td>\n",
       "      <td>0.618717</td>\n",
       "      <td>0.503098</td>\n",
       "      <td>0.532804</td>\n",
       "      <td>9.815921</td>\n",
       "      <td>1.246805</td>\n",
       "      <td>11.062727</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 450}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.744749</td>\n",
       "      <td>0.618458</td>\n",
       "      <td>0.507999</td>\n",
       "      <td>0.537459</td>\n",
       "      <td>11.109138</td>\n",
       "      <td>1.397235</td>\n",
       "      <td>12.506374</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 500}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.746119</td>\n",
       "      <td>0.619879</td>\n",
       "      <td>0.516508</td>\n",
       "      <td>0.545668</td>\n",
       "      <td>12.253359</td>\n",
       "      <td>1.557859</td>\n",
       "      <td>13.811218</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 50}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.735160</td>\n",
       "      <td>0.609658</td>\n",
       "      <td>0.462005</td>\n",
       "      <td>0.486324</td>\n",
       "      <td>1.277203</td>\n",
       "      <td>0.185448</td>\n",
       "      <td>1.462651</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.742466</td>\n",
       "      <td>0.622165</td>\n",
       "      <td>0.479496</td>\n",
       "      <td>0.507940</td>\n",
       "      <td>2.500682</td>\n",
       "      <td>0.338226</td>\n",
       "      <td>2.838908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 150}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.742466</td>\n",
       "      <td>0.616422</td>\n",
       "      <td>0.490969</td>\n",
       "      <td>0.519996</td>\n",
       "      <td>3.702583</td>\n",
       "      <td>0.498116</td>\n",
       "      <td>4.200699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743379</td>\n",
       "      <td>0.616978</td>\n",
       "      <td>0.506686</td>\n",
       "      <td>0.536258</td>\n",
       "      <td>4.948622</td>\n",
       "      <td>0.634683</td>\n",
       "      <td>5.583304</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 250}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.746347</td>\n",
       "      <td>0.618413</td>\n",
       "      <td>0.521197</td>\n",
       "      <td>0.550125</td>\n",
       "      <td>6.194493</td>\n",
       "      <td>0.791826</td>\n",
       "      <td>6.986319</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.744292</td>\n",
       "      <td>0.611878</td>\n",
       "      <td>0.528190</td>\n",
       "      <td>0.554712</td>\n",
       "      <td>7.407741</td>\n",
       "      <td>0.959499</td>\n",
       "      <td>8.367240</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 350}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.743836</td>\n",
       "      <td>0.611018</td>\n",
       "      <td>0.532432</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>8.626899</td>\n",
       "      <td>1.097643</td>\n",
       "      <td>9.724541</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 400}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.742237</td>\n",
       "      <td>0.607704</td>\n",
       "      <td>0.532015</td>\n",
       "      <td>0.557145</td>\n",
       "      <td>9.844184</td>\n",
       "      <td>1.236738</td>\n",
       "      <td>11.080922</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 450}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.741324</td>\n",
       "      <td>0.603350</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>0.553699</td>\n",
       "      <td>11.049847</td>\n",
       "      <td>1.394094</td>\n",
       "      <td>12.443941</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 500}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.739498</td>\n",
       "      <td>0.601306</td>\n",
       "      <td>0.530021</td>\n",
       "      <td>0.553857</td>\n",
       "      <td>12.332721</td>\n",
       "      <td>1.567568</td>\n",
       "      <td>13.900290</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 50}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.597260</td>\n",
       "      <td>0.425184</td>\n",
       "      <td>0.445480</td>\n",
       "      <td>0.412793</td>\n",
       "      <td>1.272417</td>\n",
       "      <td>0.187971</td>\n",
       "      <td>1.460388</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.597260</td>\n",
       "      <td>0.425184</td>\n",
       "      <td>0.445480</td>\n",
       "      <td>0.412793</td>\n",
       "      <td>2.518799</td>\n",
       "      <td>0.346508</td>\n",
       "      <td>2.865307</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 150}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.597260</td>\n",
       "      <td>0.425184</td>\n",
       "      <td>0.445480</td>\n",
       "      <td>0.412793</td>\n",
       "      <td>3.732127</td>\n",
       "      <td>0.502877</td>\n",
       "      <td>4.235005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.597260</td>\n",
       "      <td>0.425184</td>\n",
       "      <td>0.445480</td>\n",
       "      <td>0.412793</td>\n",
       "      <td>4.982032</td>\n",
       "      <td>0.647476</td>\n",
       "      <td>5.629508</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 250}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.597260</td>\n",
       "      <td>0.425184</td>\n",
       "      <td>0.445480</td>\n",
       "      <td>0.412793</td>\n",
       "      <td>6.215006</td>\n",
       "      <td>0.793102</td>\n",
       "      <td>7.008107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.597260</td>\n",
       "      <td>0.425184</td>\n",
       "      <td>0.445480</td>\n",
       "      <td>0.412793</td>\n",
       "      <td>7.445750</td>\n",
       "      <td>0.942069</td>\n",
       "      <td>8.387819</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 350}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.597260</td>\n",
       "      <td>0.425184</td>\n",
       "      <td>0.445480</td>\n",
       "      <td>0.412793</td>\n",
       "      <td>8.591862</td>\n",
       "      <td>1.094602</td>\n",
       "      <td>9.686464</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 400}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.597260</td>\n",
       "      <td>0.425184</td>\n",
       "      <td>0.445480</td>\n",
       "      <td>0.412793</td>\n",
       "      <td>9.804339</td>\n",
       "      <td>1.241890</td>\n",
       "      <td>11.046229</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 450}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.597260</td>\n",
       "      <td>0.425184</td>\n",
       "      <td>0.445480</td>\n",
       "      <td>0.412793</td>\n",
       "      <td>11.090627</td>\n",
       "      <td>1.399839</td>\n",
       "      <td>12.490465</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 2.0, 'n_estimators': 500}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.597260</td>\n",
       "      <td>0.425184</td>\n",
       "      <td>0.445480</td>\n",
       "      <td>0.412793</td>\n",
       "      <td>11.402715</td>\n",
       "      <td>1.234390</td>\n",
       "      <td>12.637105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 350}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.737900</td>\n",
       "      <td>0.604464</td>\n",
       "      <td>0.530898</td>\n",
       "      <td>0.555372</td>\n",
       "      <td>8.626899</td>\n",
       "      <td>1.097643</td>\n",
       "      <td>9.724541</td>\n",
       "      <td>[[698, 28, 43], [69, 53, 18], [111, 18, 57]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Balance           Classifier  \\\n",
       "0    Imbalanced                Dummy   \n",
       "1    Imbalanced                Dummy   \n",
       "2    Imbalanced                Dummy   \n",
       "3    Imbalanced                Dummy   \n",
       "4    Imbalanced  Logistic Regression   \n",
       "5    Imbalanced  Logistic Regression   \n",
       "6    Imbalanced  Logistic Regression   \n",
       "7    Imbalanced  Logistic Regression   \n",
       "8    Imbalanced  Logistic Regression   \n",
       "9    Imbalanced  Logistic Regression   \n",
       "10   Imbalanced  Logistic Regression   \n",
       "11   Imbalanced  Logistic Regression   \n",
       "12   Imbalanced  Logistic Regression   \n",
       "13   Imbalanced  Logistic Regression   \n",
       "14   Imbalanced  Logistic Regression   \n",
       "15   Imbalanced  Logistic Regression   \n",
       "16   Imbalanced  Logistic Regression   \n",
       "17   Imbalanced  Logistic Regression   \n",
       "18   Imbalanced  Logistic Regression   \n",
       "19   Imbalanced  Logistic Regression   \n",
       "20   Imbalanced  Logistic Regression   \n",
       "21   Imbalanced  Logistic Regression   \n",
       "22   Imbalanced  Logistic Regression   \n",
       "23   Imbalanced  Logistic Regression   \n",
       "24   Imbalanced  Logistic Regression   \n",
       "25   Imbalanced  Logistic Regression   \n",
       "26   Imbalanced  Logistic Regression   \n",
       "27   Imbalanced  Logistic Regression   \n",
       "28   Imbalanced  Logistic Regression   \n",
       "29   Imbalanced  Logistic Regression   \n",
       "..          ...                  ...   \n",
       "578  Imbalanced            Ada Boost   \n",
       "579  Imbalanced            Ada Boost   \n",
       "580  Imbalanced            Ada Boost   \n",
       "581  Imbalanced            Ada Boost   \n",
       "582  Imbalanced            Ada Boost   \n",
       "583  Imbalanced            Ada Boost   \n",
       "584  Imbalanced            Ada Boost   \n",
       "585  Imbalanced            Ada Boost   \n",
       "586  Imbalanced            Ada Boost   \n",
       "587  Imbalanced            Ada Boost   \n",
       "588  Imbalanced            Ada Boost   \n",
       "589  Imbalanced            Ada Boost   \n",
       "590  Imbalanced            Ada Boost   \n",
       "591  Imbalanced            Ada Boost   \n",
       "592  Imbalanced            Ada Boost   \n",
       "593  Imbalanced            Ada Boost   \n",
       "594  Imbalanced            Ada Boost   \n",
       "595  Imbalanced            Ada Boost   \n",
       "596  Imbalanced            Ada Boost   \n",
       "597  Imbalanced            Ada Boost   \n",
       "598  Imbalanced            Ada Boost   \n",
       "599  Imbalanced            Ada Boost   \n",
       "600  Imbalanced            Ada Boost   \n",
       "601  Imbalanced            Ada Boost   \n",
       "602  Imbalanced            Ada Boost   \n",
       "603  Imbalanced            Ada Boost   \n",
       "604  Imbalanced            Ada Boost   \n",
       "605  Imbalanced            Ada Boost   \n",
       "606  Imbalanced            Ada Boost   \n",
       "607  Imbalanced            Ada Boost   \n",
       "\n",
       "                                            Parameters  Split  Accuracy  \\\n",
       "0                        {'strategy': 'most_frequent'}  Train  0.705479   \n",
       "1                           {'strategy': 'stratified'}  Train  0.534247   \n",
       "2                              {'strategy': 'uniform'}  Train  0.340868   \n",
       "3                           {'strategy': 'stratified'}   Test  0.544292   \n",
       "4    {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.705479   \n",
       "5    {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.705479   \n",
       "6    {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.705479   \n",
       "7    {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.705479   \n",
       "8    {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.746119   \n",
       "9    {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.743836   \n",
       "10   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.745890   \n",
       "11   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.743151   \n",
       "12   {'C': 10.0, 'fit_intercept': True, 'multi_clas...  Train  0.744292   \n",
       "13   {'C': 10.0, 'fit_intercept': True, 'multi_clas...  Train  0.745205   \n",
       "14   {'C': 10.0, 'fit_intercept': False, 'multi_cla...  Train  0.744521   \n",
       "15   {'C': 10.0, 'fit_intercept': False, 'multi_cla...  Train  0.744977   \n",
       "16   {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.743379   \n",
       "17   {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.743379   \n",
       "18   {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.743379   \n",
       "19   {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.743607   \n",
       "20   {'C': 10000.0, 'fit_intercept': True, 'multi_c...  Train  0.742237   \n",
       "21   {'C': 10000.0, 'fit_intercept': True, 'multi_c...  Train  0.743379   \n",
       "22   {'C': 10000.0, 'fit_intercept': False, 'multi_...  Train  0.742237   \n",
       "23   {'C': 10000.0, 'fit_intercept': False, 'multi_...  Train  0.743379   \n",
       "24   {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.742009   \n",
       "25   {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.743379   \n",
       "26   {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.742237   \n",
       "27   {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.743379   \n",
       "28   {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.741781   \n",
       "29   {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.743379   \n",
       "..                                                 ...    ...       ...   \n",
       "578        {'learning_rate': 0.5, 'n_estimators': 100}  Train  0.739269   \n",
       "579        {'learning_rate': 0.5, 'n_estimators': 150}  Train  0.743836   \n",
       "580        {'learning_rate': 0.5, 'n_estimators': 200}  Train  0.742009   \n",
       "581        {'learning_rate': 0.5, 'n_estimators': 250}  Train  0.743379   \n",
       "582        {'learning_rate': 0.5, 'n_estimators': 300}  Train  0.744521   \n",
       "583        {'learning_rate': 0.5, 'n_estimators': 350}  Train  0.744749   \n",
       "584        {'learning_rate': 0.5, 'n_estimators': 400}  Train  0.743836   \n",
       "585        {'learning_rate': 0.5, 'n_estimators': 450}  Train  0.744749   \n",
       "586        {'learning_rate': 0.5, 'n_estimators': 500}  Train  0.746119   \n",
       "587         {'learning_rate': 1.0, 'n_estimators': 50}  Train  0.735160   \n",
       "588        {'learning_rate': 1.0, 'n_estimators': 100}  Train  0.742466   \n",
       "589        {'learning_rate': 1.0, 'n_estimators': 150}  Train  0.742466   \n",
       "590        {'learning_rate': 1.0, 'n_estimators': 200}  Train  0.743379   \n",
       "591        {'learning_rate': 1.0, 'n_estimators': 250}  Train  0.746347   \n",
       "592        {'learning_rate': 1.0, 'n_estimators': 300}  Train  0.744292   \n",
       "593        {'learning_rate': 1.0, 'n_estimators': 350}  Train  0.743836   \n",
       "594        {'learning_rate': 1.0, 'n_estimators': 400}  Train  0.742237   \n",
       "595        {'learning_rate': 1.0, 'n_estimators': 450}  Train  0.741324   \n",
       "596        {'learning_rate': 1.0, 'n_estimators': 500}  Train  0.739498   \n",
       "597         {'learning_rate': 2.0, 'n_estimators': 50}  Train  0.597260   \n",
       "598        {'learning_rate': 2.0, 'n_estimators': 100}  Train  0.597260   \n",
       "599        {'learning_rate': 2.0, 'n_estimators': 150}  Train  0.597260   \n",
       "600        {'learning_rate': 2.0, 'n_estimators': 200}  Train  0.597260   \n",
       "601        {'learning_rate': 2.0, 'n_estimators': 250}  Train  0.597260   \n",
       "602        {'learning_rate': 2.0, 'n_estimators': 300}  Train  0.597260   \n",
       "603        {'learning_rate': 2.0, 'n_estimators': 350}  Train  0.597260   \n",
       "604        {'learning_rate': 2.0, 'n_estimators': 400}  Train  0.597260   \n",
       "605        {'learning_rate': 2.0, 'n_estimators': 450}  Train  0.597260   \n",
       "606        {'learning_rate': 2.0, 'n_estimators': 500}  Train  0.597260   \n",
       "607        {'learning_rate': 1.0, 'n_estimators': 350}   Test  0.737900   \n",
       "\n",
       "     Precision    Recall  F1 Score   Fit Time  Score Time  Total Time  \\\n",
       "0     0.235160  0.333333  0.275770   0.018400    0.020391    0.038792   \n",
       "1     0.342899  0.318229  0.323173   0.014031    0.017121    0.031151   \n",
       "2     0.336295  0.327415  0.292747   0.008418    0.009534    0.017953   \n",
       "3     0.339577  0.339593  0.339569   0.014031    0.017121    0.031151   \n",
       "4     0.235160  0.333333  0.275770   0.088994    0.040976    0.129970   \n",
       "5     0.235160  0.333333  0.275770   0.084963    0.045544    0.130507   \n",
       "6     0.235160  0.333333  0.275770   0.079071    0.037160    0.116231   \n",
       "7     0.235160  0.333333  0.275770   0.068594    0.037665    0.106259   \n",
       "8     0.647832  0.492661  0.526445   0.265630    0.037240    0.302870   \n",
       "9     0.642274  0.485224  0.517756   0.097978    0.036570    0.134548   \n",
       "10    0.647057  0.492767  0.526391   0.221556    0.034027    0.255584   \n",
       "11    0.638072  0.484417  0.516358   0.091158    0.036832    0.127990   \n",
       "12    0.619001  0.518454  0.547130   1.842099    0.039481    1.881580   \n",
       "13    0.622738  0.517977  0.547343   0.131990    0.038504    0.170494   \n",
       "14    0.619836  0.518562  0.547415   1.728800    0.031568    1.760368   \n",
       "15    0.622220  0.517869  0.547190   0.134426    0.038371    0.172797   \n",
       "16    0.615111  0.519830  0.547573   2.571615    0.033480    2.605095   \n",
       "17    0.615256  0.519203  0.547024   0.163744    0.032840    0.196584   \n",
       "18    0.615111  0.519830  0.547573   2.796374    0.032315    2.828689   \n",
       "19    0.615690  0.519657  0.547536   0.156304    0.033222    0.189526   \n",
       "20    0.611903  0.520476  0.547563   0.143763    0.033656    0.177419   \n",
       "21    0.615120  0.520179  0.547935   0.243438    0.035717    0.279155   \n",
       "22    0.611903  0.520476  0.547563   0.150109    0.037584    0.187693   \n",
       "23    0.615120  0.520179  0.547935   0.233062    0.034796    0.267859   \n",
       "24    0.611001  0.520368  0.547295   0.122793    0.035594    0.158387   \n",
       "25    0.614441  0.520179  0.547773   0.287278    0.038428    0.325706   \n",
       "26    0.611849  0.520336  0.547406   0.115437    0.037392    0.152829   \n",
       "27    0.614785  0.520179  0.547851   0.250478    0.034610    0.285088   \n",
       "28    0.611055  0.519773  0.546786   0.115291    0.036866    0.152157   \n",
       "29    0.614441  0.520179  0.547773   0.278571    0.035868    0.314438   \n",
       "..         ...       ...       ...        ...         ...         ...   \n",
       "578   0.687501  0.429451  0.446540   2.511457    0.347905    2.859362   \n",
       "579   0.660859  0.450364  0.474468   3.709873    0.490354    4.200227   \n",
       "580   0.644556  0.460661  0.487706   4.934107    0.661017    5.595124   \n",
       "581   0.637078  0.473384  0.502731   6.161559    0.792977    6.954536   \n",
       "582   0.624886  0.490248  0.520288   7.388120    0.945272    8.333393   \n",
       "583   0.622726  0.497186  0.527397   8.625741    1.085753    9.711494   \n",
       "584   0.618717  0.503098  0.532804   9.815921    1.246805   11.062727   \n",
       "585   0.618458  0.507999  0.537459  11.109138    1.397235   12.506374   \n",
       "586   0.619879  0.516508  0.545668  12.253359    1.557859   13.811218   \n",
       "587   0.609658  0.462005  0.486324   1.277203    0.185448    1.462651   \n",
       "588   0.622165  0.479496  0.507940   2.500682    0.338226    2.838908   \n",
       "589   0.616422  0.490969  0.519996   3.702583    0.498116    4.200699   \n",
       "590   0.616978  0.506686  0.536258   4.948622    0.634683    5.583304   \n",
       "591   0.618413  0.521197  0.550125   6.194493    0.791826    6.986319   \n",
       "592   0.611878  0.528190  0.554712   7.407741    0.959499    8.367240   \n",
       "593   0.611018  0.532432  0.558333   8.626899    1.097643    9.724541   \n",
       "594   0.607704  0.532015  0.557145   9.844184    1.236738   11.080922   \n",
       "595   0.603350  0.529297  0.553699  11.049847    1.394094   12.443941   \n",
       "596   0.601306  0.530021  0.553857  12.332721    1.567568   13.900290   \n",
       "597   0.425184  0.445480  0.412793   1.272417    0.187971    1.460388   \n",
       "598   0.425184  0.445480  0.412793   2.518799    0.346508    2.865307   \n",
       "599   0.425184  0.445480  0.412793   3.732127    0.502877    4.235005   \n",
       "600   0.425184  0.445480  0.412793   4.982032    0.647476    5.629508   \n",
       "601   0.425184  0.445480  0.412793   6.215006    0.793102    7.008107   \n",
       "602   0.425184  0.445480  0.412793   7.445750    0.942069    8.387819   \n",
       "603   0.425184  0.445480  0.412793   8.591862    1.094602    9.686464   \n",
       "604   0.425184  0.445480  0.412793   9.804339    1.241890   11.046229   \n",
       "605   0.425184  0.445480  0.412793  11.090627    1.399839   12.490465   \n",
       "606   0.425184  0.445480  0.412793  11.402715    1.234390   12.637105   \n",
       "607   0.604464  0.530898  0.555372   8.626899    1.097643    9.724541   \n",
       "\n",
       "                                  Confusion Matrix  \n",
       "0                                              NaN  \n",
       "1                                              NaN  \n",
       "2                                              NaN  \n",
       "3    [[544, 97, 128], [94, 18, 28], [124, 28, 34]]  \n",
       "4                                              NaN  \n",
       "5                                              NaN  \n",
       "6                                              NaN  \n",
       "7                                              NaN  \n",
       "8                                              NaN  \n",
       "9                                              NaN  \n",
       "10                                             NaN  \n",
       "11                                             NaN  \n",
       "12                                             NaN  \n",
       "13                                             NaN  \n",
       "14                                             NaN  \n",
       "15                                             NaN  \n",
       "16                                             NaN  \n",
       "17                                             NaN  \n",
       "18                                             NaN  \n",
       "19                                             NaN  \n",
       "20                                             NaN  \n",
       "21                                             NaN  \n",
       "22                                             NaN  \n",
       "23                                             NaN  \n",
       "24                                             NaN  \n",
       "25                                             NaN  \n",
       "26                                             NaN  \n",
       "27                                             NaN  \n",
       "28                                             NaN  \n",
       "29                                             NaN  \n",
       "..                                             ...  \n",
       "578                                            NaN  \n",
       "579                                            NaN  \n",
       "580                                            NaN  \n",
       "581                                            NaN  \n",
       "582                                            NaN  \n",
       "583                                            NaN  \n",
       "584                                            NaN  \n",
       "585                                            NaN  \n",
       "586                                            NaN  \n",
       "587                                            NaN  \n",
       "588                                            NaN  \n",
       "589                                            NaN  \n",
       "590                                            NaN  \n",
       "591                                            NaN  \n",
       "592                                            NaN  \n",
       "593                                            NaN  \n",
       "594                                            NaN  \n",
       "595                                            NaN  \n",
       "596                                            NaN  \n",
       "597                                            NaN  \n",
       "598                                            NaN  \n",
       "599                                            NaN  \n",
       "600                                            NaN  \n",
       "601                                            NaN  \n",
       "602                                            NaN  \n",
       "603                                            NaN  \n",
       "604                                            NaN  \n",
       "605                                            NaN  \n",
       "606                                            NaN  \n",
       "607   [[698, 28, 43], [69, 53, 18], [111, 18, 57]]  \n",
       "\n",
       "[608 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run imbalanced dataset\n",
    "imbalanced, imbalanced_classifiers = clf.fit_predict_measure(\n",
    "    'Imbalanced', X_train, X_test, y_train, y_test, list(y_labels[0]), classifiers)\n",
    "imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Fit Time</th>\n",
       "      <th>Score Time</th>\n",
       "      <th>Total Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>608.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>608.000000</td>\n",
       "      <td>608.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.716023</td>\n",
       "      <td>0.390587</td>\n",
       "      <td>0.407929</td>\n",
       "      <td>0.378591</td>\n",
       "      <td>1.852117</td>\n",
       "      <td>3.553671</td>\n",
       "      <td>5.405789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.033263</td>\n",
       "      <td>0.180926</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.136263</td>\n",
       "      <td>3.022015</td>\n",
       "      <td>6.868807</td>\n",
       "      <td>6.782086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.340868</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.318229</td>\n",
       "      <td>0.275770</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.017953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275770</td>\n",
       "      <td>0.180338</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>0.691260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275770</td>\n",
       "      <td>0.937331</td>\n",
       "      <td>0.176226</td>\n",
       "      <td>2.019142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.740297</td>\n",
       "      <td>0.605898</td>\n",
       "      <td>0.520476</td>\n",
       "      <td>0.547684</td>\n",
       "      <td>2.283555</td>\n",
       "      <td>0.495381</td>\n",
       "      <td>8.372385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.778082</td>\n",
       "      <td>0.822644</td>\n",
       "      <td>0.616496</td>\n",
       "      <td>0.629215</td>\n",
       "      <td>23.042675</td>\n",
       "      <td>26.114778</td>\n",
       "      <td>26.292144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accuracy   Precision      Recall    F1 Score    Fit Time  Score Time  \\\n",
       "count  608.000000  608.000000  608.000000  608.000000  608.000000  608.000000   \n",
       "mean     0.716023    0.390587    0.407929    0.378591    1.852117    3.553671   \n",
       "std      0.033263    0.180926    0.102600    0.136263    3.022015    6.868807   \n",
       "min      0.340868    0.235160    0.318229    0.275770    0.008418    0.009534   \n",
       "25%      0.705479    0.235160    0.333333    0.275770    0.180338    0.066938   \n",
       "50%      0.705479    0.235160    0.333333    0.275770    0.937331    0.176226   \n",
       "75%      0.740297    0.605898    0.520476    0.547684    2.283555    0.495381   \n",
       "max      0.778082    0.822644    0.616496    0.629215   23.042675   26.114778   \n",
       "\n",
       "       Total Time  \n",
       "count  608.000000  \n",
       "mean     5.405789  \n",
       "std      6.782086  \n",
       "min      0.017953  \n",
       "25%      0.691260  \n",
       "50%      2.019142  \n",
       "75%      8.372385  \n",
       "max     26.292144  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of imbalanced classifiers (test and training sets)\n",
    "imbalanced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balance</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Fit Time</th>\n",
       "      <th>Score Time</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 10, 'n...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.774429</td>\n",
       "      <td>0.668664</td>\n",
       "      <td>0.599096</td>\n",
       "      <td>0.625391</td>\n",
       "      <td>0.241250</td>\n",
       "      <td>18.027862</td>\n",
       "      <td>18.269112</td>\n",
       "      <td>[[701, 25, 43], [68, 54, 18], [78, 15, 93]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.747945</td>\n",
       "      <td>0.628553</td>\n",
       "      <td>0.546944</td>\n",
       "      <td>0.574400</td>\n",
       "      <td>19.679999</td>\n",
       "      <td>0.040780</td>\n",
       "      <td>19.720779</td>\n",
       "      <td>[[702, 34, 33], [61, 56, 23], [116, 9, 61]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.6, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.731507</td>\n",
       "      <td>0.604520</td>\n",
       "      <td>0.547882</td>\n",
       "      <td>0.566858</td>\n",
       "      <td>0.044606</td>\n",
       "      <td>0.031428</td>\n",
       "      <td>0.076034</td>\n",
       "      <td>[[678, 54, 37], [70, 57, 13], [104, 16, 66]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 350}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.737900</td>\n",
       "      <td>0.604464</td>\n",
       "      <td>0.530898</td>\n",
       "      <td>0.555372</td>\n",
       "      <td>8.626899</td>\n",
       "      <td>1.097643</td>\n",
       "      <td>9.724541</td>\n",
       "      <td>[[698, 28, 43], [69, 53, 18], [111, 18, 57]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'max_...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.723288</td>\n",
       "      <td>0.471217</td>\n",
       "      <td>0.385421</td>\n",
       "      <td>0.368374</td>\n",
       "      <td>6.076363</td>\n",
       "      <td>0.181682</td>\n",
       "      <td>6.258045</td>\n",
       "      <td>[[761, 0, 8], [134, 0, 6], [155, 0, 31]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.544292</td>\n",
       "      <td>0.339577</td>\n",
       "      <td>0.339593</td>\n",
       "      <td>0.339569</td>\n",
       "      <td>0.014031</td>\n",
       "      <td>0.017121</td>\n",
       "      <td>0.031151</td>\n",
       "      <td>[[544, 97, 128], [94, 18, 28], [124, 28, 34]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Imbalanced</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 7, 'max_...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.449296</td>\n",
       "      <td>0.363916</td>\n",
       "      <td>0.335269</td>\n",
       "      <td>0.060282</td>\n",
       "      <td>0.039252</td>\n",
       "      <td>0.099534</td>\n",
       "      <td>[[761, 0, 8], [137, 0, 3], [167, 0, 19]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Balance               Classifier  \\\n",
       "180  Imbalanced      K Nearest Neighbors   \n",
       "46   Imbalanced      Logistic Regression   \n",
       "59   Imbalanced  Multinomial Naive Bayes   \n",
       "607  Imbalanced                Ada Boost   \n",
       "566  Imbalanced            Random Forest   \n",
       "3    Imbalanced                    Dummy   \n",
       "277  Imbalanced            Decision Tree   \n",
       "\n",
       "                                            Parameters Split  Accuracy  \\\n",
       "180  {'algorithm': 'ball_tree', 'leaf_size': 10, 'n...  Test  0.774429   \n",
       "46   {'C': 1000000.0, 'fit_intercept': True, 'multi...  Test  0.747945   \n",
       "59                   {'alpha': 0.6, 'fit_prior': True}  Test  0.731507   \n",
       "607        {'learning_rate': 1.0, 'n_estimators': 350}  Test  0.737900   \n",
       "566  {'criterion': 'entropy', 'max_depth': 7, 'max_...  Test  0.723288   \n",
       "3                           {'strategy': 'stratified'}  Test  0.544292   \n",
       "277  {'criterion': 'entropy', 'max_depth': 7, 'max_...  Test  0.712329   \n",
       "\n",
       "     Precision    Recall  F1 Score   Fit Time  Score Time  Total Time  \\\n",
       "180   0.668664  0.599096  0.625391   0.241250   18.027862   18.269112   \n",
       "46    0.628553  0.546944  0.574400  19.679999    0.040780   19.720779   \n",
       "59    0.604520  0.547882  0.566858   0.044606    0.031428    0.076034   \n",
       "607   0.604464  0.530898  0.555372   8.626899    1.097643    9.724541   \n",
       "566   0.471217  0.385421  0.368374   6.076363    0.181682    6.258045   \n",
       "3     0.339577  0.339593  0.339569   0.014031    0.017121    0.031151   \n",
       "277   0.449296  0.363916  0.335269   0.060282    0.039252    0.099534   \n",
       "\n",
       "                                  Confusion Matrix  \n",
       "180    [[701, 25, 43], [68, 54, 18], [78, 15, 93]]  \n",
       "46     [[702, 34, 33], [61, 56, 23], [116, 9, 61]]  \n",
       "59    [[678, 54, 37], [70, 57, 13], [104, 16, 66]]  \n",
       "607   [[698, 28, 43], [69, 53, 18], [111, 18, 57]]  \n",
       "566       [[761, 0, 8], [134, 0, 6], [155, 0, 31]]  \n",
       "3    [[544, 97, 128], [94, 18, 28], [124, 28, 34]]  \n",
       "277       [[761, 0, 8], [137, 0, 3], [167, 0, 19]]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators of imbalanced dataset\n",
    "imbalanced_test = imbalanced[imbalanced['Split'] == 'Test']\n",
    "imbalanced_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model: Classes Balanced with SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   56.0s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed: 22.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 24.3min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 53.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 59.8min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 65.9min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-45a57034b13d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run SMOTE balanced dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m balanced_smote, smote_classifiers = clf.fit_predict_measure(\n\u001b[0;32m----> 3\u001b[0;31m     'SMOTE Oversampled', X_train_smote, X_test, y_train_smote, y_test, list(y_labels[0]), classifiers)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbalanced_smote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ACD/endangered_species_classification/Source/classifiers.py\u001b[0m in \u001b[0;36mfit_predict_measure\u001b[0;34m(balance, X_train, X_test, y_train, y_test, y_labels, classifiers)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# fit training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running jobs: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Grid Search'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# cross-validated training metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run SMOTE balanced dataset\n",
    "balanced_smote, smote_classifiers = clf.fit_predict_measure(\n",
    "    'SMOTE Oversampled', X_train_smote, X_test, y_train_smote, y_test, list(y_labels[0]), classifiers)\n",
    "balanced_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics of SMOTE balanced classifiers (test and training sets)\n",
    "balanced_smote.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best estimators of SMOTE balanced dataset\n",
    "balanced_smote_test = balanced_smote[balanced_smote['Split'] == 'Test']\n",
    "balanced_smote_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model:  Classes Balanced with Near Miss Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run Near Miss balanced dataset\n",
    "balanced_under, under_classifiers = clf.fit_predict_measure(\n",
    "    'Near Miss Undersampled', X_train_under, X_test, y_train_under, y_test, list(y_labels[0]), classifiers)\n",
    "balanced_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics of Near Miss balanced classifiers (test and training sets)\n",
    "balanced_under.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best estimators of Near Miss balanced dataset\n",
    "balanced_under_test = balanced_under[balanced_under['Split'] == 'Test']\n",
    "balanced_under_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced.to_pickle(    '../Data/imbalanced.pkl')\n",
    "balanced_smote.to_pickle('../Data/balanced_smote.pkl')\n",
    "balanced_under.to_pickle('../Data/balanced_under.pkl')\n",
    "\n",
    "pickle.dump(imbalanced_classifiers, open('imbalanced_classifiers.pkl', 'wb'))\n",
    "pickle.dump(smote_classifiers,      open('smote_classifiers.pkl',      'wb'))\n",
    "pickle.dump(under_classifiers,      open('under_classifiers.pkl',      'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
