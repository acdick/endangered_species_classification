{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifiers as clf\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "\n",
    "from imblearn.over_sampling  import SMOTE\n",
    "from imblearn.over_sampling  import SMOTENC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Species Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scientific Name</th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Group</th>\n",
       "      <th>Federal Listing Status</th>\n",
       "      <th>VIP</th>\n",
       "      <th>State</th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accipiter gentilis</td>\n",
       "      <td>Northern goshawk</td>\n",
       "      <td>Birds</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>V</td>\n",
       "      <td>AL</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acipenser fulvescens</td>\n",
       "      <td>Lake sturgeon</td>\n",
       "      <td>Fishes</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>V</td>\n",
       "      <td>AL</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acipenser oxyrinchus (=oxyrhynchus) desotoi</td>\n",
       "      <td>Atlantic sturgeon (Gulf subspecies)</td>\n",
       "      <td>Fishes</td>\n",
       "      <td>Threatened</td>\n",
       "      <td>V</td>\n",
       "      <td>AL</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agarodes alabamensis</td>\n",
       "      <td>[Unnamed] caddisfly</td>\n",
       "      <td>Insects</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>I</td>\n",
       "      <td>AL</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agrimonia incisa</td>\n",
       "      <td>Incised groovebur</td>\n",
       "      <td>Flowering Plants</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>P</td>\n",
       "      <td>AL</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Scientific Name  \\\n",
       "0                           Accipiter gentilis   \n",
       "1                         Acipenser fulvescens   \n",
       "2  Acipenser oxyrinchus (=oxyrhynchus) desotoi   \n",
       "3                         Agarodes alabamensis   \n",
       "4                             Agrimonia incisa   \n",
       "\n",
       "                           Common Name             Group  \\\n",
       "0                     Northern goshawk             Birds   \n",
       "1                        Lake sturgeon            Fishes   \n",
       "2  Atlantic sturgeon (Gulf subspecies)            Fishes   \n",
       "3                  [Unnamed] caddisfly           Insects   \n",
       "4                    Incised groovebur  Flowering Plants   \n",
       "\n",
       "  Federal Listing Status VIP State  Total Land Area (Thousands of Acres)  \\\n",
       "0             Not Listed   V    AL                                 32413   \n",
       "1             Not Listed   V    AL                                 32413   \n",
       "2             Threatened   V    AL                                 32413   \n",
       "3             Not Listed   I    AL                                 32413   \n",
       "4             Not Listed   P    AL                                 32413   \n",
       "\n",
       "    Forest Land Area (Thousands of Acres)  \n",
       "0                                   22877  \n",
       "1                                   22877  \n",
       "2                                   22877  \n",
       "3                                   22877  \n",
       "4                                   22877  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = pd.read_pickle(\"../Data/species.pkl\")\n",
    "species.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Target and Feature Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not Listed', 'Threatened', 'Endangered']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Land Area (Thousands of Acres)  \\\n",
       "0                                 32413   \n",
       "1                                 32413   \n",
       "2                                 32413   \n",
       "3                                 32413   \n",
       "4                                 32413   \n",
       "\n",
       "    Forest Land Area (Thousands of Acres)  \n",
       "0                                   22877  \n",
       "1                                   22877  \n",
       "2                                   22877  \n",
       "3                                   22877  \n",
       "4                                   22877  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create target variables\n",
    "y = species['Federal Listing Status']\n",
    "y_labels = list(y.unique())\n",
    "print(y_labels)\n",
    "\n",
    "# Create target variables\n",
    "X = species.drop(['Federal Listing Status', 'Scientific Name', 'Common Name', 'VIP', 'State', 'Group'], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train Normal</th>\n",
       "      <th>Test Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Listed</th>\n",
       "      <td>6939</td>\n",
       "      <td>1736</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.764758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Endangered</th>\n",
       "      <td>1512</td>\n",
       "      <td>372</td>\n",
       "      <td>0.166575</td>\n",
       "      <td>0.163877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threatened</th>\n",
       "      <td>626</td>\n",
       "      <td>162</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.071366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>9077</td>\n",
       "      <td>2270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Train  Test  Train Normal  Test Normal\n",
       "Not Listed   6939  1736      0.764460     0.764758\n",
       "Endangered   1512   372      0.166575     0.163877\n",
       "Threatened    626   162      0.068966     0.071366\n",
       "Total        9077  2270      1.000000     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# data set statistics\n",
    "data_sets = pd.DataFrame({'Train':        y_train.value_counts(),\n",
    "                          'Test':         y_test.value_counts(),\n",
    "                          'Train Normal': y_train.value_counts() / y_train.count(),\n",
    "                          'Test Normal':  y_test.value_counts()  / y_test.count()})\n",
    "\n",
    "data_sets.loc['Total'] = data_sets.sum().astype(int)\n",
    "data_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7653</th>\n",
       "      <td>30161</td>\n",
       "      <td>18966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>62140</td>\n",
       "      <td>11448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>36809</td>\n",
       "      <td>24768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9817</th>\n",
       "      <td>167188</td>\n",
       "      <td>62425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>99699</td>\n",
       "      <td>32618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total Land Area (Thousands of Acres)  \\\n",
       "7653                                  30161   \n",
       "11291                                 62140   \n",
       "3945                                  36809   \n",
       "9817                                 167188   \n",
       "2185                                  99699   \n",
       "\n",
       "        Forest Land Area (Thousands of Acres)  \n",
       "7653                                    18966  \n",
       "11291                                   11448  \n",
       "3945                                    24768  \n",
       "9817                                    62425  \n",
       "2185                                    32618  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7653</th>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.145247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>0.168454</td>\n",
       "      <td>0.086621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0.099045</td>\n",
       "      <td>0.190491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9817</th>\n",
       "      <td>0.456293</td>\n",
       "      <td>0.484143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>0.271368</td>\n",
       "      <td>0.251706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total Land Area (Thousands of Acres)  \\\n",
       "7653                               0.080829   \n",
       "11291                              0.168454   \n",
       "3945                               0.099045   \n",
       "9817                               0.456293   \n",
       "2185                               0.271368   \n",
       "\n",
       "        Forest Land Area (Thousands of Acres)  \n",
       "7653                                 0.145247  \n",
       "11291                                0.086621  \n",
       "3945                                 0.190491  \n",
       "9817                                 0.484143  \n",
       "2185                                 0.251706  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train[X_train.columns] = scaler.fit_transform(X_train[X_train.columns])\n",
    "X_test[X_test.columns]   = scaler.transform(X_test[X_test.columns])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model Hyper Parameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter grid search for all classifiers\n",
    "classifiers = []\n",
    "\n",
    "# dummy classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_dummy_classifier(dict(\n",
    "        strategy=['most_frequent','stratified'])))\n",
    "\n",
    "# logistic regression\n",
    "classifiers.append(\n",
    "    clf.grid_search_logistic_regression(dict(\n",
    "        C=[1e-2,1e0,1e2,1e6,1e12],\n",
    "        penalty=['l1', 'l2'],\n",
    "        fit_intercept=[True, False],\n",
    "        multi_class=['ovr'],\n",
    "        solver=['liblinear'])))\n",
    "\n",
    "# multinomial naive bayes classifer\n",
    "classifiers.append(\n",
    "    clf.grid_search_multinomial_nb(dict(\n",
    "        alpha=[0.0,1.0],\n",
    "        fit_prior=[True])))\n",
    "\n",
    "# k nearest neighbors classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_k_neighbors_classifier(dict(\n",
    "#        n_neighbors=[5,11],\n",
    "#        weights=['uniform', 'distance'],\n",
    "        algorithm=['ball_tree','kd_tree'],\n",
    "        leaf_size=[100,200])))\n",
    "\n",
    "# decision tree classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_decision_tree_classifier(dict(\n",
    "        criterion=['gini','entropy'],\n",
    "#        max_depth=[6,8],\n",
    "#        min_samples_leaf=[20,50,100],\n",
    "#        max_features=[20,30,40],\n",
    "        min_impurity_decrease=[0.01,0.03,0.05])))\n",
    "\n",
    "# random forest classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_random_forest_classifier(dict(\n",
    "        n_estimators=[100,200,300],\n",
    "#        max_depth=[2,3,4],\n",
    "#        min_samples_leaf=[100,200],\n",
    "#        max_features=[10,20],\n",
    "        min_impurity_decrease=[0.01,0.03,0.05])))\n",
    "\n",
    "# ada boost classifer\n",
    "classifiers.append(\n",
    "    clf.grid_search_ada_boost_classifier(dict(\n",
    "        n_estimators=[100,200,300],\n",
    "        learning_rate=[0.5,1.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1972s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    5.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0772s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1765s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:    0.7s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:    0.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Decision Tree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0706s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Random Forest\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:    9.8s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Ada Boost\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:   31.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   37.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.613749</td>\n",
       "      <td>0.618513</td>\n",
       "      <td>0.616173</td>\n",
       "      <td>0.614045</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.758511</td>\n",
       "      <td>0.593476</td>\n",
       "      <td>0.758511</td>\n",
       "      <td>0.660516</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.733723</td>\n",
       "      <td>0.611280</td>\n",
       "      <td>0.733723</td>\n",
       "      <td>0.660626</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.735485</td>\n",
       "      <td>0.616161</td>\n",
       "      <td>0.735485</td>\n",
       "      <td>0.662427</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.733723</td>\n",
       "      <td>0.611280</td>\n",
       "      <td>0.733723</td>\n",
       "      <td>0.660626</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.735485</td>\n",
       "      <td>0.616161</td>\n",
       "      <td>0.735485</td>\n",
       "      <td>0.662427</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.746696</td>\n",
       "      <td>0.617177</td>\n",
       "      <td>0.746696</td>\n",
       "      <td>0.665667</td>\n",
       "      <td>[[1680, 0, 56], [151, 0, 11], [357, 0, 15]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Data               Classifier  \\\n",
       "0   Baseline                    Dummy   \n",
       "1   Baseline                    Dummy   \n",
       "2   Baseline                    Dummy   \n",
       "3   Baseline      Logistic Regression   \n",
       "4   Baseline      Logistic Regression   \n",
       "5   Baseline      Logistic Regression   \n",
       "6   Baseline      Logistic Regression   \n",
       "7   Baseline      Logistic Regression   \n",
       "8   Baseline      Logistic Regression   \n",
       "9   Baseline      Logistic Regression   \n",
       "10  Baseline      Logistic Regression   \n",
       "11  Baseline      Logistic Regression   \n",
       "12  Baseline      Logistic Regression   \n",
       "13  Baseline      Logistic Regression   \n",
       "14  Baseline      Logistic Regression   \n",
       "15  Baseline      Logistic Regression   \n",
       "16  Baseline      Logistic Regression   \n",
       "17  Baseline      Logistic Regression   \n",
       "18  Baseline      Logistic Regression   \n",
       "19  Baseline      Logistic Regression   \n",
       "20  Baseline      Logistic Regression   \n",
       "21  Baseline      Logistic Regression   \n",
       "22  Baseline      Logistic Regression   \n",
       "23  Baseline      Logistic Regression   \n",
       "24  Baseline  Multinomial Naive Bayes   \n",
       "25  Baseline  Multinomial Naive Bayes   \n",
       "26  Baseline  Multinomial Naive Bayes   \n",
       "27  Baseline      K Nearest Neighbors   \n",
       "28  Baseline      K Nearest Neighbors   \n",
       "29  Baseline      K Nearest Neighbors   \n",
       "30  Baseline      K Nearest Neighbors   \n",
       "31  Baseline      K Nearest Neighbors   \n",
       "32  Baseline            Decision Tree   \n",
       "33  Baseline            Decision Tree   \n",
       "34  Baseline            Decision Tree   \n",
       "35  Baseline            Decision Tree   \n",
       "36  Baseline            Decision Tree   \n",
       "37  Baseline            Decision Tree   \n",
       "38  Baseline            Decision Tree   \n",
       "39  Baseline            Random Forest   \n",
       "40  Baseline            Random Forest   \n",
       "41  Baseline            Random Forest   \n",
       "42  Baseline            Random Forest   \n",
       "43  Baseline            Random Forest   \n",
       "44  Baseline            Random Forest   \n",
       "45  Baseline            Random Forest   \n",
       "46  Baseline            Random Forest   \n",
       "47  Baseline            Random Forest   \n",
       "48  Baseline            Random Forest   \n",
       "49  Baseline                Ada Boost   \n",
       "50  Baseline                Ada Boost   \n",
       "51  Baseline                Ada Boost   \n",
       "52  Baseline                Ada Boost   \n",
       "53  Baseline                Ada Boost   \n",
       "54  Baseline                Ada Boost   \n",
       "55  Baseline                Ada Boost   \n",
       "\n",
       "                                           Parameters  Split  Accuracy  \\\n",
       "0                       {'strategy': 'most_frequent'}  Train  0.764460   \n",
       "1                          {'strategy': 'stratified'}  Train  0.613749   \n",
       "2                       {'strategy': 'most_frequent'}   Test  0.764758   \n",
       "3   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.764460   \n",
       "4   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.764460   \n",
       "5   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.758511   \n",
       "6   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.764460   \n",
       "7   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.764460   \n",
       "8   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.764460   \n",
       "9   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.764460   \n",
       "10  {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.764460   \n",
       "11  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.764460   \n",
       "12  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.764460   \n",
       "13  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.764460   \n",
       "14  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.764460   \n",
       "15  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.764460   \n",
       "16  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.764460   \n",
       "17  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.764460   \n",
       "18  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.764460   \n",
       "19  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.764460   \n",
       "20  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.764460   \n",
       "21  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.764460   \n",
       "22  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.764460   \n",
       "23  {'C': 0.01, 'fit_intercept': True, 'multi_clas...   Test  0.764758   \n",
       "24                  {'alpha': 0.0, 'fit_prior': True}  Train  0.764460   \n",
       "25                  {'alpha': 1.0, 'fit_prior': True}  Train  0.764460   \n",
       "26                  {'alpha': 0.0, 'fit_prior': True}   Test  0.764758   \n",
       "27       {'algorithm': 'ball_tree', 'leaf_size': 100}  Train  0.733723   \n",
       "28       {'algorithm': 'ball_tree', 'leaf_size': 200}  Train  0.735485   \n",
       "29         {'algorithm': 'kd_tree', 'leaf_size': 100}  Train  0.733723   \n",
       "30         {'algorithm': 'kd_tree', 'leaf_size': 200}  Train  0.735485   \n",
       "31       {'algorithm': 'ball_tree', 'leaf_size': 200}   Test  0.746696   \n",
       "32  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.764460   \n",
       "33  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.764460   \n",
       "34  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.764460   \n",
       "35  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.764460   \n",
       "36  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.764460   \n",
       "37  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.764460   \n",
       "38  {'criterion': 'gini', 'min_impurity_decrease':...   Test  0.764758   \n",
       "39  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.764460   \n",
       "40  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.764460   \n",
       "41  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.764460   \n",
       "42  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.764460   \n",
       "43  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.764460   \n",
       "44  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.764460   \n",
       "45  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.764460   \n",
       "46  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.764460   \n",
       "47  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.764460   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...   Test  0.764758   \n",
       "49        {'learning_rate': 0.5, 'n_estimators': 100}  Train  0.764460   \n",
       "50        {'learning_rate': 0.5, 'n_estimators': 200}  Train  0.764460   \n",
       "51        {'learning_rate': 0.5, 'n_estimators': 300}  Train  0.764460   \n",
       "52        {'learning_rate': 1.0, 'n_estimators': 100}  Train  0.764460   \n",
       "53        {'learning_rate': 1.0, 'n_estimators': 200}  Train  0.764460   \n",
       "54        {'learning_rate': 1.0, 'n_estimators': 300}  Train  0.764460   \n",
       "55        {'learning_rate': 0.5, 'n_estimators': 100}   Test  0.764758   \n",
       "\n",
       "    Precision    Recall  F1 Score                             Confusion Matrix  \n",
       "0    0.584399  0.764460  0.662411                                          NaN  \n",
       "1    0.618513  0.616173  0.614045                                          NaN  \n",
       "2    0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  \n",
       "3    0.584399  0.764460  0.662411                                          NaN  \n",
       "4    0.584399  0.764460  0.662411                                          NaN  \n",
       "5    0.593476  0.758511  0.660516                                          NaN  \n",
       "6    0.584399  0.764460  0.662411                                          NaN  \n",
       "7    0.584399  0.764460  0.662411                                          NaN  \n",
       "8    0.584399  0.764460  0.662411                                          NaN  \n",
       "9    0.584399  0.764460  0.662411                                          NaN  \n",
       "10   0.584399  0.764460  0.662411                                          NaN  \n",
       "11   0.584399  0.764460  0.662411                                          NaN  \n",
       "12   0.584399  0.764460  0.662411                                          NaN  \n",
       "13   0.584399  0.764460  0.662411                                          NaN  \n",
       "14   0.584399  0.764460  0.662411                                          NaN  \n",
       "15   0.584399  0.764460  0.662411                                          NaN  \n",
       "16   0.584399  0.764460  0.662411                                          NaN  \n",
       "17   0.584399  0.764460  0.662411                                          NaN  \n",
       "18   0.584399  0.764460  0.662411                                          NaN  \n",
       "19   0.584399  0.764460  0.662411                                          NaN  \n",
       "20   0.584399  0.764460  0.662411                                          NaN  \n",
       "21   0.584399  0.764460  0.662411                                          NaN  \n",
       "22   0.584399  0.764460  0.662411                                          NaN  \n",
       "23   0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  \n",
       "24   0.584399  0.764460  0.662411                                          NaN  \n",
       "25   0.584399  0.764460  0.662411                                          NaN  \n",
       "26   0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  \n",
       "27   0.611280  0.733723  0.660626                                          NaN  \n",
       "28   0.616161  0.735485  0.662427                                          NaN  \n",
       "29   0.611280  0.733723  0.660626                                          NaN  \n",
       "30   0.616161  0.735485  0.662427                                          NaN  \n",
       "31   0.617177  0.746696  0.665667  [[1680, 0, 56], [151, 0, 11], [357, 0, 15]]  \n",
       "32   0.584399  0.764460  0.662411                                          NaN  \n",
       "33   0.584399  0.764460  0.662411                                          NaN  \n",
       "34   0.584399  0.764460  0.662411                                          NaN  \n",
       "35   0.584399  0.764460  0.662411                                          NaN  \n",
       "36   0.584399  0.764460  0.662411                                          NaN  \n",
       "37   0.584399  0.764460  0.662411                                          NaN  \n",
       "38   0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  \n",
       "39   0.584399  0.764460  0.662411                                          NaN  \n",
       "40   0.584399  0.764460  0.662411                                          NaN  \n",
       "41   0.584399  0.764460  0.662411                                          NaN  \n",
       "42   0.584399  0.764460  0.662411                                          NaN  \n",
       "43   0.584399  0.764460  0.662411                                          NaN  \n",
       "44   0.584399  0.764460  0.662411                                          NaN  \n",
       "45   0.584399  0.764460  0.662411                                          NaN  \n",
       "46   0.584399  0.764460  0.662411                                          NaN  \n",
       "47   0.584399  0.764460  0.662411                                          NaN  \n",
       "48   0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  \n",
       "49   0.584399  0.764460  0.662411                                          NaN  \n",
       "50   0.584399  0.764460  0.662411                                          NaN  \n",
       "51   0.584399  0.764460  0.662411                                          NaN  \n",
       "52   0.584399  0.764460  0.662411                                          NaN  \n",
       "53   0.584399  0.764460  0.662411                                          NaN  \n",
       "54   0.584399  0.764460  0.662411                                          NaN  \n",
       "55   0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run baseline dataset\n",
    "baseline = clf.fit_predict_measure('Baseline', X_train, X_test, y_train, y_test, y_labels, classifiers)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.759244</td>\n",
       "      <td>0.587898</td>\n",
       "      <td>0.759288</td>\n",
       "      <td>0.661552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.021367</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.006494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.613749</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.616173</td>\n",
       "      <td>0.614045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.584399</td>\n",
       "      <td>0.764460</td>\n",
       "      <td>0.662411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.618513</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.665667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall   F1 Score\n",
       "count  56.000000  56.000000  56.000000  56.000000\n",
       "mean    0.759244   0.587898   0.759288   0.661552\n",
       "std     0.021367   0.009628   0.021067   0.006494\n",
       "min     0.613749   0.584399   0.616173   0.614045\n",
       "25%     0.764460   0.584399   0.764460   0.662411\n",
       "50%     0.764460   0.584399   0.764460   0.662411\n",
       "75%     0.764460   0.584399   0.764460   0.662411\n",
       "max     0.764758   0.618513   0.764758   0.665667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of baseline classifiers (test and training sets)\n",
    "baseline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.746696</td>\n",
       "      <td>0.617177</td>\n",
       "      <td>0.746696</td>\n",
       "      <td>0.665667</td>\n",
       "      <td>[[1680, 0, 56], [151, 0, 11], [357, 0, 15]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.764758</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>[[1736, 0, 0], [162, 0, 0], [372, 0, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Data               Classifier  \\\n",
       "31  Baseline      K Nearest Neighbors   \n",
       "2   Baseline                    Dummy   \n",
       "23  Baseline      Logistic Regression   \n",
       "26  Baseline  Multinomial Naive Bayes   \n",
       "38  Baseline            Decision Tree   \n",
       "48  Baseline            Random Forest   \n",
       "55  Baseline                Ada Boost   \n",
       "\n",
       "                                           Parameters Split  Accuracy  \\\n",
       "31       {'algorithm': 'ball_tree', 'leaf_size': 200}  Test  0.746696   \n",
       "2                       {'strategy': 'most_frequent'}  Test  0.764758   \n",
       "23  {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Test  0.764758   \n",
       "26                  {'alpha': 0.0, 'fit_prior': True}  Test  0.764758   \n",
       "38  {'criterion': 'gini', 'min_impurity_decrease':...  Test  0.764758   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...  Test  0.764758   \n",
       "55        {'learning_rate': 0.5, 'n_estimators': 100}  Test  0.764758   \n",
       "\n",
       "    Precision    Recall  F1 Score                             Confusion Matrix  \n",
       "31   0.617177  0.746696  0.665667  [[1680, 0, 56], [151, 0, 11], [357, 0, 15]]  \n",
       "2    0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  \n",
       "23   0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  \n",
       "26   0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  \n",
       "38   0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  \n",
       "48   0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  \n",
       "55   0.584854  0.764758  0.662815     [[1736, 0, 0], [162, 0, 0], [372, 0, 0]]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators of baseline dataset\n",
    "baseline_test = baseline[baseline['Split'] == 'Test']\n",
    "baseline_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance with SMOTENC Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train Normal</th>\n",
       "      <th>Test Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Listed</th>\n",
       "      <td>6939</td>\n",
       "      <td>1736</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.764758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Endangered</th>\n",
       "      <td>6939</td>\n",
       "      <td>372</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.163877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threatened</th>\n",
       "      <td>6939</td>\n",
       "      <td>162</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.071366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>20817</td>\n",
       "      <td>2270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Train  Test  Train Normal  Test Normal\n",
       "Not Listed   6939  1736      0.333333     0.764758\n",
       "Endangered   6939   372      0.333333     0.163877\n",
       "Threatened   6939   162      0.333333     0.071366\n",
       "Total       20817  2270      1.000000     1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balance classes with SMOTE oversampling\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "X_train_smote = pd.DataFrame(X_train_smote, columns=X_train.columns)\n",
    "y_train_smote = pd.Series(y_train_smote)\n",
    "\n",
    "# balanced data set statistics\n",
    "smote_sets = pd.DataFrame({'Train':        y_train_smote.value_counts(),\n",
    "                           'Test':         y_test.value_counts(),\n",
    "                           'Train Normal': y_train_smote.value_counts() / y_train_smote.count(),\n",
    "                           'Test Normal':  y_test.value_counts()        / y_test.count()})\n",
    "\n",
    "smote_sets.loc['Total'] = smote_sets.sum().astype(int)\n",
    "smote_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a220f6dd8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7gAAAHhCAYAAABEJxJNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XuUZGV57/FvVfcwF+2hEUcRERE1j0Y4eoQIIlcjIiFGkmgEQgwoi0AwkajxHoGcGOMFjDfAS5QYRFRy8MQYEKMiCA4YxAQvPARQFA0qSDODM8xMd9f5o/Zg29M9XV21q6t77+9nrVldtevdb739dlE/nn1ttFotJEmSJEla6pqDHoAkSZIkSWWwwJUkSZIkVYIFriRJkiSpEixwJUmSJEmVYIErSZIkSaoEC1xJkiRJUiVY4EqSJEmSKsECV5IkSZJUCRa4kiRJkqRKGB70AMowOTnZmphoDXoYkqSKWLZs6G5gzaDHsZSZzZKkMnWazZUocCcmWoyNbRj0MCRJFbFmzcgdgx7DUmc2S5LK1Gk2e4iyJEmSJKkSLHAlSZIkSZVggStJkiRJqoS+nIMbEScAJxRPVwBPAw4F3g2MA1dk5lkR0QTOBZ4KbAJOysxbI2L/6W37MU5JkurCbJYk1UFf9uBm5gWZeWhmHgrcAPw5cD5wHHAgsF9EPB04GliRmc8EXgecXXQxU1tJktQls1mSVAd9PUQ5IvYFngJcDCzPzNsyswV8HvhN2iF5OUBmrgX2jYjVs7SVJEk9MpslSVXW79sEvQE4C1gNrJuyfD2wZ7H8vinLJ7bTdlZDQw1GR1eVMV5JkqrObJYkVVbfCtyIGAWelJlfLrb8jkx5eQQYA1ZNW96kHaAztZ1Vt/faG1o+zCTehH6paNJgYtP4oIchqQbWrBmZu9ESZDarbAuZzatXTNBgYkHeS71rMcS6B4YW5L2GVk7S8rOxpDQYYmLj/A4m7jSb+7kH92Dg3wEyc11EbI6IxwO3A0fQ3nq8G/B84FPFxStu2k7b0k3S4uUf/Pd+dK0+eN/Jzxn0ECRpqTObVaqFzOYGE/zkwlMW7P3Um0cefz6wMAVuiwn+4jOvXJD3UjnedfQ59Ots2X4WuEE7BLc6Bfg47U/6FZl5XUR8HTg8Iq4FGsCJs7Xt4zglSaoLs1mSVGl9K3Az8x3Tnq8F9p+2bJJ2YE5fd5u2kiSpN2azJKnq+noVZUmSJEmSFooFriRJkiSpEixwJUmSJEmVYIErSZIkSaoEC1xJkiRJUiVY4EqSJEmSKsECV5IkSZJUCRa4kiRJkqRKsMCVJEmSJFWCBa4kSZIkqRIscCVJkiRJlWCBK0mSJEmqBAtcSZIkSVIlWOBKkiRJkirBAleSJEmSVAkWuJIkSZKkSrDAlSRJkiRVggWuJEmSJKkSLHAlSZIkSZUw3K+OI+L1wO8AOwDnAl8BLgBawLeA0zJzMiLOAI4CxoHTM/P6iHjCTG37NVZJkurAbJYkVV1f9uBGxKHAAcCzgEOAxwDnAG/KzIOABvCCiHh68fp+wDHA+4sutmnbj3FKklQXZrMkqQ76dYjyEcBNwKXAZ4F/BfahvaUY4DLgOcCBwBWZ2crMHwDDEbFmlraSJKl7ZrMkqfL6dYjyw4HHAr8NPA74F6CZma3i9fXAjsBq4J4p621d3pih7ayGhhqMjq6a9yDXb9rM0LCnIS8VzWaDkS7+zpIkwGxWHyxkNjc2b2F4yM/GUtFsdvcd0I37t6zze2OJaTYbrO7T56NfBe49wM2ZuRnIiHiA9qFQW40AY8C64vH05ZMzLJvVxESLsbEN8x5kY/kQE+OePrRUTE5293eWpPlas2Zk7kZLj9ms0i1kNu+4osX4hJ+NpWJyssV9C/TZaK5s+b2xxHTz3dFpNvdrU8dXgedFRCMidgUeAnyxOP8H4EjgauAa4IiIaEbE7rS3JN8N3DhDW0mS1D2zWZJUeX3Zg5uZ/xoRBwPX0y6iTwO+B3woInYAvgtckpkTEXE18LUp7QBeNb1tP8YpSVJdmM2SpDro222CMvM1Myw+ZIZ2ZwJnTlt2y0xtJUlS98xmSVLVeTa2JEmSJKkSLHAlSZIkSZVggStJkiRJqgQLXEmSJElSJVjgSpIkSZIqwQJXkiRJklQJFriSJEmSpEqwwJUkSZIkVYIFriRJkiSpEixwJUmSJEmVYIErSZIkSaoEC1xJkiRJUiVY4EqSJEmSKsECV5IkSZJUCRa4kiRJkqRKsMCVJEmSJFWCBa4kSZIkqRIscCVJkiRJlWCBK0mSJEmqhOF+dRwRNwL3FU+/B3wAeDcwDlyRmWdFRBM4F3gqsAk4KTNvjYj9p7ft1zglSaoLs1mSVHV9KXAjYgVAZh46Zdk3gd8Hbgc+FxFPB/YAVmTmM4vgPBt4AXD+9LaZ+Y1+jFWSpDowmyVJddCvPbhPBVZFxBXFe5wJLM/M2wAi4vPAbwKPAi4HyMy1EbFvRKyepa0hKklS98xmSVLl9avA3QC8E/gw8ETgMmBsyuvrgT2B1fzyUCmAiWLZuhnazmpoqMHo6Kp5D3L9ps0MDXsa8lLRbDYY6eLvLEkCzGb1wUJmc2PzFoaH/GwsFc1md98B3bh/yzq/N5aYZrPB6j59PvpV4N4C3JqZLeCWiLgPeNiU10doh+qq4vFWTdoBOjJD21lNTLQYG9sw70E2lg8xMT457/U0GJOT3f2dJWm+1qwZmbvR0mM2q3QLmc07rmgxPuFnY6mYnGxx3wJ9NporW35vLDHdfHd0ms392tTxUtrn7BARu9IOy19ExOMjogEcAVwNXAP8VtFuf+CmzFwHbJ6hrSRJ6p7ZLEmqvH7twf0H4IKI+CrQoh2qk8DHgSHaV1+8LiK+DhweEdcCDeDEYv1Tprft0zglSaoLs1mSVHl9KXAzczNw3Awv7T+t3STtwJy+/trpbSVJUvfMZklSHXg2tiRJkiSpEixwJUmSJEmVYIErSZIkSaoEC1xJkiRJUiVY4EqSJEmSKsECV5IkSZJUCRa4kiRJkqRKsMCVJEmSJFWCBa4kSZIkqRIscCVJkiRJlWCBK0mSJEmqBAtcSZIkSVIlWOBKkiRJkirBAleSJEmSVAkWuJIkSZKkSrDAlSRJkiRVggWuJEmSJKkSLHAlSZIkSZVggStJkiRJqoThfnUcEY8AbgAOB8aBC4AW8C3gtMycjIgzgKOK10/PzOsj4gkzte3XOCVJqguzWZJUdX3ZgxsRy4APABuLRecAb8rMg4AG8IKIeDpwCLAfcAzw/tna9mOMkiTVidksSaqDfh2i/E7gfODHxfN9gK8Ujy8DngMcCFyRma3M/AEwHBFrZmkrSZJ6YzZLkiqvo0OUI+KkzPzwlOd/npnvmaXtCcDPMvPzEfH6YnEjM1vF4/XAjsBq4J4pq25dPlPb7RoaajA6uqqTX+VXrN+0maFhT0NeKprNBiNd/J0lqYrMZi0GC5nNjc1bGB7ys7FUNJvdfQd04/4t6/zeWGKazQar+/T52G6BGxHHAr8DHBYRzy4WDwF7ATOGKPBSoBURzwGeBnwMeMSU10eAMWBd8Xj68skZlm3XxESLsbENczXbRmP5EBPjnkK0VExOdvd3lqT5WrNmZO5GA2I2azFZyGzecUWL8Qk/G0vF5GSL+xbos9Fc2fJ7Y4np5ruj02yeaw/u5cD/ADvTPm8H2iF322wrZObBWx9HxJXAKcA7IuLQzLwSOBL4MnAr8PaIeCewG9DMzLsj4sYZ2kqSpDazWZKkWWy3wM3Me4ErgSuLKy+u6GS9GbwK+FBE7AB8F7gkMyci4mrga7TPBT5ttrbzfC9JkirLbJYkaXadnoP7ftq3DPgx7asntoAD5lovMw+d8vSQGV4/Ezhz2rJbZmorSZJ+yWyWJGlbnW7t3Q/Y03veSZK0aJjNkiRN0+nlxm7ll4dASZKkwTObJUmaptM9uLsDd0TErcXzVmbOeRiUJEnqG7NZkqRpOi1wj+3rKCRJ0nyZzZIkTdNpgfvHMyz76zIHIkmS5sVsliRpmk4L3J8UPxvA0+n83F1JktQfZrMkSdN0VOBm5gemPo+Iy/ozHEmS1AmzWZKkbXV6H9xfm/L0UbQvbCFJkgbEbJYkaVudHqI8dSvxA8Cr+zAWSZLUObNZkqRpOj1E+bCI2Bl4PHB7Zt7d32FJkqTtMZslSdpWRxekiIgXAdcCbwDWRsTxfR2VJEnaLrNZkqRtdXrFxVcC+2Tm0cD/Bl7RvyFJkqQOmM2SJE3TaYE7mZn3A2Tmetrn+kiSpMExmyVJmqbTi0zdFhFnA1cBBwG39W9IkiSpA2azJEnTdLoH94PAz4HDgROB9/VtRJIkqRNmsyRJ03Ra4J4DXJqZLwd+o3guSZIGx2yWJGmaTgvc8cz8DkBm3g5M9m9IkiSpA2azJEnTdHoO7h0R8bfA14BnAD/q35AkSVIHzGZJkqbpdA/uicBPgd8Cfga8tG8jkiRJnTCbJUmapqM9uJn5APD3nXYaEUPAh4AAJmiHcAO4AGgB3wJOy8zJiDgDOAoYB07PzOsj4gkzte30/SVJqjqzWZKkbXW6B3e+ng+Qmc8C3kz7whfnAG/KzINoB+oLIuLpwCHAfsAxwPuL9bdp26dxSpJUF2azJKny+lLgZuZngJOLp48FfgLsA3ylWHYZ8BzgQOCKzGxl5g+A4YhYM0tbSZLUJbNZklQHnV5kat4yczwi/hH4XeCFwG9nZqt4eT2wI7AauGfKaluXN2ZoO6uhoQajo6vmPcb1mzYzNNyvndgqW7PZYKSLv7Mkqc1sVtkWMpsbm7cwPORnY6loNrv7DujG/VvW+b2xxDSbDVb36fPRtwIXIDP/OCJeC1wHrJzy0ggwBqwrHk9fPjnDsllNTLQYG9sw7/E1lg8xMe7pQ0vF5GR3f2dJmq81a0bmbrREmc0q00Jm844rWoxP+NlYKiYnW9y3QJ+N5sqW3xtLTDffHZ1mc182dUTEH0XE64unG2iH4n9ExKHFsiOBq4FrgCMiohkRuwPNzLwbuHGGtpIkqUtmsySpDvq1B/f/Ah+NiKuAZcDpwHeBD0XEDsXjSzJzIiKupn0PvyZwWrH+q6a37dM4JUmqC7NZklR5fSlwM/MXwB/M8NIhM7Q9Ezhz2rJbZmorSZK6YzZLkurAs7ElSZIkSZVggStJkiRJqgQLXEmSJElSJVjgSpIkSZIqwQJXkiRJklQJFriSJEmSpEqwwJUkSZIkVYIFriRJkiSpEixwJUmSJEmVYIErSZIkSaoEC1xJkiRJUiVY4EqSJEmSKsECV5IkSZJUCRa4kiRJkqRKsMCVJEmSJFWCBa4kSZIkqRIscCVJkiRJlWCBK0mSJEmqBAtcSZIkSVIlWOBKkiRJkiphuOwOI2IZ8BFgD2A58DfAd4ALgBbwLeC0zJyMiDOAo4Bx4PTMvD4injBT27LHKUlSXZjNkqS66Mce3OOBezLzIOBI4H3AOcCbimUN4AUR8XTgEGA/4Bjg/cX627TtwxglSaoTs1mSVAul78EFPg1cMuX5OLAP8JXi+WXAc4EErsjMFvCDiBiOiDWztL10e284NNRgdHTVvAe6ftNmhoY9SnupaDYbjHTxd5Ykmc3qj4XM5sbmLQwP+dlYKprN7r4DunH/lnV+bywxzWaD1X36fJRe4Gbm/QARMUI7TN8EvLMIS4D1wI7AauCeKatuXd6Yoe12TUy0GBvbMO+xNpYPMTHuEVZLxeRkd39nSZqvNWtGBj2EUpnN6peFzOYdV7QYn/CzsVRMTra4b4E+G82VLb83lphuvjs6zea+bOqIiMcAXwb+KTMvAqZ+4kaAMWBd8Xj68pnaSpKkHpjNkqQ6KL3AjYhHAlcAr83MjxSLb4yIQ4vHRwJXA9cAR0REMyJ2B5qZefcsbSVJUpfMZklSXfTjHNw3ADsBfxURf1UsewXwnojYAfgucElmTkTE1cDXaBfapxVtXwV8aGrbPoxRkqQ6MZslSbXQj3NwX0E7NKc7ZIa2ZwJnTlt2y0xtJUlSd8xmSVJdeLkxSZIkSVIlWOBKkiRJkirBAleSJEmSVAkWuJIkSZKkSrDAlSRJkiRVggWuJEmSJKkSLHAlSZIkSZVggStJkiRJqoThQQ9AWoxWr5igwcSgh6EOtRhi3QNDgx6GJEmSBswCV5pBgwl+cuEpgx6GOvTI488HLHAlSZLqzkOUJUmSJEmVYIErSZIkSaoEC1xJkiRJUiVY4EqSJEmSKsECV5IkSZJUCRa4kiRJkqRKsMCVJEmSJFWCBa4kSZIkqRIscCVJkiRJlTDcr44jYj/gbZl5aEQ8AbgAaAHfAk7LzMmIOAM4ChgHTs/M62dr269xSpJUF2azJKnq+rIHNyJeA3wYWFEsOgd4U2YeBDSAF0TE04FDgP2AY4D3z9a2H2OUJKlOzGZJUh30aw/ubcDvAf9UPN8H+Erx+DLguUACV2RmC/hBRAxHxJpZ2l66vTcbGmowOrpq3oNcv2kzQ8Mepb1UNJsNRrr4O3ejsXkLw0N+NpaKZrO77wCpZsxmlc5s1mwWMpvv37LO740lptlssLpPn4++FLiZ+c8RsceURY0iLAHWAzsCq4F7prTZunymtts1MdFibGzDvMfZWD7ExLhHWC0Vk5Pd/Z27seOKFuMTfjaWisnJFvct0GdD9bBmzcigh1A6s1n9YDZrNguZzc2VLb83lphuvjs6zeaF2tQx9RM3AowB64rH05fP1FaSJJXLbJYkVc5CFbg3RsShxeMjgauBa4AjIqIZEbsDzcy8e5a2kiSpXGazJKly+nYV5WleBXwoInYAvgtckpkTEXE18DXahfZps7VdoDFKklQnZrMkqXL6VuBm5veB/YvHt9C+KuP0NmcCZ05bNmNbSZLUG7NZklR1Xm5MkiRJklQJFriSJEmSpEqwwJUkSZIkVYIFriRJkiSpEixwJUmSJEmVsFC3CZKkShhaOUmLiUEPQ/PQYIiJjW7PlSSpDixwJWkeWkzwF5955aCHoXl419Hn4AFLkiTVg4kvSZIkSaoEC1xJkiRJUiVY4EqSJEmSKsECV5IkSZJUCRa4kiRJkqRKsMCVJEmSJFWCBa4kSZIkqRIscCVJkiRJlWCBK0mSJEmqBAtcSZIkSVIlWOBKkiRJkirBAleSJEmSVAnDgx7ATCKiCZwLPBXYBJyUmbcOdlSSJNWX2SxJWgoW6x7co4EVmflM4HXA2QMejyRJdWc2S5IWvcVa4B4IXA6QmWuBfQc7HEmSas9sliQteo1WqzXoMWwjIj4M/HNmXlY8/wGwZ2aOz7LKz4A7Fmp8kqTKeyywZtCDWEzMZknSgHWUzYvyHFxgHTAy5XlzOwEK/k+IJEn9ZjZLkha9xXqI8jXAbwFExP7ATYMdjiRJtWc2S5IWvcW6B/dS4PCIuBZoACcOeDySJNWd2SxJWvQW5Tm4kiRJkiTN12I9RFmSJEmSpHmxwJUkSZIkVcJiPQe38iLiUOAzwN6Z+cNi2d8BN2fmBbOs8zDgeZl50bTlVwKnZObNU5Y9D9g9Mz84S1+/C1yXmT/uYKzPA47JzBPm/s3UjeLz8CngO1MW/ywzX9TBumtp/32+35/RzV9E3JWZuwx6HFUREWcD+wC7AKuA24GnAF/MzGNKfJ+XZ+b7yupvSr+nALtk5pll9y2VyWzWVGaztsdsXrwscAdrM/DRiDg8Mzs5Gfp/Ab8DXDRXw8y8fI4mrwBOAeYMUS2YL5X5hajqyMxXAUTECcCTMvN1xf94nVLyW70JKD1EpSXGbNZUZrNmZDYvXha4g/Ul2oeJn8a0D25EvAo4BhgHrsrM1wJvBJ4aESfPtvV3yvonAE8CzqS99XFHYCXwGuAhwNOAj0XEgcCfAMcBLeDizHxPRDwZ+Ajwi+LfvSX8vpqnYg/AN4G9gNXAizLzjoh4C/A84IfAw4u2uwHnASuAnYG/zszPRMR/AV+h/T9hLeAFtO9n+X5gX+Au4HHA84EJ4INFHw8AJwNDwGeBe4B/Ay4D3kP7Kqr3AC8F7i/WewpwG7C8T1OiX/XEiLgMeATw2cw8s/jM/AzYCTgKOBd4Iu3vmjdl5pUR8ULa3zuNop8X0v4eeFhEnEv7f7LPn2G9bT5LmXlfRLwVOLhoe05mfrr4bnk38HPan6u1fZ4LqSxms7bLbNYczOYB8xzcwTsV+IuIeOLWBRGxN/AHwAHFvydGxG8Db6G9JXG7ATrN42kfOvF82kG5KjM/R/uL+SXAE4AXAwcW/46OiAD+D/DmzHwOcG1vv6I69OyIuHLKv78sll9f/B2+ABwbEXvR/sL6Ddp/w5Gi3ZOAszPzcODltL8koR2+n8jMQ4AfAUfS3tuwc2Y+A3gZ8Jii7TuB92TmYcXjvyuW7wI8NzPfDnwIOC0zD6Udqq8p+lyRmfsDr6d9qI76bwVwNHAQ7b/5VhcVn5mXAndn5sG0/+fp/cXrvwYcVfwNEzgiM98C/Dwz/xQ4aZb1tvksRcSRwOMy81nAYcAbI2IUeBdwbPF5/F5/fn2pb8xmbWU2a77M5gFzD+6AZeY9EXE6cAFwTbH4ScDazNwCEBFX0976dl0X/X87It4PfAJYRnvr3lR7AY8Fvlg834l2sD4FuL5Ydg3w5Pm+t+Ztm8OgIuIo4Mbi6Q9ph9lTgP/IzElgXUTcVLz+P8CbIuJltLfgLZvS1dQ+VgB7AF8DyMyfRcTWc8T2Bt4QEa+lvQVxc7H8e5m59fGTgXPb/6/FMuAWpnxeMvMHEfHDbidB8/KtzNwEEBHjU5Zn8XNv4KCI2K94PhwROwM/Bf4xIu6n/X3ztWn9zrYebPtZ2h3Yp9g6De3PxGOBR2fmLcWya2h/r0hLgtmsKcxmzZfZPGDuwV0EMvOztD/0JxSLbgb2i4jhiGjQ3iJ4CzDJPP9mxRbnkcw8Cvhj4L3FS1v7SuDbwGHFFqMLgJuKMTyzaPsb3fxeKs30c8ASeEZENCPiIcCvF8v/D/CxzPwj4Mv88hCXmfr4FsXfNyJ2or3VENp/99cWn4U/AS4plk9Oe/+XFG1eA3yOKZ+XiNgVePS8f0t1Y7bzA7f+vW6mvVX3UNpb8j9N+9DKs2gfZnkSsJFfflYa21lv66GQ09/zZuDLRdtn0z7s8nbgruJwSvA7REuQ2aw5mM2ajdk8YO7BXTxOB34TIDNviohP0d6y0gS+SvuqjrsCe0fE6Zn599PWvyQiHigeX0n7SxLgv4EzIuIltLf4vblYfi3wMeC5tLcQfzUiltPe0vcj4E+BTxaH4vyM9jkf6q9nT9nSttXK6Y0y85sR8Wng67QvRPLT4qVPA++JiLuYcv7PLD5H+xCWa2mf57MB2AK8GjgvIlYU7/2KGdY9lfY5YkPF85dl5i0RcWBEXAfcAdw952+rhfAB4EMR8RXahzCdS/scr2uAb/DLc/h2Ldp/JyIupH1o3K+sl5mTxZ6B6T4LHFrszXoocGlmro+I42lviV4PrMdzBbU0mc0ym1U2s7nPGq1WJxcIlFQlEfEk4GmZeXFxeMu3gcduPaRGkiQtLLNZKocFrlRDxeFTFwGPpH0lxvdl5j8OdlSSJNWX2SyVwwJXkiRJklQJXmRKkiRJklQJFriSJEmSpEqwwJUkSZIkVYK3CZI6FBF7AP9F+xLuW30pM/+6g3VPAXbJzDN7eP8LgIsz8/Ipy84E7srM86cs2wV4c2b+6Sz97A3slJlXRcTFtO+bt3mmth2MaSVwHu1L2beA+4BTM/OeiPhd4LrM/PEs6z4MeF5mXtTNe0uSJEnTWeBK8/Od4qbZi1Zm3kX7Xomz+X3a99e7KjOP6fHtTqRdYJ8AEBGn076f4yuKf6fQvh/gTP4X8Du0rxgpSZIk9cwCVypBRLwVOJj2Yf/nZOanI+JA4N3Az4EJYG3R9s+A42jv8bw4M99T7J3dufj3fOBtwGOK55dl5l/NYyx7FP3uHxFvAZ5djOsTtG84fwKwOSK+AXwKeBJwPrAJ2AN4FHBCZn4jIl4GvLz4HTYDn8zMC6a83R3ASRFxDfAV4L1AIyKOAp5G+6bzBwJnAfsCI8B3M/NE4I3AUyPiZOCAYsyXR8TzgGMy84RiXh4PrADemZmf7HQeJEmSVD+egyvNz69HxJVT/j06Io4EHpeZzwIOA94YEaPAu4BjM/Nw4HsAEfHrwIuBA4t/R0dEFH1/KTMPoF0Ers3MI4o2p/Yw3pfQLqYPBjZm5o+AC2gX4ddPa3tH8Z7vBU6OiIcDrwWeBTwXeMj0zjPzc8DfAC8rfscvAk8uln+zeP8VwL3FPBwA7B8RjwbeUvzOH5xp4BExQns+fw84kvY9ASVJkqRZuQdXmp9tDlGOiD8E9omIK4tFy4DHAo/OzFuKZdcATwD2Kl77YrF8p2I5QBY/fw78RkQcBqwDlvcw3mOAtwK7AJfN0fbG4ucPaRe1T6D9+24AiIhrp68QEc8EvpiZ/zcihoA/ol1A7zOl2UbgERHxCeB+4KG052g2DYDMXB8RLwc+CKwGLpxj/JIkSao59+BKvbsZ+HJR+D6b9mG/twN3RcSTiza/UfxM4NvAYUX7C4Cbitcmi58nAGOZ+YfA2cCqiGjMd1ARsRx4EXBsMa4TIuKxxfvM9N9+a9rzW4EnRcTKiGgCz5hhnWOBvwTIzAnaF+HaNOX3adLe+/qYzDwWeAOwknYRO3UcD9A+NBrg6cX4HwXsk5m/CxwFvD0i3CgnSZKkWfk/i1LvPgscGhFX0947eWmx9/F44B8jYj2wnvZhuv8ZEV8EvloUoNcDP5rW3xeBiyPiIOAXwH/TvkrxbF4fEScVj9fTvvATmbkpIn5O+1Dhe4ErgB8ANwDviIjvbu+Xysy7I+JtwNW09yqvBLZMa/ZG4H0R8c1irL+gfbgywLXAx2hfSOqvImIt7eL39uL3uQ3Yu7gw1YeBjxR7w7fu9b4L2CUibqS95/edmTm+vTFLkiSp3hqt1vSdNpIExd7S12bmW4rnVwFvysyrBjsySZIkaWbuwZU0o8wcj4iHFFdb3gxcR3tvriRJkrQouQdXkiRJklQJXmRKkiRJklQJFriSJEmSpEqwwJUkSZIkVYIFriRJkiSpEixwJUkabLNbAAAgAElEQVSSJEmVYIErSZIkSaoEC1xJkiRJUiVY4EqSJEmSKsECV5IkSZJUCcODHkAZJicnWxMTrVL6GhpqUFZfVeY8zc056ozz1BnnaW5lztGyZUN3A2tK6aymzOaF5zzNzTnqjPPUGedpboPI5koUuBMTLcbGNpTS1+joqtL6qjLnaW7OUWecp844T3Mrc47WrBm5o5SOasxsXnjO09yco844T51xnuY2iGz2EGVJkiRJUiVY4EqSJEmSKsECV5IkSZJUCRa4kiRJkqRKsMCVJC1pq0aWsXl4iB+ve4DNw0OsGlk26CFJklRrg8zmgV5FOSL2A96WmYdOW/584M3AOPCRzPzQAIYnSVrkVo0s4/Z7NnHqhTdw570b2W2nlZx3/D7sufNyNqzfMujhLUlmsySpF4PO5oHtwY2I1wAfBlZMW74MeBfwXOAQ4OSI2GXhRyhJWuzGNk4+GKAAd967kVMvvIGxjZMDHtnSZDZLkno16Gwe5B7c24DfA/5p2vInA7dm5r0AEfFV4CDg07N1NDTUYHR0VSmDGhpqltZXlTlPc3OOOuM8dcZ5mtmP1z3wYIBudee9GxmfbPEI56sbZvMS5jzNzTnqjPPUGedpZoPO5lIK3IgYAR4G/CwzO7qTb2b+c0TsMcNLq4H7pjxfD+y4vb68mfzCc57m5hx1xnnqjPM0s+HhIXbbaeWvBOluO61kuNnoab7WrBkpY3gDZTbXj/M0N+eoM85TZ5ynmQ06m3s6RDkiXhIRa4FvABcBX4+Ir0bEcT10uw6YOvoRYKyH/iRJFTW6ssl5x+/DbjutBHjwPJ/RlfW9hqLZLEkapEFnc9d7cCPiAuAa4HmZOTZl+Y7AcRHxT5n5R110/V3giRHxMOB+4GDgnd2OU5JUXRvWb2HPnZfzyZP3Z3yyxXCzwejKZm0vMGU2S5IGbdDZ3Mshyqdk5gPTF2bmfcB5EfHR+XRWbFl+aGZ+MCJeCXye9h7mj2Tmj3oYpySpwjas38IOwCOKQ8U2rJ8Y9JAGyWyWJA3cILO50Wq1euogIh4F7ET7tgGvBd6bmd8sYWwd27JlouV5PgvLeZqbc9QZ56kzztPcypyjNWtGbgD2LaWzATCb68l5mptz1BnnqTPO09wGkc1lHAj9MeCRwN8CX6B9GwFJkjQ4ZrMkqZbKKHCHgauA0cy8GBgqoU9JktQ9s1mSVEtlFLg7AOcAV0XEYQz23rqSJMlsliTVVBkF7glAAn8HrAGOL6FPSZLUvRMwmyVJNVRGgXs7sBl4I/BT2vfKkyRJg2M2S5JqqYwC9wPA7sBzad/4/WMl9ClJkrpnNkuSaqmMAvfxmflmYGNmfhbYsYQ+JUlS98xmSVItlXIV5Yh4OEBEjACTJfQpSZK6ZzZLkmqpjKsqvhG4BngUsBZ4RQl9SpKk7pnNkqRaKmMP7mMyM4DHA3tl5r+X0KckSeqe2SxJqqUy9uCeDHw8M39WQl+SJKl3ZrMkqZbKKHCXR8SNtO+31wJamXlcCf1KkqTumM2SpFoqo8B9bQl9SJKk8pjNkqRaKuMc3NXAb2bmV4DXAytK6FOSJHXPbJYk1VIZe3DPAp5XPH4xcBnw+RL6lSRJ3TGbJUm1VMYe3C2Z+VOAzLwPmCihT0mS1D2zWZJUS2Xswb0+Ii4CvgY8A7ixhD4lSVL3zGZJUi2VUeD+OfACIIBPAd5rT5KkwTKbJUm11PMhypnZyszPAJ8GDgW+32ufkiSpe2azJKmuei5wI+K3IuLfaB/+dDfwtJ5HJUmSumY2S5LqqutDlCPiVcAJwH8CZwPNzHxrSeOSJEnzZDZLkuqulz24rwa+ALwtM78ITJYzJEmS1CWzWZJUa70UuHsA/wG8OyLWAo+JiB1LGZUkSerGHpjNkqQa67rAzcxNmXlRZj4bOB74HPCfEXFJaaOTJEkdM5slSXXX80WmADLz1sx8HfB44ONl9ClJkrpnNkuS6qiM++A+KDMngEvL7FOSJHXPbJYk1Ukpe3AlSZIkSRq0rgvciLi8+HlGecORJEndMpslSXXXyyHKqyPi08BBERFTX8jM47a3YkQ0gXOBpwKbgJMy89Ypr78aOJb27Q3+NjM9tEqSpLmZzZKkWuulwD0S2Bt4AnA+0JjHukcDKzLzmRGxP+2b0b8AICJGgT8v+n0I8E08d0iSpE6YzZKkWuu6wM3M+4CvRsQzgMOBpwC3ZOb/62D1A4HLi37WRsS+U177BXAH7QB9CB3cpH5oqMHo6Kp5/gaz9dUsra8qc57m5hx1xnnqjPM0N+fIbK4752luzlFnnKfOOE9zG8QclXEV5b8Gfg24GvjjiDg4M181xzqrgfumPJ+IiOHMHC+e/xD4DjAEvHWuAUxMtBgb2zD/kc9gdHRVaX1VmfM0N+eoM85TZ5ynuZU5R2vWjJTSzwCZzTXkPM3NOeqM89QZ52lug8jmMq6ifHBm/n5m/j3w+7S3AM9lHTB1hM0pAXok8CjgccDuwNHFlmhJktQZs1mSVEtlFLjLigtTQPtcn1YH61wD/BZAcZ7PTVNeuxfYCGzKzAeAMWC0hHFKklQXZrMkqZbKOET5k8A1EbEW2A+4uIN1LgUOj4hraQfviRHxSuDWzPyXiHgOsDYiJoGvAl8oYZySJNWF2SxJqqVGq9XJRt3ti4i9gCcBN2fmt3rucJ62bJloeZ7PwnKe5uYcdcZ56ozzNLeSz/O5Adh3zoaLmNlcP87T3JyjzjhPnXGe5jaIbC5jDy5FcC54eEqSpJmZzZKkOirjHFxJkiRJkgau1AJ3ygUtJEnSImA2S5LqpOdDlCPiRbTvibcceEdEvD0z39nzyCRJUlfMZklSXZWxVffVtK+keDzwGOD5JfQpSZK6ZzZLkmqpjAL3geLn+szcxK/eJF6SJC08s1mSVEtlFLjfA/4D+EhEnAFcV0KfkiSpe2azJKmWei5wM/MEYO/M/FfgA5l5as+jkiRJXTObJUl11fVFpiLio0BryvMHf2bmS3sfmiRJmg+zWZJUd73swb0Y+CTwMOBm4B+A/wJWlDAuSZI0f2azJKnWut6Dm5mfB4iIV2Xm24vF10TEF0oZmSRJmhezWZJUdz3fBxd4aEQ8G/g6cACwQwl9SpKk7pnNkqRaKuMqyi8FTqV9hcaTgReX0KckSeqe2SxJqqWe9+Bm5s3Ai0oYiyRJKoHZLEmqq54L3Ih4A/AaYAPQAFqZuWuv/UqSpO6YzZKkuirjHNw/AHbNzA0l9CVJknpnNkuSaqmMc3C/D2wsoR9JklSO72M2S5JqqIw9uDsAN0XETcXzVmYeV0K/kiSpO2azJKmWyihw31ZCH5IkqTxmsySplso4RPkmYFfgscAetO+3J0mSBsdsliTVUhl7cC8BbgH2Bh6gfcVGSZI0OGazJKmWytiDS2aeAiRwOLBTGX1KkqTumc2SpDoqpcCNiBXAQ4AW8NAy+pQkSd0zmyVJdVRGgft+4HTgCuCHwM0l9ClJkrpnNkuSaqnnc3Az85+3Po6IT2fmul77lCRJ3TObJUl11XOBGxEvAoaA5cDbI+IdmfnOnkcmSZK6YjZLkuqqjEOUXw18ATge2B14fgl9SpKk7pnNkqRaKuM2QQ8UP9dn5qaIGJlrhYhoAucCTwU2ASdl5q1TXj8SOKN4+g3gtMxslTBWSZLqwGyWJNVSGXtwvwf8B/CRiDgDuK6DdY4GVmTmM4HXAWdvfaEI4XcAv52Z+wPfBx5ewjglSaoLs1mSVEs9F7iZeQKwd2b+K/CBzDy1g9UOBC4v1l8L7DvltQOAm4CzI+Jq4CeZ+bNexylJUl2YzZKkuirjIlMfBVoRsfU5mfnSOVZbDdw35flERAxn5jjtLcKHAU8D7geujoivZeYts3U2NNRgdHRVL7/GlL6apfVVZc7T3JyjzjhPnXGe5uYc/ZLZXE/O09yco844T51xnuY2iDkq4xzci4ufDeDpwK4drLMOmHo+ULMIUIB7gK9n5l0AEXEV7UCdNUQnJlqMjW2Y77hnNDq6qrS+qsx5mptz1BnnqTPO09zKnKM1a+Y8ZXWxM5tryHmam3PUGeepM87T3AaRzWXcB/fzU55eHhFXdLDaNbSv6PipiNif9mFPW90A7BURDwfGgP2BD/U6TkmS6sJsliTVVRmHKD93ytNHAY/sYLVLgcMj4lraW5dPjIhXArdm5r9ExOuBreH8qcz8Vq/jlCSpLsxmSVJdlXGI8rFTHj8AzHWOD5k5CZwybfHNU16/mF8eXiVJkubHbJYk1VIZhyifGBF7Ab8O3JKZ3+x9WJIkqVtmsySprnq+TVBE/Bnt83AOAD4YEa/ueVSSJKlrZrMkqa56LnCB44CDMvN04FnAi0voU5Ikdc9sliTVUhkFbmPrbQQycwuwpYQ+JUlS98xmSVItlXGRqa9GxCXA1cBBtG8zIEmSBsdsliTVUs97cDPz1cBHgWXARzLzL3selSRJ6prZLEmqqzIuMrUH8GRgFbBvRLy51z4lSVL3zGZJUl2VcQ7uJ4CHAD+Z8k+SJA2O2SxJqqUyzsHdkJlnldCPJEkqh9ksSaqlrgvciPi14uFPIuJY4BtACyAzbylhbJIkaR7MZklS3fWyB/cDUx6fPOVxC3h2D/1KkqTumM2SpFrrpcB9R2b+W2kjkSRJvTKbJUm11stFpl5d2igkSVIZzGZJUq31sge3GRHLgMb0FzJzcw/9Sppm1cgyxjZOMj7ZYrjZYHRlkw3rtwx6WJIWH7NZWiBms7Q49VLg7gck7RBtFcu2Pt6zx3FJKqwaWcbt92zi1Atv4M57N7LbTis57/h92HPn5QappOnMZmkBmM3S4tVLgbs2Mw8rbSSSZjS2cfLBAAW4896NnHrhDXzy5P3ZYcBjk7TomM3SAjCbpcWrl3NwJS2A8cnWgwG61Z33bmR8sjXLGpIkqZ/MZmnx6qXAfUVpo5A0q+Fmg912Wvkry3bbaSXDzW1OsZMks1laAGaztHj1dBXliDgqIoamLoyIZkQcHREX9jg2ScDoyibnHb/Pg0G69Tyf0ZUegCFpG2aztADMZmnx6uUc3JOA04G/i4gx4CfATsAa4OPF65J6tGH9FvbceTmfPHl/r9QoaS5ms7QAzGZp8eq6wC1uN/B24O0R8UTg4cBPM/O2sgYnqW3D+i3sAO0LV0zChvUTAx6RpMXIbJYWjtksLU697MF9UGb+N/DfZfQlSZJ6ZzZLkurIEwUkSZIkSZVggStJkiRJqoSeD1GOiP2BE4FlQAPYNTOP6LVfSZLUHbNZklRXZezBfQ9wJbAjcAdwdwl9SpKk7pnNkqRaKqPAHcvMTwDrMvNMYLcS+pQkSd0zmyVJtVRGgduKiKcAqyIigF1K6FOSJHXPbJYk1VIZtwl6JfAU2odDXQScP9cKEdEEzgWeCmwCTsrMW2do8zng/2XmnH1KkqQHmc2SpFrqeQ9uZn4buBFYDRwN/H0Hqx0NrMjMZwKvA86eoc3fAA/rdXySJNWN2SxJqqueC9yIeDntLcN/C/we8N4OVjsQuBwgM9cC+07r84XAJHBZr+OTJKluzGZJUl2VcYjyMcBBwJcy890R8fUO1lkN3Dfl+UREDGfmeETsBRwHvBB4cycDGBpqMDq6ar7jnqWvZml9VZnzNDfnqDPOU2ecp7k5R7/CbK4h52luzlFnnKfOOE9zG8QclVHgbt0L3Cp+bupgnXXAyNQ+MnO8ePwS4NHAl4A9gM0R8f3MvHy2ziYmWoyNbZjXoGczOrqqtL6qzHmam3PUGeepM87T3MqcozVrRuZutLiZzTXkPM3NOeqM89QZ52lug8jmMgrci4CrgMdGxL8Bn+lgnWuA5wOfKm5Gf9PWFzLzNVsfR8SZwF3bC1BJkrQNs1mSVEtlFLhfAL4I7AVkZv5XB+tcChweEdcCDeDEiHglcGtm/ksJY5Ikqc7MZklSLZVR4P5DZh4IfLfTFTJzEjhl2uKbZ2h3Zm9DkySplsxmSVItlVHg/iIi3gUk7asrkpkfLKFfSZLUHbNZklRLZRS41xY/H1n8bM3WUJIkLQizWZJUSz0XuJl51tbHEfF84LRe+5QkSd0zmyVJddVzgRsRDwNOAk4GbgM+3GufkiSpe2azJKmuui5wI2If4OXAAcCngDsz84iyBiZJkubHbJYk1V1z7iazuhb4MbB3Zv4V4F2OJUkaLLNZklRrvRS4BwNrgG9HxNuAh5YzJEmS1CWzWZJUa10XuJl5XWaeDDwNuAVYFhHXRcTLSxudJEnqmNksSaq7Mq6i/AvgH4B/iIi9aV/UQpIkDYjZLEmqqzLug/ugzLwJeEWZfUqSpO6ZzZKkOunlHFxJkiRJkhYNC1xJkiRJUiX0ch/cLwOtmV7LzGd3PSJJktQVs1mSVHe9nIN7SvHzDOAzwDXAM4Df7nVQkiSpK2azJKnWui5wMzMBIuKRmfmpYvGlEfFnpYxMkiTNi9ksSaq7Uq6iHBEvA64HDgA2lNGnJEnqntksSaqjMi4y9YfAk4C3Ab8GvLiEPiVJUvfMZklSLfW8Bzcz74qIdwArikU7A7/otV9JktQds1mSVFc9F7gRcS5wJPA/QIP21RsP6LVf1duqkWWMbZxkfLLFcLPB6MomG9ZvGfSwJGlJMJvVD2azpKWgjHNwnwE8PjMnS+hLYtXIMm6/ZxOnXngDd967kd12Wsl5x+/DnjsvN0glqTNms0plNktaKso4B/dWfnkIlNSzsY2TDwYowJ33buTUC29gbKP/nyZJHTKbVSqzWdJSUcYe3N2BOyLi1uJ5KzM9DEpdG59sPRigW91570bGJ1vsMKAxSdISYzarVGazpKWijAL32BL60AAs1nNphpsNdttp5a8E6W47rWS42QA3FEtSJ8zmJcpslqTelFHgLgNeVPxsALsCf1JCv+qjxXwuzejKJucdv882Y2uH/MRAxyZJS4TZvASZzZLUuzIK3I8BnwUOBH4MPLSEPtVns51L88mT9x/4oUYb1m9hz52X88mT9190W7AlaYkwm5cgs1mSelfGRaY2ZOZbgTsz8wTgkSX0qT7b3rk0i8GG9VvYYXyCVZOT7DA+YYBK0vyYzUuQ2SxJvSujwG1ExC7AQyPiIcDDSuhTfbb1XJqpHjyXRpK01JnNS5DZLEm9K6PAPQs4GrgQ+B5wWQl9qs+2nkuzNUinnksjSVryzOYlyGyWpN71fA5uZl4FXFU8fUREHDTXOhHRBM4FngpsAk7KzFunvP4XwDHF03/LzLN6Had+1WI4l2axXilSkpY6s3lpMpslqXf92CR4dgdtjgZWZP7/9u49zs2q3vf4J8lkpjPtlCm03CxuAeXHpa9ypFxaRCwoCFo37A0cEIqUW4ugbG8VL5uNHlA3Aue4UbkURC6iFmErUDawFRARKELBXbDyQ25KAaEtHTrtXJJJcv54kiEzk8szM5lJJvN9v159dZInWVlZTfOdtZ611uPzgK/kP8fMdgFOAg4E5gGHm9nsUahnzWtpjZNoiNEZjZJoiNHSGq9o+ZVYSzPcOuZ2ijx+2Uo+dMlvOX7ZSl7c0FPx9ygiIoCyuWLGazb3NMTINDYQixX/1U/ZLCL1YDQ6uGEWihwE3APg7iuBffOOvQIc4e4pd08TXOKgu+K1rHHjIWRGUsdiO0W2d+lieiIio0DZXAHjOZunNUd5Yf0W3upNF+3kKptFpB5U4jJBA4XZ6m8q8Hbe7ZSZNbh7r7sngfVmFgEuAZ5y9+dKFRaLRWhraxl+jfuVFa1YWSPx5uaeopcK2LYG6heLRWnfXPxyBuXq+Nqm7qI7RdbC+6uEWvks1Tq1Uzhqp/LURiUpmytgvGfz0ltXc+FRs5i641SmtU4a9Hxls+SoncJRO5VXjTYadgfXzB5lcGBGgN1DPH0T0Jp3O+ruvXllTwKuAzqAs8sVlkplaG/vDPGy5bW1tVSsrKEYuOZlanO0aMiMZv3Crr1pa2speTmDcnVsaIgxc1pzv+fndoqsRvuPhmp9lsYbtVM4aqfyKtlGM2a0ln9QDVI2V9bATIzHIuM6m9du7KKlMUZ3MkV7z+DnK5slR+0UjtqpvGpk80jO4J5Q/iFFPQx8ArjFzOYCT+cOZEeHbwfud/eLR/Aa40ZuOlFuxDW3a+Ld5x7IkZc/0ve4mdOa2XpyjE1dkVHZ/KFYPXbZpqnga+QuZ1AoCCkzmym3U+TA1wreT6oi70dEZAJSNldIsUxc8sH3cPVDL/c9bua0ZtpaYmzurv1snjmtmc5EioZI4RnrymYRqQeRTGbsLx6et1PjbIKR5VOBjwHPAzHgZ8DKvKd81d0fLVZeMpnKjOdR4kRDjOOXrRwURssXz+27f+a0Zu4690D+9lb4kBvqToil6tHY2z/Y2tpaSKSSQwrdkdZvvNGoXjhqp3DUTuVVeJR4Ff3XoNY9ZXN/xTLx54vnckJeNt/+mQN5rX18ZPPqVzczo7WJrRuipFKFR6KVzQJqp7DUTuVVI5tHYw1uWdkNKs4acPezeT8PXhhSx0pNJ8q/VMDm7uLrahoHlDnUEd9y9RhYPoz8cgadHUkaISg7jUaHRUSqSNncX7FMTA3I5u7E+MjmjV1pdp0+mYZUumjnNvd8ZbOIjGcj3kXZzGYOuG0jLXOiyU0bypebTpQfTqVCbqDh7IRYqh7FVOJyBiIiUlnK5pGrt2xu6k0RSfSW7NyKiNSDYXdwzWyWmX0UWGFmh2f/HAksr1z16l9La7xvzUsuwHIjut+880/9tvif1BANHXJDCdycYvVoax6Nq0mJiEilKZsro6U1TjwW5aoQ2TyUDqiyWURk9I1kivI0gs0stgM+mb0vTbB+R0JoaY3z+qYkM1rjbNfaxM8XzyWVHRX+5p1/4r/XvAm8M8L7iyXzQm/+MJwNoMpNOc5fl5PY3ENba1xnbEVEaouyeYRy2bxxS5IZrU385PQDiMcixGNR/vVXTw/K5js+c6CyWUSkhgy7g+vuDwEPmdk+7v4kBBtUZNfwTGhhN2jYkoCtJ8cHbRx10+n79wVoztqNXSRS6dBrXtuao/0e98bbncTj8bI7IRZbezOcdUMiIjK2lM3FDczm5sYosXSGRHdvv8dt6cmwpaeX3nSahT96rC/zrl44h7bm/qte127soqM7NaRsvvmMA1jX0cOGLQluW/UKn/3wbspmEZEKqsT8ll3N7AQzOwV43cy+VIEyx61c2By/bGW/KUwtrfFBj02k0nQV2Jzi5fWdRac7hVnz2tIa56UBdYjH4yMKvOGsGxIRkapRNucplM1rN3azKZkelM+JdIa3tiRZeuvqvsybMaWJNzt6OOfQ9/LweYdwzcn7AEPP5vVbUv06t+d+eDd22aaJjcPMUmWziMhglejgfgn4NbAQeDfBNfQmrLBhkwvUQutxLr/vLwXX/YRZb5ML0LMqHHjDWTckIiJVo2zOUyibz775SSKRCBu70qQbG4g2x2lpjZNKZ2hpjPU99v07tfGljxrn3/5MX+d4+7YWbjx1zpCy+eUNPZx07WMce9WjXLhiDaccuDOX3/cc7V1p0sPMUmWziMhglejg9mT/7nD3HqC1AmWOW6XCpqU1TqIhRjIe4+UNPZywbCWJ3vSgs7XrNvfQOqmB8xfsya1nzWP54rmDzr7myuqMRkk0xPo6zO1dadZ19FQ88Iazi6OIiFSNsjlPsWx+dWMXjQ3B8Z7eNC9v6OHFdVvoTKT6Mu+s+bty3m2rBw0a77rt1CFl85IBHezzblvNMXN2ojedIT7MLFU2i4gMVokO7ovAE8B1ZnYB8FgFyhy3ioXN9MmxvulRf93QyZsdPVx23N50Jnq58qR9+p2tveKkffjh/c+z5KZVHHvVo/SmM4MCtNg06N50hg1bEhUPPO3iKCIyriib8xTL5t22m8wbm5Icv2wlHd1JpjbH2WXGZHbbbgrXn7ovM6c109YcLzpoPJRsLlTGNpMbaYhGaMoMbwBa2SwiMthIdlEGwN0XmdkUd99sZk+4+98rUbHxKhc2Azd8yE2PmjGliSlNDSy99cm+49eeMocbTtufhmiEZCrDsgdf4JZVa4HCuysWmwa9fPFcGqIRblv1ChcfM7tvxHnmtGauKrKjY1jldnEUEZHaoWzur1A2X3zMbDqz+2AcP2cmiRScfs3Kftn9n5+eRyKVCbXzcblsLlTGjNamEWWpsllEZLARD/GZ2V7A3Wb2NLDIzBaMvFrjV37YPLh0ft/04tzo7Xf+eRbNjQ3ceNr+/PrzB3PgLttwxg2r+NuGTloaY3QlUzzy4gag+EhsqWnQbc1RPvvh3bjhkZf6pjjffMYB7FyBHRXzN9HYdop2aBQRqVXK5v5y2fzzbDZfeNQsLr3X+/L0qH1mFuyc9vRmmNIU7ixpuWweWMbVC+cwfXJM2SwiUmEjPoMLXA6cClwD/Ai4G1hRgXLrSkM0wjcW7E4yDWfc+Ie+EeIrTgp2YnzP9Mm0xAk1ElvqOnq5EL/gE3tpNFdEZOJSNheQW6iz23ZTuOy4WX15ms4U7pymMxni0cpls860ioiMvoos0nD354GMu68DOipR5niSv6lEsiHG69n1PPlrcNqaoxy21w4Fd3Fc/KFdmdQQBF2YSw2UW3MTpgwREalvyuZ3srmhZfD62C3JIE+vWjiHWKT4Zk3KZhGR8aUSZ3DfMrMlwGQzOwFor0CZ40ahi6xfcuxsZkxpYu3Grr5pTrcsmVd0+lI8FmHqpAidIbOuvSvNqpfW89Mz55LJZIhEIty/5nW2btmBxvJPH1T//AvfDxxRLndcRERqkrI5L5sf+vIhRdfHbjM5zqbuZMH9M4ayd0V7V5qNm7v6naV94c1NtLfEK5LNvWnY3BPcN21yjA5ls4hIQZXo4J4OfA1YD+ybvT1hFNpUYumtqzl/wZ4suWlV3329qXTZ6Uth9aYzfGPFs3xjxbP97j9kj+2HFKKFOpDF5FEAABUpSURBVOdXLpzTd9mDUsdFRKSmKZvzsjlVZApyroN4+g3BRlO5geNoJMLkpqF1GnvTGT7141WD7n9w6fyKZPOObU0cv2wlFyzYg+3bWpTNIiJFVGKK8pXu/hV3/7i7f8nd36pAmeNGsbOybc3xvtszpzUTjUZY89rbFdnOv1LXvSu242N7VzrUcRERqVnK5rxsjpaYgtzUEOHKhXNYvmotB3/3AU669jHau5I0xYb2mqOdzd2JNGs3drHnjlspm0VESqjEGdxJZjYbeI7shvnunqhAueNCsbOynYlU389XLpxDPBrhmyv+zAUL9ug3fal10tCnFRW7FNFQLwNUasfHxjLHRUSkpimb87L59ifXFszNqc1RjvyPR/jV2fNGvAHUWGRzmOMiIhNdJTq4uwG3593OALtUoNxxoVCgXbVwDtu2NvHg0vl9QQkUCb6hTymq1G6MpaZMky5zXEREapmyOS9zl69ay7H7zRyUmxBk89FXPDo+sjnEcRGRiS6SyYx8xM/MIsAMYIO7hx+mrJBkMpVpb++sSFltbS0MtaywGzG1tMbpSkJPb21sDDGSNbiNsfiQ22miGc5naSJSO4Wjdiqvkm00Y0brKoK1q+OWsjl8Nm9JQCKVJpXOEI9G2KoGs3nHtiaO+sEjJdfgKpvL03dpOGqncNRO5VUjm0fcwTWz+cB1wNvANOBMd//1iAodomqHaFjlOpTVMNxdlPUfujy1UThqp3DUTuWpg/sOZXN44yWbw+yirO+J8tRG4aidwlE7lVeNbK7EJlMXAQe5+/uBD2RvSwG1uGlTuevy6bp9IiLjkrI5pPGSzYkt79zXo2wWESmqEh3clLu/BuDurwLdFSizLmljCBERGSPK5pCUzSIi9aUSm0xtMrPPAr8DDgbq5lIEYdfvhC2HdIYfL9qPy+/7C0+90g7039Sp0q8rIiITlrI5ZDkxKLnhYqVfV0RERlclOrgLgX8FvgWsAU6rQJlV19Ia57VNSda+1UVLY4zORIqZWzez49T4kAKt0NqeS46dzXfvcdZt7hl0CYFaXAskIiLjTt1m89s9adKZYFvodAbe7kmzVevws3nGlCYuOXY2S29dXfTyPspmEZHxY9gdXDNb4O4r3P1tYGkF61QTNvdkWN/Rw/m3P9OvYzq1qWFI87oLre1Zeutqfr54LhEYNAJcbC3Q8sVzaazg+xMRkfpT79nck4INm5ODOpqTGoZ2WZ/8rF27sYvv3uNceNQsdp0xmViBs7PKZhGR8WMka3C/kPvBzJZXoC41pTed6RvNhXc6pskhrskptrYnlc4U3BiiN51hxpQmrj55DssXz+Xqk+cwY0rTkNcCtbTGSTTE6IxGSTTEaGmND+n5IiIyLtV1NncnCnc0uxJD2xBqYDY/9Uo7p17/OBlQNouIjHMjmaKcf0XxbUdakVrS0hon1ZPmx4v2o7kxCkToTaVJpjI0xiLQG76skhdkL5DHzQ1RvnyE9Zsqdcmxs2luiEKJAM9fG9Qcj/HShh7O0lQqEZGJpq6z+c3Nvazd2MX7d2rjrPm70tYcp70rSSRS/vn5hprNk4pk86QhZPOUSTFNcxYRGQMjOYObKfLzuNeTgg1bklxy77P8dUMXJyxbyfxLH+TU6x/njY7EkEZc25qjXLlwDjOnNQP0W9tTSG+GgmeOe0u0cG5t0Dfv/BPP/r2DTd29rOvoYcaUpr4yqn3JAxERGRN1m81dSWiIRrnr3IP4xj/uxYUr1nD8spVcuGING7ckRzWbMxTO5mIN3NQSJ9oSZ/2WFF3JFJFIhM3dKdYrm0VERt1IzuDuambfJhgtzv0MgLt/bcQ1G2O5Udb1nT2QibDkplWcv2BPzrtt9YjW3HR2JNllmyaWL54baufFZCpdcEpzMpUmP7rzR4UTXWm+f99znHLgzn31nTmtmYuPmc2l9zpPvdLed8kDrRUSEalrdZnNG7sSvNmR4KyfBNl84Yo1/bJ5yShnc09v4Wzu6U3TMqC+3Uno7M2wYXOCO/64lo/v/S4W/fhxZbOIyBgZSQf334r8XJaZRYErgL2BHuAMd38+7/iZwBKCycAXufuKEdSzrNwZ0O/f9xxLP7o7jQ1R1m7soq05XvTaeEMJo86OJI0QPCdN366MhYSZNjVwN8f7v/ghjpmz06DO+Hm3reb8BXuy5KZVJadeiYhI3ai7bF710noO22sHupMpzl+wJztuNalms3l9Z4q3O5Ns2Jzg/Nuf4ceL9uPU6x9XNouIjKFhd3Dd/YYRvO7RwCR3n2dmc4HLgKMAzGx74FxgX2AS8Hsz+7W794zg9UpqzzsDeur1j3P+gj2ZOa2Z9q7kkNboVEJu2tTANTr5lysYuJtjKp1hm8mNBQO/rTlesAwREak/9ZbNq15az5ydp3P8spV9mfjDE/fh8D235b/XvNn32FrJ5mRvhrNvfpLLjtubtRu7iEUjymYRkTFWievgDsdBwD0A7r7SzPbNO7Y/8HA2NHvM7HlgNvD4aFWmN53pdwb0qt++wMXHzOaGR17i4mNm95v2O9phFGba1MDdH6/53Yucc+h7C3bG3zWtmeWL5+qC9CIiUk7NZfOhe+7Aides7HcG9JyfPsmNp+3Pmtc7ai6bo5GgjrkB8lQ6o2wWERlj1ergTgXezrudMrMGd+8tcKwD2KpUYbFYhLa2llIPKSmxuaffGdCnXmnn0nuds+bvyj9s3czPzpxLOpMhHo2wdXMjsViExrbR3dp/2yn9b+e/XmJzT7/AvGXVWvbcYQpXL5zDkgGjy9Oz9R1YxkjFYtERtflEoDYKR+0UjtqpPLXRiNVcNieLXGqvo7uXG0/bn2g0QlMsyrRJ8ZrI5mQq6NDmBspvfeJvXHHSPpx985PK5hqhNgpH7RSO2qm8arRRtTq4m4DWvNvRbIAWOtYKtJcqLJXK0N7eOezKtLXG6U039es0PvVKOxeuWMPPF88lCmzdEqOzI0lHR1fpwsZAW2t80FSpOTtP5z0FRpdHq75tbS0javOJQG0UjtopHLVTeZVsoxkzWss/qP7UXDa3d6ULngGdPqWReCzK5Mbg7GpHcgjX7xslba1xejOZvg7tpfc65374fWw3VdlcS9RG4aidwlE7lVeNbK5WB/dh4BPALdl1Pk/nHfsD8C0zmwQ0AXsAz4xmZTo7kkxvjXPVwjmDrh07LTt9qJbWx5SaKhV2wwwREZEBaiqbe5OZMmtfk3SO2grgocv9LjE5HuvL53g0wqQIJHpTymYRkTFSrQ7uL4HDzOwRgksZnGpmXwCed/c7zOxy4CGC6/R+3d27R7tCnR1Jdh7CJQOqTZ1ZERGpsJrK5kR3L9AwpMv5VFuuXvn5nKj+yWURkQklksmM/+vAJ5OpTKVOfWuqQThqp/LURuGoncJRO5VX4WlQqwh2DJZhUjaPPbVTeWqjcNRO4aidyqtGNkcr8moiIiIiIiIiVaYOroiIiIiIiNQFdXBFRERERESkLqiDKyIiIiIiInWhLjaZAtYBf612JUREpG78AzCj2pUY55TNIiJSSaGyuV46uCIiIiIiIjLBaYqyiIiIiIiI1AV1cEVERERERKQuqIMrIiIiIiIidUEdXBEREREREakL6uCKiIiIiIhIXVAHV0REREREROpCQ7UrUC1mFgWuAPYGeoAz3P35vONnAkuAXuAid19RlYpWUYg2+jxwQvbmf7n7N8e+ltVXrp3yHnMXcLu7XzX2tay+EJ+nI4ELsjefBM5x9wl1HbMQbfQl4JNAGvi2u/+yKhWtEWZ2AHCxu88fcP8ngH8j+P6+zt2vqUL1ZBiUzeUpm8NRNpenXA5H2Tw0tZDNE/kM7tHAJHefB3wFuCx3wMy2B84FPgB8FPiOmTVVpZbVVaqNdgFOAg4E5gGHm9nsqtSy+oq2U56LgK3HtFa1p9TnqRW4BFjg7nOBl4Hp1ahklZVqozaC76V5wOHA96pSwxphZl8GrgUmDbg/Dvw/gjb6ELA4+50u44OyuTxlczjK5vKUy+Eom0OqlWyeyB3cg4B7ANx9JbBv3rH9gYfdvcfd3waeByZiQJRqo1eAI9w95e5pIA50j30Va0KpdsLMjiUY1bt77KtWU0q104HA08BlZvYQ8Ia7rxv7KlZdqTbaAvwVmJz9kx7z2tWWF4B/LnD/HsDz7r7R3RPA74EPjmnNZCSUzeUpm8NRNpenXA5H2RxeTWTzRO7gTgXezrudMrOGIsc6gK3GqmI1pGgbuXvS3debWcTMLgWecvfnqlLL6ivaTmY2CziRYErGRFfq/9x04BDgPOBI4HNmttsY168WlGojCH55XUMwVezysaxYrXH324BkgUP6/h7flM3lKZvDUTaXp1wOR9kcUq1k80Tu4G4CWvNuR929t8ixVqB9rCpWQ0q1EWY2Cbg5+5izx7hutaRUO30KeBdwP7AI+IKZHTG21asZpdppA/C4u//d3TcDvwP+11hXsAaUaqMjgR2AnYF3A0eb2f5jXL/xQN/f45uyuTxlczjK5vKUy+Eom0duTL+/J3IH92HgYwBmNpdgGkbOH4APmtkkM9uK4LT6M2Nfxaor2kZmFgFuB/7H3Ze4e6o6VawJRdvJ3b/s7gdkF9pfD/xfd7+nGpWsAaX+z60CZpnZ9Oyo6FyC0dCJplQbbQS6gB537yYIhrYxr2Ht+zPwPjPb2swagYOBR6tcJwlP2VyesjkcZXN5yuVwlM0jN6bZPGF3UQZ+CRxmZo8AEeBUM/sCwfzwO8zscuAhgkGAr2c/tBNN0TYCYgSLxJuyu+wBfNXdJ+IvkiU/S9WtWk0p93/uq8C92cfe4u4T8RfXcm30EWClmaUJ1q/8uop1rSlmdiIwxd2XZdvsXoLv7+vc/dXq1k6GQNlcnrI5HGVzecrlcJTNw1StbI5kMhNut28RERERERGpQxN5irKIiIiIiIjUEXVwRUREREREpC6ogysiIiIiIiJ1QR1cERERERERqQvq4IqIiIiIiEhdmMiXCZIaZ2aXAXOA7YEW4EVgnbsfV+Tx7wFmufuKIsffC1zv7gfl3dcAvOzuMytU5ynAH939vQWO7QQ8B5zo7r+sxOvllR0huJbfV4GfZu9+P/AswfXZrgc+QvD+f1PJ1x4uM5sFfM/dPzLM58eB/wKagY+5+6YBx58B7nP3fxlxZQe/dpSgTRdP0MuUiMgEpWwe0usqm5XNUgXq4ErNcvcvApjZImB3d/9Kmad8BHgPUDBEa8BpwPeAcwiuqVZJJwIr3f01YD6Amf0eWOTuz2dvDyusati7gKnufsDAA2b2IeAJ4KNmNtndt1Tyhd09bWbLgS8C36pk2SIitUzZPCTK5jzKZhkr6uDKuGRm3wPmZW/eBCwDlgKTzOxRgpHRf80ebwYWDrH82cClBNP42wiCbxXwDPAYYMCrwHHAZIKR2a2AF4qUFyUIunnAPWa2h7v/2czOAE4GYtn6bg/8C5ACHnT3r5vZu4ErgEZgOnCBu9854CU+AywI8dbONrOvZeu6xN2fMLMvZ99HL/CAu3/NzC4iGD2/Nn8018z+HTgYiAM3uvv3zexQBrd1BLgBeA3YFXjY3T9rZu8CfgJkgHV57TOo3AHt9yngs0AP4MASgn/z3c3sCnc/e8D7PBP4GfBmtn2vypZzAfAJgu++HwC/Bf4TeAu4E/gN8B/ZMtYBp2ff0/LsfQ0EI8NrCC5W/l0z+7a764LiIjLhKZuVzSibpQZoDa6MO2Z2NLAjMBf4ILAIeC9wCXCTu98F7AV80t0PBe4Gjh3iy+wFfC47Refy7GtAEAhfdfe5BKOU+xB80T7p7gcD1xYp7/DsY94CrgPyv/TXZ6dm/YkgjA7N3t7FzA4BdgcudvfDgc8NeG5u6tX27r4hxPv6Q7ZNrgQ+ZWbvB44mCPcDgb3M7IgSzz8Z+CRBu+em/xRr6/cRtNv+wD+Z2XSCX3RuzD72jjLl5t7fttl2mZ9tl07gjGw7PD0wQM1sGnAAcA95bW1m+wEfztbnA8Cs7FO2BQ5z98uAHxGE5HyCQP0iwedsPXAE8HmCX0Bw916C8N2jRHuJiEwIymZlM8pmqRE6gyvj0R7AQ9mRuYSZPcbgL7JXgR+a2WZgJsFo4FC8CnzDzLoIvjTXZ+9/MzvVCGAtMIkgRH6Vve9RIF2gvDOBd5vZPQSjvbOzo7UQjHpCEDrbAnebGcBUgtB+DPiamZ1JMCgVH1D21uSNuJaxKvv33wnCYXfg0Wwg5KZO7TXgOZG8nz8JfBfYjnemmxVr67/kph+Z2d95p62uyR5/GDi1RLk5uxKEZW4q0+8IRpSLrVdaSNBOd2Vv75SdFrUT8Ji7p4EtwOeya79edPdk9rG7A8uy7d8IrAH+T7YOdwAJ4MK813od2KZIPUREJhJlc3/K5v6UzTJmdAZXxqM/AwcBmFkjwQjnXwjCK/eZXgac4u6LgDfoHwRh/AD4urufQjB6m3t+oekuz/LOlKw5DPh/lR3l3Ac4wN2PyI6Q3kkwMgrvhO4LwN8IRiznZ+vwGME6kuvc/VPAgwXey3qCwA1jYP2fBeaaWSy7GcYHCTbb6AZ2yD5mn+z7aAb+CTgBOBRYnJ3WVKyty7XVfmXKzXkBmGVmLdnbH8rWsZjTgY9n2/oIgpH1cwg+N3PMLGJmjWb2G4J/q/xfep4FFmbb/ysEG2UcArySHaW/GLgo7/HTCKZaiYhMdMrm/pTN/SmbZcyogyvj0e3Aa2b2CMGo7E/dfTWwGjjGzI4jWHfzuJk9TLDL444lytvWzJ7I+/O/Cdai3GVmDxGMEJZ6/uUEU5Z+TzAa3Dvg+CLgF9nRyZxrCL7Y+7j7G8D3gQezI9+HAc8DtwBXZOsyn2AkOf95ncBbZjbk0Up3f4pghPsR4HGCX0ZWEKyROcrMHgD2zj62C9gE/BF4AFjh7q8ytLb+OsG/0QPAx8uUm6vjmwTB9YCZrQRaCYJ7EDPbH0i4+7N5d/+CIAhfB+4nGJ3+HcE6pIEj+p8Gbs7+W15E8Jn6H+DT2c/bdwiCFDOLEazLKhXoIiIThbK5//OUzVnKZhlrkUxG669FxjszOxloG7gBhIweM/tHYE93//dq10VERGqPsnnsKZsFdAZXpF7cDByQN1VIRlF2ytjxvLOro4iIyEDK5jGkbJYcncEVERERERGRuqAzuCIiIiIiIlIX1MEVERERERGRuqAOroiIiIiIiNQFdXBFRERERESkLqiDKyIiIiIiInXh/wNMhWn3qX2eVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot comparison of unbalanced and balanced training sets\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16,8))\n",
    "\n",
    "sns.countplot(y_train,       order=y_train.value_counts().index, alpha=0.8, ax = axes[0,0])\n",
    "sns.countplot(y_train_smote, order=y_train.value_counts().index, alpha=0.8, ax = axes[0,1])\n",
    "\n",
    "sns.scatterplot(x=X_train.columns[0],       y=X_train.columns[1],       data=X_train,       ax = axes[1,0])\n",
    "sns.scatterplot(x=X_train_smote.columns[0], y=X_train_smote.columns[1], data=X_train_smote, ax = axes[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1966s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1786s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:    2.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Decision Tree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1536s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Random Forest\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:   18.2s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   19.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Ada Boost\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  1.3min remaining:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.338762</td>\n",
       "      <td>0.333144</td>\n",
       "      <td>0.333670</td>\n",
       "      <td>0.334150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.309692</td>\n",
       "      <td>0.609073</td>\n",
       "      <td>0.309692</td>\n",
       "      <td>0.375733</td>\n",
       "      <td>[[534, 571, 631], [55, 48, 59], [115, 136, 121]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.366047</td>\n",
       "      <td>0.243448</td>\n",
       "      <td>0.366047</td>\n",
       "      <td>0.289320</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.399145</td>\n",
       "      <td>0.404937</td>\n",
       "      <td>0.399145</td>\n",
       "      <td>0.362017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.331316</td>\n",
       "      <td>0.145512</td>\n",
       "      <td>0.331316</td>\n",
       "      <td>0.167669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.405006</td>\n",
       "      <td>0.404439</td>\n",
       "      <td>0.405006</td>\n",
       "      <td>0.393515</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.405054</td>\n",
       "      <td>0.404630</td>\n",
       "      <td>0.405054</td>\n",
       "      <td>0.393509</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.252816</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.301646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.376952</td>\n",
       "      <td>0.252752</td>\n",
       "      <td>0.376952</td>\n",
       "      <td>0.301566</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.406448</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.399150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.406448</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.399150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.252816</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.301646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.252816</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.301646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.406448</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.399150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.406448</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.399150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.252816</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.301646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.252816</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.301646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.406448</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.399150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.406448</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.399150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.252816</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.301646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.252816</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.301646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.415859</td>\n",
       "      <td>0.686188</td>\n",
       "      <td>0.415859</td>\n",
       "      <td>0.469860</td>\n",
       "      <td>[[671, 383, 682], [40, 55, 67], [89, 65, 218]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.374213</td>\n",
       "      <td>0.249609</td>\n",
       "      <td>0.374213</td>\n",
       "      <td>0.297350</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.374213</td>\n",
       "      <td>0.249609</td>\n",
       "      <td>0.374213</td>\n",
       "      <td>0.297350</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.471366</td>\n",
       "      <td>0.650169</td>\n",
       "      <td>0.471366</td>\n",
       "      <td>0.507660</td>\n",
       "      <td>[[827, 0, 909], [67, 0, 95], [129, 0, 243]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.368209</td>\n",
       "      <td>0.381529</td>\n",
       "      <td>0.368209</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.378152</td>\n",
       "      <td>0.386629</td>\n",
       "      <td>0.378152</td>\n",
       "      <td>0.373376</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.368305</td>\n",
       "      <td>0.381625</td>\n",
       "      <td>0.368305</td>\n",
       "      <td>0.359103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.378249</td>\n",
       "      <td>0.386695</td>\n",
       "      <td>0.378249</td>\n",
       "      <td>0.373461</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.368282</td>\n",
       "      <td>0.658614</td>\n",
       "      <td>0.368282</td>\n",
       "      <td>0.420609</td>\n",
       "      <td>[[574, 509, 653], [47, 64, 51], [92, 82, 198]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.403228</td>\n",
       "      <td>0.322679</td>\n",
       "      <td>0.403228</td>\n",
       "      <td>0.297348</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.443772</td>\n",
       "      <td>0.494579</td>\n",
       "      <td>0.443772</td>\n",
       "      <td>0.429311</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.403228</td>\n",
       "      <td>0.322679</td>\n",
       "      <td>0.403228</td>\n",
       "      <td>0.297348</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.428194</td>\n",
       "      <td>0.704959</td>\n",
       "      <td>0.428194</td>\n",
       "      <td>0.503481</td>\n",
       "      <td>[[764, 774, 198], [53, 107, 2], [92, 179, 101]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.315413</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.297166</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.315413</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.297166</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.315413</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.297166</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.055111</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.058950</td>\n",
       "      <td>[[0, 1496, 240], [0, 152, 10], [0, 264, 108]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.469226</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.452761</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.458856</td>\n",
       "      <td>0.469973</td>\n",
       "      <td>0.458856</td>\n",
       "      <td>0.453193</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.460489</td>\n",
       "      <td>0.469609</td>\n",
       "      <td>0.460489</td>\n",
       "      <td>0.455017</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.461210</td>\n",
       "      <td>0.473991</td>\n",
       "      <td>0.461210</td>\n",
       "      <td>0.455086</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.461306</td>\n",
       "      <td>0.472034</td>\n",
       "      <td>0.461306</td>\n",
       "      <td>0.456404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.460825</td>\n",
       "      <td>0.468227</td>\n",
       "      <td>0.460825</td>\n",
       "      <td>0.457584</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.392070</td>\n",
       "      <td>0.690880</td>\n",
       "      <td>0.392070</td>\n",
       "      <td>0.462166</td>\n",
       "      <td>[[652, 756, 328], [49, 93, 20], [83, 144, 145]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Data               Classifier  \\\n",
       "0   Balanced                    Dummy   \n",
       "1   Balanced                    Dummy   \n",
       "2   Balanced                    Dummy   \n",
       "3   Balanced      Logistic Regression   \n",
       "4   Balanced      Logistic Regression   \n",
       "5   Balanced      Logistic Regression   \n",
       "6   Balanced      Logistic Regression   \n",
       "7   Balanced      Logistic Regression   \n",
       "8   Balanced      Logistic Regression   \n",
       "9   Balanced      Logistic Regression   \n",
       "10  Balanced      Logistic Regression   \n",
       "11  Balanced      Logistic Regression   \n",
       "12  Balanced      Logistic Regression   \n",
       "13  Balanced      Logistic Regression   \n",
       "14  Balanced      Logistic Regression   \n",
       "15  Balanced      Logistic Regression   \n",
       "16  Balanced      Logistic Regression   \n",
       "17  Balanced      Logistic Regression   \n",
       "18  Balanced      Logistic Regression   \n",
       "19  Balanced      Logistic Regression   \n",
       "20  Balanced      Logistic Regression   \n",
       "21  Balanced      Logistic Regression   \n",
       "22  Balanced      Logistic Regression   \n",
       "23  Balanced      Logistic Regression   \n",
       "24  Balanced  Multinomial Naive Bayes   \n",
       "25  Balanced  Multinomial Naive Bayes   \n",
       "26  Balanced  Multinomial Naive Bayes   \n",
       "27  Balanced      K Nearest Neighbors   \n",
       "28  Balanced      K Nearest Neighbors   \n",
       "29  Balanced      K Nearest Neighbors   \n",
       "30  Balanced      K Nearest Neighbors   \n",
       "31  Balanced      K Nearest Neighbors   \n",
       "32  Balanced            Decision Tree   \n",
       "33  Balanced            Decision Tree   \n",
       "34  Balanced            Decision Tree   \n",
       "35  Balanced            Decision Tree   \n",
       "36  Balanced            Decision Tree   \n",
       "37  Balanced            Decision Tree   \n",
       "38  Balanced            Decision Tree   \n",
       "39  Balanced            Random Forest   \n",
       "40  Balanced            Random Forest   \n",
       "41  Balanced            Random Forest   \n",
       "42  Balanced            Random Forest   \n",
       "43  Balanced            Random Forest   \n",
       "44  Balanced            Random Forest   \n",
       "45  Balanced            Random Forest   \n",
       "46  Balanced            Random Forest   \n",
       "47  Balanced            Random Forest   \n",
       "48  Balanced            Random Forest   \n",
       "49  Balanced                Ada Boost   \n",
       "50  Balanced                Ada Boost   \n",
       "51  Balanced                Ada Boost   \n",
       "52  Balanced                Ada Boost   \n",
       "53  Balanced                Ada Boost   \n",
       "54  Balanced                Ada Boost   \n",
       "55  Balanced                Ada Boost   \n",
       "\n",
       "                                           Parameters  Split  Accuracy  \\\n",
       "0                       {'strategy': 'most_frequent'}  Train  0.333333   \n",
       "1                          {'strategy': 'stratified'}  Train  0.338762   \n",
       "2                          {'strategy': 'stratified'}   Test  0.309692   \n",
       "3   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.366047   \n",
       "4   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.399145   \n",
       "5   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.331316   \n",
       "6   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.333333   \n",
       "7   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.405006   \n",
       "8   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.405054   \n",
       "9   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.377048   \n",
       "10  {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.376952   \n",
       "11  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.407888   \n",
       "12  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.407888   \n",
       "13  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.377048   \n",
       "14  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.377048   \n",
       "15  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.407888   \n",
       "16  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.407888   \n",
       "17  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.377048   \n",
       "18  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.377048   \n",
       "19  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.407888   \n",
       "20  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.407888   \n",
       "21  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.377048   \n",
       "22  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.377048   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...   Test  0.415859   \n",
       "24                  {'alpha': 0.0, 'fit_prior': True}  Train  0.374213   \n",
       "25                  {'alpha': 1.0, 'fit_prior': True}  Train  0.374213   \n",
       "26                  {'alpha': 0.0, 'fit_prior': True}   Test  0.471366   \n",
       "27       {'algorithm': 'ball_tree', 'leaf_size': 100}  Train  0.368209   \n",
       "28       {'algorithm': 'ball_tree', 'leaf_size': 200}  Train  0.378152   \n",
       "29         {'algorithm': 'kd_tree', 'leaf_size': 100}  Train  0.368305   \n",
       "30         {'algorithm': 'kd_tree', 'leaf_size': 200}  Train  0.378249   \n",
       "31         {'algorithm': 'kd_tree', 'leaf_size': 200}   Test  0.368282   \n",
       "32  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.403228   \n",
       "33  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.333333   \n",
       "34  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.333333   \n",
       "35  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.443772   \n",
       "36  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.403228   \n",
       "37  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.333333   \n",
       "38  {'criterion': 'entropy', 'min_impurity_decreas...   Test  0.428194   \n",
       "39  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.400826   \n",
       "40  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.400826   \n",
       "41  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.400826   \n",
       "42  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.333333   \n",
       "43  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.333333   \n",
       "44  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.333333   \n",
       "45  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "46  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "47  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...   Test  0.114537   \n",
       "49        {'learning_rate': 0.5, 'n_estimators': 100}  Train  0.456790   \n",
       "50        {'learning_rate': 0.5, 'n_estimators': 200}  Train  0.458856   \n",
       "51        {'learning_rate': 0.5, 'n_estimators': 300}  Train  0.460489   \n",
       "52        {'learning_rate': 1.0, 'n_estimators': 100}  Train  0.461210   \n",
       "53        {'learning_rate': 1.0, 'n_estimators': 200}  Train  0.461306   \n",
       "54        {'learning_rate': 1.0, 'n_estimators': 300}  Train  0.460825   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 300}   Test  0.392070   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "0    0.111111  0.333333  0.166667   \n",
       "1    0.333144  0.333670  0.334150   \n",
       "2    0.609073  0.309692  0.375733   \n",
       "3    0.243448  0.366047  0.289320   \n",
       "4    0.404937  0.399145  0.362017   \n",
       "5    0.145512  0.331316  0.167669   \n",
       "6    0.111111  0.333333  0.166667   \n",
       "7    0.404439  0.405006  0.393515   \n",
       "8    0.404630  0.405054  0.393509   \n",
       "9    0.252816  0.377048  0.301646   \n",
       "10   0.252752  0.376952  0.301566   \n",
       "11   0.406448  0.407888  0.399150   \n",
       "12   0.406448  0.407888  0.399150   \n",
       "13   0.252816  0.377048  0.301646   \n",
       "14   0.252816  0.377048  0.301646   \n",
       "15   0.406448  0.407888  0.399150   \n",
       "16   0.406448  0.407888  0.399150   \n",
       "17   0.252816  0.377048  0.301646   \n",
       "18   0.252816  0.377048  0.301646   \n",
       "19   0.406448  0.407888  0.399150   \n",
       "20   0.406448  0.407888  0.399150   \n",
       "21   0.252816  0.377048  0.301646   \n",
       "22   0.252816  0.377048  0.301646   \n",
       "23   0.686188  0.415859  0.469860   \n",
       "24   0.249609  0.374213  0.297350   \n",
       "25   0.249609  0.374213  0.297350   \n",
       "26   0.650169  0.471366  0.507660   \n",
       "27   0.381529  0.368209  0.359000   \n",
       "28   0.386629  0.378152  0.373376   \n",
       "29   0.381625  0.368305  0.359103   \n",
       "30   0.386695  0.378249  0.373461   \n",
       "31   0.658614  0.368282  0.420609   \n",
       "32   0.322679  0.403228  0.297348   \n",
       "33   0.111111  0.333333  0.166667   \n",
       "34   0.111111  0.333333  0.166667   \n",
       "35   0.494579  0.443772  0.429311   \n",
       "36   0.322679  0.403228  0.297348   \n",
       "37   0.111111  0.333333  0.166667   \n",
       "38   0.704959  0.428194  0.503481   \n",
       "39   0.315413  0.400826  0.297166   \n",
       "40   0.315413  0.400826  0.297166   \n",
       "41   0.315413  0.400826  0.297166   \n",
       "42   0.111111  0.333333  0.166667   \n",
       "43   0.111111  0.333333  0.166667   \n",
       "44   0.111111  0.333333  0.166667   \n",
       "45   0.111111  0.333333  0.166667   \n",
       "46   0.111111  0.333333  0.166667   \n",
       "47   0.111111  0.333333  0.166667   \n",
       "48   0.055111  0.114537  0.058950   \n",
       "49   0.469226  0.456790  0.452761   \n",
       "50   0.469973  0.458856  0.453193   \n",
       "51   0.469609  0.460489  0.455017   \n",
       "52   0.473991  0.461210  0.455086   \n",
       "53   0.472034  0.461306  0.456404   \n",
       "54   0.468227  0.460825  0.457584   \n",
       "55   0.690880  0.392070  0.462166   \n",
       "\n",
       "                                    Confusion Matrix  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2   [[534, 571, 631], [55, 48, 59], [115, 136, 121]]  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  \n",
       "10                                               NaN  \n",
       "11                                               NaN  \n",
       "12                                               NaN  \n",
       "13                                               NaN  \n",
       "14                                               NaN  \n",
       "15                                               NaN  \n",
       "16                                               NaN  \n",
       "17                                               NaN  \n",
       "18                                               NaN  \n",
       "19                                               NaN  \n",
       "20                                               NaN  \n",
       "21                                               NaN  \n",
       "22                                               NaN  \n",
       "23    [[671, 383, 682], [40, 55, 67], [89, 65, 218]]  \n",
       "24                                               NaN  \n",
       "25                                               NaN  \n",
       "26       [[827, 0, 909], [67, 0, 95], [129, 0, 243]]  \n",
       "27                                               NaN  \n",
       "28                                               NaN  \n",
       "29                                               NaN  \n",
       "30                                               NaN  \n",
       "31    [[574, 509, 653], [47, 64, 51], [92, 82, 198]]  \n",
       "32                                               NaN  \n",
       "33                                               NaN  \n",
       "34                                               NaN  \n",
       "35                                               NaN  \n",
       "36                                               NaN  \n",
       "37                                               NaN  \n",
       "38   [[764, 774, 198], [53, 107, 2], [92, 179, 101]]  \n",
       "39                                               NaN  \n",
       "40                                               NaN  \n",
       "41                                               NaN  \n",
       "42                                               NaN  \n",
       "43                                               NaN  \n",
       "44                                               NaN  \n",
       "45                                               NaN  \n",
       "46                                               NaN  \n",
       "47                                               NaN  \n",
       "48     [[0, 1496, 240], [0, 152, 10], [0, 264, 108]]  \n",
       "49                                               NaN  \n",
       "50                                               NaN  \n",
       "51                                               NaN  \n",
       "52                                               NaN  \n",
       "53                                               NaN  \n",
       "54                                               NaN  \n",
       "55   [[652, 756, 328], [49, 93, 20], [83, 144, 145]]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run balanced dataset\n",
    "balanced = clf.fit_predict_measure('Balanced', X_train_smote, X_test, y_train_smote, y_test, y_labels, classifiers)\n",
    "balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.380877</td>\n",
       "      <td>0.332489</td>\n",
       "      <td>0.380786</td>\n",
       "      <td>0.322949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.055155</td>\n",
       "      <td>0.170577</td>\n",
       "      <td>0.055230</td>\n",
       "      <td>0.109708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.055111</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.058950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.337405</td>\n",
       "      <td>0.248068</td>\n",
       "      <td>0.333586</td>\n",
       "      <td>0.295204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.322679</td>\n",
       "      <td>0.377048</td>\n",
       "      <td>0.301646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.406448</td>\n",
       "      <td>0.407888</td>\n",
       "      <td>0.399150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.471366</td>\n",
       "      <td>0.704959</td>\n",
       "      <td>0.471366</td>\n",
       "      <td>0.507660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall   F1 Score\n",
       "count  56.000000  56.000000  56.000000  56.000000\n",
       "mean    0.380877   0.332489   0.380786   0.322949\n",
       "std     0.055155   0.170577   0.055230   0.109708\n",
       "min     0.114537   0.055111   0.114537   0.058950\n",
       "25%     0.337405   0.248068   0.333586   0.295204\n",
       "50%     0.377048   0.322679   0.377048   0.301646\n",
       "75%     0.407888   0.406448   0.407888   0.399150\n",
       "max     0.471366   0.704959   0.471366   0.507660"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of balanced classifiers (test and training sets)\n",
    "balanced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.471366</td>\n",
       "      <td>0.650169</td>\n",
       "      <td>0.471366</td>\n",
       "      <td>0.507660</td>\n",
       "      <td>[[827, 0, 909], [67, 0, 95], [129, 0, 243]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.428194</td>\n",
       "      <td>0.704959</td>\n",
       "      <td>0.428194</td>\n",
       "      <td>0.503481</td>\n",
       "      <td>[[764, 774, 198], [53, 107, 2], [92, 179, 101]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.415859</td>\n",
       "      <td>0.686188</td>\n",
       "      <td>0.415859</td>\n",
       "      <td>0.469860</td>\n",
       "      <td>[[671, 383, 682], [40, 55, 67], [89, 65, 218]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.392070</td>\n",
       "      <td>0.690880</td>\n",
       "      <td>0.392070</td>\n",
       "      <td>0.462166</td>\n",
       "      <td>[[652, 756, 328], [49, 93, 20], [83, 144, 145]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.368282</td>\n",
       "      <td>0.658614</td>\n",
       "      <td>0.368282</td>\n",
       "      <td>0.420609</td>\n",
       "      <td>[[574, 509, 653], [47, 64, 51], [92, 82, 198]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.309692</td>\n",
       "      <td>0.609073</td>\n",
       "      <td>0.309692</td>\n",
       "      <td>0.375733</td>\n",
       "      <td>[[534, 571, 631], [55, 48, 59], [115, 136, 121]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.055111</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.058950</td>\n",
       "      <td>[[0, 1496, 240], [0, 152, 10], [0, 264, 108]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Data               Classifier  \\\n",
       "26  Balanced  Multinomial Naive Bayes   \n",
       "38  Balanced            Decision Tree   \n",
       "23  Balanced      Logistic Regression   \n",
       "55  Balanced                Ada Boost   \n",
       "31  Balanced      K Nearest Neighbors   \n",
       "2   Balanced                    Dummy   \n",
       "48  Balanced            Random Forest   \n",
       "\n",
       "                                           Parameters Split  Accuracy  \\\n",
       "26                  {'alpha': 0.0, 'fit_prior': True}  Test  0.471366   \n",
       "38  {'criterion': 'entropy', 'min_impurity_decreas...  Test  0.428194   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Test  0.415859   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 300}  Test  0.392070   \n",
       "31         {'algorithm': 'kd_tree', 'leaf_size': 200}  Test  0.368282   \n",
       "2                          {'strategy': 'stratified'}  Test  0.309692   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...  Test  0.114537   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "26   0.650169  0.471366  0.507660   \n",
       "38   0.704959  0.428194  0.503481   \n",
       "23   0.686188  0.415859  0.469860   \n",
       "55   0.690880  0.392070  0.462166   \n",
       "31   0.658614  0.368282  0.420609   \n",
       "2    0.609073  0.309692  0.375733   \n",
       "48   0.055111  0.114537  0.058950   \n",
       "\n",
       "                                    Confusion Matrix  \n",
       "26       [[827, 0, 909], [67, 0, 95], [129, 0, 243]]  \n",
       "38   [[764, 774, 198], [53, 107, 2], [92, 179, 101]]  \n",
       "23    [[671, 383, 682], [40, 55, 67], [89, 65, 218]]  \n",
       "55   [[652, 756, 328], [49, 93, 20], [83, 144, 145]]  \n",
       "31    [[574, 509, 653], [47, 64, 51], [92, 82, 198]]  \n",
       "2   [[534, 571, 631], [55, 48, 59], [115, 136, 121]]  \n",
       "48     [[0, 1496, 240], [0, 152, 10], [0, 264, 108]]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators of balanced dataset\n",
    "balanced_test = balanced[balanced['Split'] == 'Test']\n",
    "balanced_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.to_pickle('../Data/baseline.pkl')\n",
    "balanced.to_pickle('../Data/balanced.pkl')\n",
    "pd.DataFrame(y_labels).to_pickle('../Data/y_labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
