{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifiers as clf\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "\n",
    "from imblearn.over_sampling  import SMOTENC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Species Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11347, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scientific Name</th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Federal Listing Status</th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "      <th>Days with AQI</th>\n",
       "      <th>Good Days</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>...</th>\n",
       "      <th>State_OR</th>\n",
       "      <th>State_PA</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accipiter gentilis</td>\n",
       "      <td>Northern goshawk</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acipenser fulvescens</td>\n",
       "      <td>Lake sturgeon</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acipenser oxyrinchus (=oxyrhynchus) desotoi</td>\n",
       "      <td>Atlantic sturgeon (Gulf subspecies)</td>\n",
       "      <td>Threatened</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agarodes alabamensis</td>\n",
       "      <td>[Unnamed] caddisfly</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agrimonia incisa</td>\n",
       "      <td>Incised groovebur</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Scientific Name  \\\n",
       "0                           Accipiter gentilis   \n",
       "1                         Acipenser fulvescens   \n",
       "2  Acipenser oxyrinchus (=oxyrhynchus) desotoi   \n",
       "3                         Agarodes alabamensis   \n",
       "4                             Agrimonia incisa   \n",
       "\n",
       "                           Common Name Federal Listing Status  \\\n",
       "0                     Northern goshawk             Not Listed   \n",
       "1                        Lake sturgeon             Not Listed   \n",
       "2  Atlantic sturgeon (Gulf subspecies)             Threatened   \n",
       "3                  [Unnamed] caddisfly             Not Listed   \n",
       "4                    Incised groovebur             Not Listed   \n",
       "\n",
       "   Total Land Area (Thousands of Acres)  \\\n",
       "0                                 32413   \n",
       "1                                 32413   \n",
       "2                                 32413   \n",
       "3                                 32413   \n",
       "4                                 32413   \n",
       "\n",
       "   Forest Land Area (Thousands of Acres)  Days with AQI  Good Days  \\\n",
       "0                                  22877            324        251   \n",
       "1                                  22877            324        251   \n",
       "2                                  22877            324        251   \n",
       "3                                  22877            324        251   \n",
       "4                                  22877            324        251   \n",
       "\n",
       "   Group_Amphibians  Group_Birds  Group_Clams    ...     State_OR  State_PA  \\\n",
       "0                 0            1            0    ...            0         0   \n",
       "1                 0            0            0    ...            0         0   \n",
       "2                 0            0            0    ...            0         0   \n",
       "3                 0            0            0    ...            0         0   \n",
       "4                 0            0            0    ...            0         0   \n",
       "\n",
       "   State_SC  State_TN  State_TX  State_UT  State_VA  State_WA  State_WV  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   State_WY  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = pd.read_pickle(\"../Data/species.pkl\")\n",
    "print(species.shape)\n",
    "species.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Target and Feature Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not Listed', 'Threatened', 'Endangered']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "      <th>Days with AQI</th>\n",
       "      <th>Good Days</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>Group_Crustaceans</th>\n",
       "      <th>Group_Ferns and Allies</th>\n",
       "      <th>Group_Fishes</th>\n",
       "      <th>...</th>\n",
       "      <th>State_OR</th>\n",
       "      <th>State_PA</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Land Area (Thousands of Acres)  \\\n",
       "0                                 32413   \n",
       "1                                 32413   \n",
       "2                                 32413   \n",
       "3                                 32413   \n",
       "4                                 32413   \n",
       "\n",
       "   Forest Land Area (Thousands of Acres)  Days with AQI  Good Days  \\\n",
       "0                                  22877            324        251   \n",
       "1                                  22877            324        251   \n",
       "2                                  22877            324        251   \n",
       "3                                  22877            324        251   \n",
       "4                                  22877            324        251   \n",
       "\n",
       "   Group_Amphibians  Group_Birds  Group_Clams  Group_Crustaceans  \\\n",
       "0                 0            1            0                  0   \n",
       "1                 0            0            0                  0   \n",
       "2                 0            0            0                  0   \n",
       "3                 0            0            0                  0   \n",
       "4                 0            0            0                  0   \n",
       "\n",
       "   Group_Ferns and Allies  Group_Fishes    ...     State_OR  State_PA  \\\n",
       "0                       0             0    ...            0         0   \n",
       "1                       0             1    ...            0         0   \n",
       "2                       0             1    ...            0         0   \n",
       "3                       0             0    ...            0         0   \n",
       "4                       0             0    ...            0         0   \n",
       "\n",
       "   State_SC  State_TN  State_TX  State_UT  State_VA  State_WA  State_WV  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   State_WY  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create target variables\n",
    "y = species['Federal Listing Status']\n",
    "y_labels = list(y.unique())\n",
    "print(y_labels)\n",
    "\n",
    "# Create target variables\n",
    "X = species.drop(['Federal Listing Status', 'Scientific Name', 'Common Name'], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train Normal</th>\n",
       "      <th>Test Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Listed</th>\n",
       "      <td>6938</td>\n",
       "      <td>1737</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.765198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Endangered</th>\n",
       "      <td>1506</td>\n",
       "      <td>378</td>\n",
       "      <td>0.165914</td>\n",
       "      <td>0.166520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threatened</th>\n",
       "      <td>633</td>\n",
       "      <td>155</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.068282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>9077</td>\n",
       "      <td>2270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Train  Test  Train Normal  Test Normal\n",
       "Not Listed   6938  1737      0.764349     0.765198\n",
       "Endangered   1506   378      0.165914     0.166520\n",
       "Threatened    633   155      0.069737     0.068282\n",
       "Total        9077  2270      1.000000     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# data set statistics\n",
    "data_sets = pd.DataFrame({'Train':        y_train.value_counts(),\n",
    "                          'Test':         y_test.value_counts(),\n",
    "                          'Train Normal': y_train.value_counts() / y_train.count(),\n",
    "                          'Test Normal':  y_test.value_counts()  / y_test.count()})\n",
    "\n",
    "data_sets.loc['Total'] = data_sets.sum().astype(int)\n",
    "data_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "      <th>Days with AQI</th>\n",
       "      <th>Good Days</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>Group_Crustaceans</th>\n",
       "      <th>Group_Ferns and Allies</th>\n",
       "      <th>Group_Fishes</th>\n",
       "      <th>...</th>\n",
       "      <th>State_OR</th>\n",
       "      <th>State_PA</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5697</th>\n",
       "      <td>35532</td>\n",
       "      <td>4848</td>\n",
       "      <td>363</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6796</th>\n",
       "      <td>30031</td>\n",
       "      <td>19542</td>\n",
       "      <td>359</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9576</th>\n",
       "      <td>167188</td>\n",
       "      <td>62425</td>\n",
       "      <td>363</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>34447</td>\n",
       "      <td>17461</td>\n",
       "      <td>365</td>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3766</th>\n",
       "      <td>36809</td>\n",
       "      <td>24768</td>\n",
       "      <td>315</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total Land Area (Thousands of Acres)  \\\n",
       "5697                                 35532   \n",
       "6796                                 30031   \n",
       "9576                                167188   \n",
       "3518                                 34447   \n",
       "3766                                 36809   \n",
       "\n",
       "      Forest Land Area (Thousands of Acres)  Days with AQI  Good Days  \\\n",
       "5697                                   4848            363        277   \n",
       "6796                                  19542            359        273   \n",
       "9576                                  62425            363        284   \n",
       "3518                                  17461            365        324   \n",
       "3766                                  24768            315        247   \n",
       "\n",
       "      Group_Amphibians  Group_Birds  Group_Clams  Group_Crustaceans  \\\n",
       "5697                 0            0            0                  0   \n",
       "6796                 0            0            0                  0   \n",
       "9576                 0            0            0                  0   \n",
       "3518                 0            0            0                  0   \n",
       "3766                 0            1            0                  0   \n",
       "\n",
       "      Group_Ferns and Allies  Group_Fishes    ...     State_OR  State_PA  \\\n",
       "5697                       0             0    ...            0         0   \n",
       "6796                       0             0    ...            0         0   \n",
       "9576                       0             0    ...            0         0   \n",
       "3518                       0             0    ...            0         0   \n",
       "3766                       0             0    ...            0         0   \n",
       "\n",
       "      State_SC  State_TN  State_TX  State_UT  State_VA  State_WA  State_WV  \\\n",
       "5697         0         0         0         0         0         0         0   \n",
       "6796         0         0         0         0         0         0         0   \n",
       "9576         0         0         1         0         0         0         0   \n",
       "3518         0         0         0         0         0         0         0   \n",
       "3766         0         0         0         0         0         0         0   \n",
       "\n",
       "      State_WY  \n",
       "5697         0  \n",
       "6796         0  \n",
       "9576         0  \n",
       "3518         0  \n",
       "3766         0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_categorical_cols = ['Total Land Area (Thousands of Acres)',\n",
    "                        'Forest Land Area (Thousands of Acres)',\n",
    "                        'Days with AQI',\n",
    "                        'Good Days']\n",
    "categorical_cols     = ['Group_Amphibians', 'Group_Birds', 'Group_Clams', 'Group_Crustaceans',\n",
    "                        'Group_Ferns and Allies', 'Group_Fishes', 'Group_Flowering Plants',\n",
    "                        'Group_Insects', 'Group_Mammals', 'Group_Reptiles', 'Group_Snails',\n",
    "                        'VIP_I', 'VIP_P', 'VIP_V', 'State_AL', 'State_AR', 'State_AZ',\n",
    "                        'State_CA', 'State_CO', 'State_FL', 'State_GA', 'State_HI', 'State_ID',\n",
    "                        'State_IL', 'State_IN', 'State_KY', 'State_MO', 'State_MS', 'State_NC',\n",
    "                        'State_NM', 'State_NY', 'State_OR', 'State_PA', 'State_SC', 'State_TN',\n",
    "                        'State_TX', 'State_UT', 'State_VA', 'State_WA', 'State_WV', 'State_WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "      <th>Days with AQI</th>\n",
       "      <th>Good Days</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>Group_Crustaceans</th>\n",
       "      <th>Group_Ferns and Allies</th>\n",
       "      <th>Group_Fishes</th>\n",
       "      <th>...</th>\n",
       "      <th>State_OR</th>\n",
       "      <th>State_PA</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5697</th>\n",
       "      <td>0.095546</td>\n",
       "      <td>0.035154</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6796</th>\n",
       "      <td>0.080473</td>\n",
       "      <td>0.149738</td>\n",
       "      <td>0.968421</td>\n",
       "      <td>0.633929</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9576</th>\n",
       "      <td>0.456293</td>\n",
       "      <td>0.484143</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.683036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>0.092573</td>\n",
       "      <td>0.133511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3766</th>\n",
       "      <td>0.099045</td>\n",
       "      <td>0.190491</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total Land Area (Thousands of Acres)  \\\n",
       "5697                              0.095546   \n",
       "6796                              0.080473   \n",
       "9576                              0.456293   \n",
       "3518                              0.092573   \n",
       "3766                              0.099045   \n",
       "\n",
       "      Forest Land Area (Thousands of Acres)  Days with AQI  Good Days  \\\n",
       "5697                               0.035154       0.989474   0.651786   \n",
       "6796                               0.149738       0.968421   0.633929   \n",
       "9576                               0.484143       0.989474   0.683036   \n",
       "3518                               0.133511       1.000000   0.861607   \n",
       "3766                               0.190491       0.736842   0.517857   \n",
       "\n",
       "      Group_Amphibians  Group_Birds  Group_Clams  Group_Crustaceans  \\\n",
       "5697                 0            0            0                  0   \n",
       "6796                 0            0            0                  0   \n",
       "9576                 0            0            0                  0   \n",
       "3518                 0            0            0                  0   \n",
       "3766                 0            1            0                  0   \n",
       "\n",
       "      Group_Ferns and Allies  Group_Fishes    ...     State_OR  State_PA  \\\n",
       "5697                       0             0    ...            0         0   \n",
       "6796                       0             0    ...            0         0   \n",
       "9576                       0             0    ...            0         0   \n",
       "3518                       0             0    ...            0         0   \n",
       "3766                       0             0    ...            0         0   \n",
       "\n",
       "      State_SC  State_TN  State_TX  State_UT  State_VA  State_WA  State_WV  \\\n",
       "5697         0         0         0         0         0         0         0   \n",
       "6796         0         0         0         0         0         0         0   \n",
       "9576         0         0         1         0         0         0         0   \n",
       "3518         0         0         0         0         0         0         0   \n",
       "3766         0         0         0         0         0         0         0   \n",
       "\n",
       "      State_WY  \n",
       "5697         0  \n",
       "6796         0  \n",
       "9576         0  \n",
       "3518         0  \n",
       "3766         0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler                        = MinMaxScaler()\n",
    "X_train[non_categorical_cols] = scaler.fit_transform(X_train[non_categorical_cols])\n",
    "X_test[non_categorical_cols]  = scaler.transform(X_test[non_categorical_cols])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model Hyper Parameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter grid search for all classifiers\n",
    "classifiers = []\n",
    "\n",
    "# dummy classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_dummy_classifier(dict(\n",
    "        strategy=['most_frequent','stratified'])))\n",
    "\n",
    "# logistic regression\n",
    "classifiers.append(\n",
    "    clf.grid_search_logistic_regression(dict(\n",
    "        C=[1e-2,1e0,1e2,1e6,1e12],\n",
    "        penalty=['l1', 'l2'],\n",
    "        fit_intercept=[True, False],\n",
    "        multi_class=['ovr'],\n",
    "        solver=['liblinear'])))\n",
    "\n",
    "# multinomial naive bayes classifer\n",
    "classifiers.append(\n",
    "    clf.grid_search_multinomial_nb(dict(\n",
    "        alpha=[0.0,1.0],\n",
    "        fit_prior=[True])))\n",
    "\n",
    "# k nearest neighbors classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_k_neighbors_classifier(dict(\n",
    "#        n_neighbors=[5,11],\n",
    "#        weights=['uniform', 'distance'],\n",
    "        algorithm=['ball_tree','kd_tree'],\n",
    "        leaf_size=[100,200])))\n",
    "\n",
    "# decision tree classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_decision_tree_classifier(dict(\n",
    "        criterion=['gini','entropy'],\n",
    "#        max_depth=[6,8],\n",
    "#        min_samples_leaf=[20,50,100],\n",
    "#        max_features=[20,30,40],\n",
    "        min_impurity_decrease=[0.01,0.03,0.05])))\n",
    "\n",
    "# random forest classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_random_forest_classifier(dict(\n",
    "        n_estimators=[100,200,300],\n",
    "#        max_depth=[2,3,4],\n",
    "#        min_samples_leaf=[100,200],\n",
    "#        max_features=[10,20],\n",
    "        min_impurity_decrease=[0.01,0.03,0.05])))\n",
    "\n",
    "# ada boost classifer\n",
    "classifiers.append(\n",
    "    clf.grid_search_ada_boost_classifier(dict(\n",
    "        n_estimators=[100,200,300],\n",
    "        learning_rate=[0.5,1.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Training Model 1:  Fish & Wildlife Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0872s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:   23.5s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   28.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Decision Tree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0784s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Random Forest\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:    9.9s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Ada Boost\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:   34.9s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   39.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.613749</td>\n",
       "      <td>0.616156</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.616473</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.765198</td>\n",
       "      <td>0.585528</td>\n",
       "      <td>0.765198</td>\n",
       "      <td>0.663414</td>\n",
       "      <td>[[1737, 0, 0], [155, 0, 0], [378, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.773273</td>\n",
       "      <td>0.716080</td>\n",
       "      <td>0.773273</td>\n",
       "      <td>0.688290</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787044</td>\n",
       "      <td>0.725240</td>\n",
       "      <td>0.787044</td>\n",
       "      <td>0.722972</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787044</td>\n",
       "      <td>0.725240</td>\n",
       "      <td>0.787044</td>\n",
       "      <td>0.722972</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787044</td>\n",
       "      <td>0.725240</td>\n",
       "      <td>0.787044</td>\n",
       "      <td>0.722972</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787044</td>\n",
       "      <td>0.725240</td>\n",
       "      <td>0.787044</td>\n",
       "      <td>0.722972</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.794714</td>\n",
       "      <td>0.736215</td>\n",
       "      <td>0.794714</td>\n",
       "      <td>0.734271</td>\n",
       "      <td>[[1717, 1, 19], [146, 0, 9], [290, 1, 87]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.773824</td>\n",
       "      <td>0.743942</td>\n",
       "      <td>0.773824</td>\n",
       "      <td>0.729939</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.774154</td>\n",
       "      <td>0.745340</td>\n",
       "      <td>0.774154</td>\n",
       "      <td>0.730149</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.778414</td>\n",
       "      <td>0.760026</td>\n",
       "      <td>0.778414</td>\n",
       "      <td>0.740855</td>\n",
       "      <td>[[1656, 62, 19], [122, 24, 9], [270, 21, 87]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.750468</td>\n",
       "      <td>0.690493</td>\n",
       "      <td>0.750468</td>\n",
       "      <td>0.706998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.735265</td>\n",
       "      <td>0.703243</td>\n",
       "      <td>0.735265</td>\n",
       "      <td>0.708997</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.749807</td>\n",
       "      <td>0.688833</td>\n",
       "      <td>0.749807</td>\n",
       "      <td>0.706546</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.735045</td>\n",
       "      <td>0.702072</td>\n",
       "      <td>0.735045</td>\n",
       "      <td>0.708865</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>0.713093</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>0.712318</td>\n",
       "      <td>[[1446, 6, 285], [127, 3, 25], [174, 5, 199]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.716495</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.717614</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.716495</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.717614</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.716495</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.717614</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.767324</td>\n",
       "      <td>0.608086</td>\n",
       "      <td>0.767324</td>\n",
       "      <td>0.672241</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.790308</td>\n",
       "      <td>0.730097</td>\n",
       "      <td>0.790308</td>\n",
       "      <td>0.725662</td>\n",
       "      <td>[[1719, 0, 18], [147, 0, 8], [303, 0, 75]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.765198</td>\n",
       "      <td>0.585528</td>\n",
       "      <td>0.765198</td>\n",
       "      <td>0.663414</td>\n",
       "      <td>[[1737, 0, 0], [155, 0, 0], [378, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732734</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723252</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787595</td>\n",
       "      <td>0.759126</td>\n",
       "      <td>0.787595</td>\n",
       "      <td>0.724317</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787595</td>\n",
       "      <td>0.759126</td>\n",
       "      <td>0.787595</td>\n",
       "      <td>0.724317</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787926</td>\n",
       "      <td>0.762885</td>\n",
       "      <td>0.787926</td>\n",
       "      <td>0.725268</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787595</td>\n",
       "      <td>0.759126</td>\n",
       "      <td>0.787595</td>\n",
       "      <td>0.724317</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.787595</td>\n",
       "      <td>0.758994</td>\n",
       "      <td>0.787595</td>\n",
       "      <td>0.724420</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.794714</td>\n",
       "      <td>0.736215</td>\n",
       "      <td>0.794714</td>\n",
       "      <td>0.734271</td>\n",
       "      <td>[[1717, 1, 19], [146, 0, 9], [290, 1, 87]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data               Classifier  \\\n",
       "0   FWS                    Dummy   \n",
       "1   FWS                    Dummy   \n",
       "2   FWS                    Dummy   \n",
       "3   FWS      Logistic Regression   \n",
       "4   FWS      Logistic Regression   \n",
       "5   FWS      Logistic Regression   \n",
       "6   FWS      Logistic Regression   \n",
       "7   FWS      Logistic Regression   \n",
       "8   FWS      Logistic Regression   \n",
       "9   FWS      Logistic Regression   \n",
       "10  FWS      Logistic Regression   \n",
       "11  FWS      Logistic Regression   \n",
       "12  FWS      Logistic Regression   \n",
       "13  FWS      Logistic Regression   \n",
       "14  FWS      Logistic Regression   \n",
       "15  FWS      Logistic Regression   \n",
       "16  FWS      Logistic Regression   \n",
       "17  FWS      Logistic Regression   \n",
       "18  FWS      Logistic Regression   \n",
       "19  FWS      Logistic Regression   \n",
       "20  FWS      Logistic Regression   \n",
       "21  FWS      Logistic Regression   \n",
       "22  FWS      Logistic Regression   \n",
       "23  FWS      Logistic Regression   \n",
       "24  FWS  Multinomial Naive Bayes   \n",
       "25  FWS  Multinomial Naive Bayes   \n",
       "26  FWS  Multinomial Naive Bayes   \n",
       "27  FWS      K Nearest Neighbors   \n",
       "28  FWS      K Nearest Neighbors   \n",
       "29  FWS      K Nearest Neighbors   \n",
       "30  FWS      K Nearest Neighbors   \n",
       "31  FWS      K Nearest Neighbors   \n",
       "32  FWS            Decision Tree   \n",
       "33  FWS            Decision Tree   \n",
       "34  FWS            Decision Tree   \n",
       "35  FWS            Decision Tree   \n",
       "36  FWS            Decision Tree   \n",
       "37  FWS            Decision Tree   \n",
       "38  FWS            Decision Tree   \n",
       "39  FWS            Random Forest   \n",
       "40  FWS            Random Forest   \n",
       "41  FWS            Random Forest   \n",
       "42  FWS            Random Forest   \n",
       "43  FWS            Random Forest   \n",
       "44  FWS            Random Forest   \n",
       "45  FWS            Random Forest   \n",
       "46  FWS            Random Forest   \n",
       "47  FWS            Random Forest   \n",
       "48  FWS            Random Forest   \n",
       "49  FWS                Ada Boost   \n",
       "50  FWS                Ada Boost   \n",
       "51  FWS                Ada Boost   \n",
       "52  FWS                Ada Boost   \n",
       "53  FWS                Ada Boost   \n",
       "54  FWS                Ada Boost   \n",
       "55  FWS                Ada Boost   \n",
       "\n",
       "                                           Parameters  Split  Accuracy  \\\n",
       "0                       {'strategy': 'most_frequent'}  Train  0.764349   \n",
       "1                          {'strategy': 'stratified'}  Train  0.613749   \n",
       "2                       {'strategy': 'most_frequent'}   Test  0.765198   \n",
       "3   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.764349   \n",
       "4   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.764349   \n",
       "5   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.764349   \n",
       "6   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.773273   \n",
       "7   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.787044   \n",
       "8   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.787044   \n",
       "9   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.787044   \n",
       "10  {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.787044   \n",
       "11  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.787265   \n",
       "12  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.787265   \n",
       "13  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.787265   \n",
       "14  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.787265   \n",
       "15  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.787265   \n",
       "16  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.787265   \n",
       "17  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.787265   \n",
       "18  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.787265   \n",
       "19  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.787265   \n",
       "20  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.787265   \n",
       "21  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.787265   \n",
       "22  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.787265   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...   Test  0.794714   \n",
       "24                  {'alpha': 0.0, 'fit_prior': True}  Train  0.773824   \n",
       "25                  {'alpha': 1.0, 'fit_prior': True}  Train  0.774154   \n",
       "26                  {'alpha': 1.0, 'fit_prior': True}   Test  0.778414   \n",
       "27       {'algorithm': 'ball_tree', 'leaf_size': 100}  Train  0.750468   \n",
       "28       {'algorithm': 'ball_tree', 'leaf_size': 200}  Train  0.735265   \n",
       "29         {'algorithm': 'kd_tree', 'leaf_size': 100}  Train  0.749807   \n",
       "30         {'algorithm': 'kd_tree', 'leaf_size': 200}  Train  0.735045   \n",
       "31       {'algorithm': 'ball_tree', 'leaf_size': 200}   Test  0.725991   \n",
       "32  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.784400   \n",
       "33  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.764349   \n",
       "34  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.764349   \n",
       "35  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.784400   \n",
       "36  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.784400   \n",
       "37  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.767324   \n",
       "38  {'criterion': 'gini', 'min_impurity_decrease':...   Test  0.790308   \n",
       "39  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.764349   \n",
       "40  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.764349   \n",
       "41  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.764349   \n",
       "42  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.764349   \n",
       "43  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.764349   \n",
       "44  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.764349   \n",
       "45  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.764349   \n",
       "46  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.764349   \n",
       "47  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.764349   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...   Test  0.765198   \n",
       "49        {'learning_rate': 0.5, 'n_estimators': 100}  Train  0.787265   \n",
       "50        {'learning_rate': 0.5, 'n_estimators': 200}  Train  0.787595   \n",
       "51        {'learning_rate': 0.5, 'n_estimators': 300}  Train  0.787595   \n",
       "52        {'learning_rate': 1.0, 'n_estimators': 100}  Train  0.787926   \n",
       "53        {'learning_rate': 1.0, 'n_estimators': 200}  Train  0.787595   \n",
       "54        {'learning_rate': 1.0, 'n_estimators': 300}  Train  0.787595   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 100}   Test  0.794714   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "0    0.584230  0.764349  0.662261   \n",
       "1    0.616156  0.620579  0.616473   \n",
       "2    0.585528  0.765198  0.663414   \n",
       "3    0.584230  0.764349  0.662261   \n",
       "4    0.584230  0.764349  0.662261   \n",
       "5    0.584230  0.764349  0.662261   \n",
       "6    0.716080  0.773273  0.688290   \n",
       "7    0.725240  0.787044  0.722972   \n",
       "8    0.725240  0.787044  0.722972   \n",
       "9    0.725240  0.787044  0.722972   \n",
       "10   0.725240  0.787044  0.722972   \n",
       "11   0.732602  0.787265  0.723354   \n",
       "12   0.732602  0.787265  0.723354   \n",
       "13   0.732602  0.787265  0.723354   \n",
       "14   0.732602  0.787265  0.723354   \n",
       "15   0.732602  0.787265  0.723354   \n",
       "16   0.732602  0.787265  0.723354   \n",
       "17   0.732602  0.787265  0.723354   \n",
       "18   0.732602  0.787265  0.723354   \n",
       "19   0.732602  0.787265  0.723354   \n",
       "20   0.732602  0.787265  0.723354   \n",
       "21   0.732602  0.787265  0.723354   \n",
       "22   0.732602  0.787265  0.723354   \n",
       "23   0.736215  0.794714  0.734271   \n",
       "24   0.743942  0.773824  0.729939   \n",
       "25   0.745340  0.774154  0.730149   \n",
       "26   0.760026  0.778414  0.740855   \n",
       "27   0.690493  0.750468  0.706998   \n",
       "28   0.703243  0.735265  0.708997   \n",
       "29   0.688833  0.749807  0.706546   \n",
       "30   0.702072  0.735045  0.708865   \n",
       "31   0.713093  0.725991  0.712318   \n",
       "32   0.716495  0.784400  0.717614   \n",
       "33   0.584230  0.764349  0.662261   \n",
       "34   0.584230  0.764349  0.662261   \n",
       "35   0.716495  0.784400  0.717614   \n",
       "36   0.716495  0.784400  0.717614   \n",
       "37   0.608086  0.767324  0.672241   \n",
       "38   0.730097  0.790308  0.725662   \n",
       "39   0.584230  0.764349  0.662261   \n",
       "40   0.584230  0.764349  0.662261   \n",
       "41   0.584230  0.764349  0.662261   \n",
       "42   0.584230  0.764349  0.662261   \n",
       "43   0.584230  0.764349  0.662261   \n",
       "44   0.584230  0.764349  0.662261   \n",
       "45   0.584230  0.764349  0.662261   \n",
       "46   0.584230  0.764349  0.662261   \n",
       "47   0.584230  0.764349  0.662261   \n",
       "48   0.585528  0.765198  0.663414   \n",
       "49   0.732734  0.787265  0.723252   \n",
       "50   0.759126  0.787595  0.724317   \n",
       "51   0.759126  0.787595  0.724317   \n",
       "52   0.762885  0.787926  0.725268   \n",
       "53   0.759126  0.787595  0.724317   \n",
       "54   0.758994  0.787595  0.724420   \n",
       "55   0.736215  0.794714  0.734271   \n",
       "\n",
       "                                 Confusion Matrix  \n",
       "0                                             NaN  \n",
       "1                                             NaN  \n",
       "2        [[1737, 0, 0], [155, 0, 0], [378, 0, 0]]  \n",
       "3                                             NaN  \n",
       "4                                             NaN  \n",
       "5                                             NaN  \n",
       "6                                             NaN  \n",
       "7                                             NaN  \n",
       "8                                             NaN  \n",
       "9                                             NaN  \n",
       "10                                            NaN  \n",
       "11                                            NaN  \n",
       "12                                            NaN  \n",
       "13                                            NaN  \n",
       "14                                            NaN  \n",
       "15                                            NaN  \n",
       "16                                            NaN  \n",
       "17                                            NaN  \n",
       "18                                            NaN  \n",
       "19                                            NaN  \n",
       "20                                            NaN  \n",
       "21                                            NaN  \n",
       "22                                            NaN  \n",
       "23     [[1717, 1, 19], [146, 0, 9], [290, 1, 87]]  \n",
       "24                                            NaN  \n",
       "25                                            NaN  \n",
       "26  [[1656, 62, 19], [122, 24, 9], [270, 21, 87]]  \n",
       "27                                            NaN  \n",
       "28                                            NaN  \n",
       "29                                            NaN  \n",
       "30                                            NaN  \n",
       "31  [[1446, 6, 285], [127, 3, 25], [174, 5, 199]]  \n",
       "32                                            NaN  \n",
       "33                                            NaN  \n",
       "34                                            NaN  \n",
       "35                                            NaN  \n",
       "36                                            NaN  \n",
       "37                                            NaN  \n",
       "38     [[1719, 0, 18], [147, 0, 8], [303, 0, 75]]  \n",
       "39                                            NaN  \n",
       "40                                            NaN  \n",
       "41                                            NaN  \n",
       "42                                            NaN  \n",
       "43                                            NaN  \n",
       "44                                            NaN  \n",
       "45                                            NaN  \n",
       "46                                            NaN  \n",
       "47                                            NaN  \n",
       "48       [[1737, 0, 0], [155, 0, 0], [378, 0, 0]]  \n",
       "49                                            NaN  \n",
       "50                                            NaN  \n",
       "51                                            NaN  \n",
       "52                                            NaN  \n",
       "53                                            NaN  \n",
       "54                                            NaN  \n",
       "55     [[1717, 1, 19], [146, 0, 9], [290, 1, 87]]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fws = X_train[categorical_cols]\n",
    "X_test_fws  = X_test[categorical_cols]\n",
    "\n",
    "# run FWS dataset\n",
    "model_fws = clf.fit_predict_measure(\n",
    "    'FWS', X_train_fws, X_test_fws, y_train, y_test, y_labels, classifiers)\n",
    "model_fws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.771907</td>\n",
       "      <td>0.682108</td>\n",
       "      <td>0.772029</td>\n",
       "      <td>0.700848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.026582</td>\n",
       "      <td>0.070284</td>\n",
       "      <td>0.025849</td>\n",
       "      <td>0.030720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.613749</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.616473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.584230</td>\n",
       "      <td>0.764349</td>\n",
       "      <td>0.662261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.781407</td>\n",
       "      <td>0.720867</td>\n",
       "      <td>0.781407</td>\n",
       "      <td>0.720293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.732602</td>\n",
       "      <td>0.787265</td>\n",
       "      <td>0.723354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.794714</td>\n",
       "      <td>0.762885</td>\n",
       "      <td>0.794714</td>\n",
       "      <td>0.740855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall   F1 Score\n",
       "count  56.000000  56.000000  56.000000  56.000000\n",
       "mean    0.771907   0.682108   0.772029   0.700848\n",
       "std     0.026582   0.070284   0.025849   0.030720\n",
       "min     0.613749   0.584230   0.620579   0.616473\n",
       "25%     0.764349   0.584230   0.764349   0.662261\n",
       "50%     0.781407   0.720867   0.781407   0.720293\n",
       "75%     0.787265   0.732602   0.787265   0.723354\n",
       "max     0.794714   0.762885   0.794714   0.740855"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of FWS classifiers (test and training sets)\n",
    "model_fws.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.778414</td>\n",
       "      <td>0.760026</td>\n",
       "      <td>0.778414</td>\n",
       "      <td>0.740855</td>\n",
       "      <td>[[1656, 62, 19], [122, 24, 9], [270, 21, 87]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.794714</td>\n",
       "      <td>0.736215</td>\n",
       "      <td>0.794714</td>\n",
       "      <td>0.734271</td>\n",
       "      <td>[[1717, 1, 19], [146, 0, 9], [290, 1, 87]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.794714</td>\n",
       "      <td>0.736215</td>\n",
       "      <td>0.794714</td>\n",
       "      <td>0.734271</td>\n",
       "      <td>[[1717, 1, 19], [146, 0, 9], [290, 1, 87]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.790308</td>\n",
       "      <td>0.730097</td>\n",
       "      <td>0.790308</td>\n",
       "      <td>0.725662</td>\n",
       "      <td>[[1719, 0, 18], [147, 0, 8], [303, 0, 75]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>0.713093</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>0.712318</td>\n",
       "      <td>[[1446, 6, 285], [127, 3, 25], [174, 5, 199]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.765198</td>\n",
       "      <td>0.585528</td>\n",
       "      <td>0.765198</td>\n",
       "      <td>0.663414</td>\n",
       "      <td>[[1737, 0, 0], [155, 0, 0], [378, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.765198</td>\n",
       "      <td>0.585528</td>\n",
       "      <td>0.765198</td>\n",
       "      <td>0.663414</td>\n",
       "      <td>[[1737, 0, 0], [155, 0, 0], [378, 0, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data               Classifier  \\\n",
       "26  FWS  Multinomial Naive Bayes   \n",
       "23  FWS      Logistic Regression   \n",
       "55  FWS                Ada Boost   \n",
       "38  FWS            Decision Tree   \n",
       "31  FWS      K Nearest Neighbors   \n",
       "2   FWS                    Dummy   \n",
       "48  FWS            Random Forest   \n",
       "\n",
       "                                           Parameters Split  Accuracy  \\\n",
       "26                  {'alpha': 1.0, 'fit_prior': True}  Test  0.778414   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Test  0.794714   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 100}  Test  0.794714   \n",
       "38  {'criterion': 'gini', 'min_impurity_decrease':...  Test  0.790308   \n",
       "31       {'algorithm': 'ball_tree', 'leaf_size': 200}  Test  0.725991   \n",
       "2                       {'strategy': 'most_frequent'}  Test  0.765198   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...  Test  0.765198   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "26   0.760026  0.778414  0.740855   \n",
       "23   0.736215  0.794714  0.734271   \n",
       "55   0.736215  0.794714  0.734271   \n",
       "38   0.730097  0.790308  0.725662   \n",
       "31   0.713093  0.725991  0.712318   \n",
       "2    0.585528  0.765198  0.663414   \n",
       "48   0.585528  0.765198  0.663414   \n",
       "\n",
       "                                 Confusion Matrix  \n",
       "26  [[1656, 62, 19], [122, 24, 9], [270, 21, 87]]  \n",
       "23     [[1717, 1, 19], [146, 0, 9], [290, 1, 87]]  \n",
       "55     [[1717, 1, 19], [146, 0, 9], [290, 1, 87]]  \n",
       "38     [[1719, 0, 18], [147, 0, 8], [303, 0, 75]]  \n",
       "31  [[1446, 6, 285], [127, 3, 25], [174, 5, 199]]  \n",
       "2        [[1737, 0, 0], [155, 0, 0], [378, 0, 0]]  \n",
       "48       [[1737, 0, 0], [155, 0, 0], [378, 0, 0]]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators of FWS dataset\n",
    "model_fws_test = model_fws[model_fws['Split'] == 'Test']\n",
    "model_fws_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance with SMOTENC Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train Normal</th>\n",
       "      <th>Test Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Endangered</th>\n",
       "      <td>6938</td>\n",
       "      <td>378</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Listed</th>\n",
       "      <td>6938</td>\n",
       "      <td>1737</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.765198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threatened</th>\n",
       "      <td>6938</td>\n",
       "      <td>155</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.068282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>20814</td>\n",
       "      <td>2270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Train  Test  Train Normal  Test Normal\n",
       "Endangered   6938   378      0.333333     0.166520\n",
       "Not Listed   6938  1737      0.333333     0.765198\n",
       "Threatened   6938   155      0.333333     0.068282\n",
       "Total       20814  2270      1.000000     1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balance classes with SMOTENC oversampling\n",
    "smote = SMOTENC(categorical_features=list(range(4,len(X_train.columns))))\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "X_train_smote = pd.DataFrame(X_train_smote, columns=X_train.columns)\n",
    "y_train_smote = pd.Series(y_train_smote)\n",
    "\n",
    "# balanced data set statistics\n",
    "smote_sets = pd.DataFrame({'Train':        y_train_smote.value_counts(),\n",
    "                           'Test':         y_test.value_counts(),\n",
    "                           'Train Normal': y_train_smote.value_counts() / y_train_smote.count(),\n",
    "                           'Test Normal':  y_test.value_counts()        / y_test.count()})\n",
    "\n",
    "smote_sets.loc['Total'] = smote_sets.sum().astype(int)\n",
    "smote_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "      <th>Days with AQI</th>\n",
       "      <th>Good Days</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>Group_Crustaceans</th>\n",
       "      <th>Group_Ferns and Allies</th>\n",
       "      <th>Group_Fishes</th>\n",
       "      <th>...</th>\n",
       "      <th>State_OR</th>\n",
       "      <th>State_PA</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "      <td>20814.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.133817</td>\n",
       "      <td>0.148452</td>\n",
       "      <td>0.924964</td>\n",
       "      <td>0.634465</td>\n",
       "      <td>0.011290</td>\n",
       "      <td>0.078649</td>\n",
       "      <td>0.090852</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.074853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032622</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.034688</td>\n",
       "      <td>0.040742</td>\n",
       "      <td>0.026521</td>\n",
       "      <td>0.027097</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.006918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.130731</td>\n",
       "      <td>0.129089</td>\n",
       "      <td>0.184102</td>\n",
       "      <td>0.234841</td>\n",
       "      <td>0.105658</td>\n",
       "      <td>0.269197</td>\n",
       "      <td>0.287406</td>\n",
       "      <td>0.099704</td>\n",
       "      <td>0.095603</td>\n",
       "      <td>0.263161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177650</td>\n",
       "      <td>0.078785</td>\n",
       "      <td>0.107638</td>\n",
       "      <td>0.182993</td>\n",
       "      <td>0.197696</td>\n",
       "      <td>0.160681</td>\n",
       "      <td>0.162370</td>\n",
       "      <td>0.134400</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.082891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.067439</td>\n",
       "      <td>0.084445</td>\n",
       "      <td>0.952632</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.092573</td>\n",
       "      <td>0.135527</td>\n",
       "      <td>0.984211</td>\n",
       "      <td>0.638393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.179938</td>\n",
       "      <td>0.190491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.783071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total Land Area (Thousands of Acres)  \\\n",
       "count                          20814.000000   \n",
       "mean                               0.133817   \n",
       "std                                0.130731   \n",
       "min                                0.000000   \n",
       "25%                                0.067439   \n",
       "50%                                0.092573   \n",
       "75%                                0.179938   \n",
       "max                                1.000000   \n",
       "\n",
       "       Forest Land Area (Thousands of Acres)  Days with AQI     Good Days  \\\n",
       "count                           20814.000000   20814.000000  20814.000000   \n",
       "mean                                0.148452       0.924964      0.634465   \n",
       "std                                 0.129089       0.184102      0.234841   \n",
       "min                                 0.000000       0.000000      0.000000   \n",
       "25%                                 0.084445       0.952632      0.517857   \n",
       "50%                                 0.135527       0.984211      0.638393   \n",
       "75%                                 0.190491       1.000000      0.783071   \n",
       "max                                 1.000000       1.000000      1.000000   \n",
       "\n",
       "       Group_Amphibians   Group_Birds   Group_Clams  Group_Crustaceans  \\\n",
       "count      20814.000000  20814.000000  20814.000000       20814.000000   \n",
       "mean           0.011290      0.078649      0.090852           0.010041   \n",
       "std            0.105658      0.269197      0.287406           0.099704   \n",
       "min            0.000000      0.000000      0.000000           0.000000   \n",
       "25%            0.000000      0.000000      0.000000           0.000000   \n",
       "50%            0.000000      0.000000      0.000000           0.000000   \n",
       "75%            0.000000      0.000000      0.000000           0.000000   \n",
       "max            1.000000      1.000000      1.000000           1.000000   \n",
       "\n",
       "       Group_Ferns and Allies  Group_Fishes      ...           State_OR  \\\n",
       "count            20814.000000  20814.000000      ...       20814.000000   \n",
       "mean                 0.009225      0.074853      ...           0.032622   \n",
       "std                  0.095603      0.263161      ...           0.177650   \n",
       "min                  0.000000      0.000000      ...           0.000000   \n",
       "25%                  0.000000      0.000000      ...           0.000000   \n",
       "50%                  0.000000      0.000000      ...           0.000000   \n",
       "75%                  0.000000      0.000000      ...           0.000000   \n",
       "max                  1.000000      1.000000      ...           1.000000   \n",
       "\n",
       "           State_PA      State_SC      State_TN      State_TX      State_UT  \\\n",
       "count  20814.000000  20814.000000  20814.000000  20814.000000  20814.000000   \n",
       "mean       0.006246      0.011723      0.034688      0.040742      0.026521   \n",
       "std        0.078785      0.107638      0.182993      0.197696      0.160681   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           State_VA      State_WA      State_WV      State_WY  \n",
       "count  20814.000000  20814.000000  20814.000000  20814.000000  \n",
       "mean       0.027097      0.018401      0.008120      0.006918  \n",
       "std        0.162370      0.134400      0.089744      0.082891  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000      0.000000  \n",
       "max        1.000000      1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 45 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check categorical features of class-balanced model\n",
    "X_train_smote.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1e142400>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot comparison of unbalanced and balanced training sets\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16,12))\n",
    "\n",
    "sns.countplot(y_train,       order=y_train.value_counts().index, alpha=0.8, ax = axes[0,0])\n",
    "sns.countplot(y_train_smote, order=y_train.value_counts().index, alpha=0.8, ax = axes[0,1])\n",
    "\n",
    "sns.scatterplot(x=X_train.columns[0],       y=X_train.columns[1],       data=X_train,       ax = axes[1,0])\n",
    "sns.scatterplot(x=X_train_smote.columns[0], y=X_train_smote.columns[1], data=X_train_smote, ax = axes[1,1])\n",
    "\n",
    "sns.scatterplot(x=X_train.columns[2],       y=X_train.columns[3],       data=X_train,       ax = axes[2,0])\n",
    "sns.scatterplot(x=X_train_smote.columns[2], y=X_train_smote.columns[3], data=X_train_smote, ax = axes[2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Training Model 2: Balanced FWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:  1.8min remaining:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Decision Tree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1805s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Random Forest\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:   18.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   19.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Ada Boost\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  1.4min remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.332228</td>\n",
       "      <td>0.334066</td>\n",
       "      <td>0.332228</td>\n",
       "      <td>0.328899</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.344934</td>\n",
       "      <td>0.627962</td>\n",
       "      <td>0.344934</td>\n",
       "      <td>0.414476</td>\n",
       "      <td>[[607, 563, 567], [58, 45, 52], [116, 131, 131]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.547084</td>\n",
       "      <td>0.570674</td>\n",
       "      <td>0.547084</td>\n",
       "      <td>0.544080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>0.573635</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>0.549465</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.546315</td>\n",
       "      <td>0.569022</td>\n",
       "      <td>0.546315</td>\n",
       "      <td>0.543277</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.549966</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.549966</td>\n",
       "      <td>0.547600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572307</td>\n",
       "      <td>0.578990</td>\n",
       "      <td>0.572307</td>\n",
       "      <td>0.571836</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572259</td>\n",
       "      <td>0.578944</td>\n",
       "      <td>0.572259</td>\n",
       "      <td>0.571829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.570722</td>\n",
       "      <td>0.577591</td>\n",
       "      <td>0.570722</td>\n",
       "      <td>0.570245</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571106</td>\n",
       "      <td>0.578012</td>\n",
       "      <td>0.571106</td>\n",
       "      <td>0.570612</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.579258</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.572251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.579258</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.572251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571202</td>\n",
       "      <td>0.577819</td>\n",
       "      <td>0.571202</td>\n",
       "      <td>0.570752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571202</td>\n",
       "      <td>0.577819</td>\n",
       "      <td>0.571202</td>\n",
       "      <td>0.570752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.579258</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.572251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.579258</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.572251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571106</td>\n",
       "      <td>0.577704</td>\n",
       "      <td>0.571106</td>\n",
       "      <td>0.570654</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571106</td>\n",
       "      <td>0.577704</td>\n",
       "      <td>0.571106</td>\n",
       "      <td>0.570654</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.579258</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.572251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.579258</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.572251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571106</td>\n",
       "      <td>0.577704</td>\n",
       "      <td>0.571106</td>\n",
       "      <td>0.570654</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571106</td>\n",
       "      <td>0.577704</td>\n",
       "      <td>0.571106</td>\n",
       "      <td>0.570654</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.561674</td>\n",
       "      <td>0.732050</td>\n",
       "      <td>0.561674</td>\n",
       "      <td>0.616397</td>\n",
       "      <td>[[1002, 438, 297], [61, 75, 19], [100, 80, 198]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.546507</td>\n",
       "      <td>0.561480</td>\n",
       "      <td>0.546507</td>\n",
       "      <td>0.544484</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.546555</td>\n",
       "      <td>0.561464</td>\n",
       "      <td>0.546555</td>\n",
       "      <td>0.544560</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.627313</td>\n",
       "      <td>0.748016</td>\n",
       "      <td>0.627313</td>\n",
       "      <td>0.670724</td>\n",
       "      <td>[[1163, 313, 261], [63, 73, 19], [101, 89, 188]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.423705</td>\n",
       "      <td>0.542384</td>\n",
       "      <td>0.423705</td>\n",
       "      <td>0.354080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.459354</td>\n",
       "      <td>0.577593</td>\n",
       "      <td>0.459354</td>\n",
       "      <td>0.390079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.424186</td>\n",
       "      <td>0.542933</td>\n",
       "      <td>0.424186</td>\n",
       "      <td>0.354060</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.459691</td>\n",
       "      <td>0.577470</td>\n",
       "      <td>0.459691</td>\n",
       "      <td>0.390063</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.730396</td>\n",
       "      <td>0.704923</td>\n",
       "      <td>0.730396</td>\n",
       "      <td>0.714027</td>\n",
       "      <td>[[1470, 14, 253], [132, 3, 20], [187, 6, 185]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.552417</td>\n",
       "      <td>0.584733</td>\n",
       "      <td>0.552417</td>\n",
       "      <td>0.547088</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.711030</td>\n",
       "      <td>[[1267, 323, 147], [65, 80, 10], [108, 90, 180]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.547372</td>\n",
       "      <td>0.572821</td>\n",
       "      <td>0.547372</td>\n",
       "      <td>0.543982</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545642</td>\n",
       "      <td>0.569604</td>\n",
       "      <td>0.545642</td>\n",
       "      <td>0.542641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.455367</td>\n",
       "      <td>0.462533</td>\n",
       "      <td>0.455367</td>\n",
       "      <td>0.401603</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.447007</td>\n",
       "      <td>0.423925</td>\n",
       "      <td>0.447007</td>\n",
       "      <td>0.378632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.439800</td>\n",
       "      <td>0.423355</td>\n",
       "      <td>0.439800</td>\n",
       "      <td>0.367978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.642291</td>\n",
       "      <td>0.755409</td>\n",
       "      <td>0.642291</td>\n",
       "      <td>0.683682</td>\n",
       "      <td>[[1194, 323, 220], [65, 80, 10], [104, 90, 184]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.568704</td>\n",
       "      <td>0.577952</td>\n",
       "      <td>0.568704</td>\n",
       "      <td>0.567771</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.568127</td>\n",
       "      <td>0.575836</td>\n",
       "      <td>0.568127</td>\n",
       "      <td>0.567385</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.569809</td>\n",
       "      <td>0.577283</td>\n",
       "      <td>0.569809</td>\n",
       "      <td>0.569178</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571154</td>\n",
       "      <td>0.578047</td>\n",
       "      <td>0.571154</td>\n",
       "      <td>0.570715</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572980</td>\n",
       "      <td>0.579057</td>\n",
       "      <td>0.572980</td>\n",
       "      <td>0.572658</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571490</td>\n",
       "      <td>0.576975</td>\n",
       "      <td>0.571490</td>\n",
       "      <td>0.571235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.537885</td>\n",
       "      <td>0.737800</td>\n",
       "      <td>0.537885</td>\n",
       "      <td>0.597876</td>\n",
       "      <td>[[938, 500, 299], [52, 81, 22], [89, 87, 202]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data               Classifier  \\\n",
       "0   SMOTE_FWS                    Dummy   \n",
       "1   SMOTE_FWS                    Dummy   \n",
       "2   SMOTE_FWS                    Dummy   \n",
       "3   SMOTE_FWS      Logistic Regression   \n",
       "4   SMOTE_FWS      Logistic Regression   \n",
       "5   SMOTE_FWS      Logistic Regression   \n",
       "6   SMOTE_FWS      Logistic Regression   \n",
       "7   SMOTE_FWS      Logistic Regression   \n",
       "8   SMOTE_FWS      Logistic Regression   \n",
       "9   SMOTE_FWS      Logistic Regression   \n",
       "10  SMOTE_FWS      Logistic Regression   \n",
       "11  SMOTE_FWS      Logistic Regression   \n",
       "12  SMOTE_FWS      Logistic Regression   \n",
       "13  SMOTE_FWS      Logistic Regression   \n",
       "14  SMOTE_FWS      Logistic Regression   \n",
       "15  SMOTE_FWS      Logistic Regression   \n",
       "16  SMOTE_FWS      Logistic Regression   \n",
       "17  SMOTE_FWS      Logistic Regression   \n",
       "18  SMOTE_FWS      Logistic Regression   \n",
       "19  SMOTE_FWS      Logistic Regression   \n",
       "20  SMOTE_FWS      Logistic Regression   \n",
       "21  SMOTE_FWS      Logistic Regression   \n",
       "22  SMOTE_FWS      Logistic Regression   \n",
       "23  SMOTE_FWS      Logistic Regression   \n",
       "24  SMOTE_FWS  Multinomial Naive Bayes   \n",
       "25  SMOTE_FWS  Multinomial Naive Bayes   \n",
       "26  SMOTE_FWS  Multinomial Naive Bayes   \n",
       "27  SMOTE_FWS      K Nearest Neighbors   \n",
       "28  SMOTE_FWS      K Nearest Neighbors   \n",
       "29  SMOTE_FWS      K Nearest Neighbors   \n",
       "30  SMOTE_FWS      K Nearest Neighbors   \n",
       "31  SMOTE_FWS      K Nearest Neighbors   \n",
       "32  SMOTE_FWS            Decision Tree   \n",
       "33  SMOTE_FWS            Decision Tree   \n",
       "34  SMOTE_FWS            Decision Tree   \n",
       "35  SMOTE_FWS            Decision Tree   \n",
       "36  SMOTE_FWS            Decision Tree   \n",
       "37  SMOTE_FWS            Decision Tree   \n",
       "38  SMOTE_FWS            Decision Tree   \n",
       "39  SMOTE_FWS            Random Forest   \n",
       "40  SMOTE_FWS            Random Forest   \n",
       "41  SMOTE_FWS            Random Forest   \n",
       "42  SMOTE_FWS            Random Forest   \n",
       "43  SMOTE_FWS            Random Forest   \n",
       "44  SMOTE_FWS            Random Forest   \n",
       "45  SMOTE_FWS            Random Forest   \n",
       "46  SMOTE_FWS            Random Forest   \n",
       "47  SMOTE_FWS            Random Forest   \n",
       "48  SMOTE_FWS            Random Forest   \n",
       "49  SMOTE_FWS                Ada Boost   \n",
       "50  SMOTE_FWS                Ada Boost   \n",
       "51  SMOTE_FWS                Ada Boost   \n",
       "52  SMOTE_FWS                Ada Boost   \n",
       "53  SMOTE_FWS                Ada Boost   \n",
       "54  SMOTE_FWS                Ada Boost   \n",
       "55  SMOTE_FWS                Ada Boost   \n",
       "\n",
       "                                           Parameters  Split  Accuracy  \\\n",
       "0                       {'strategy': 'most_frequent'}  Train  0.333333   \n",
       "1                          {'strategy': 'stratified'}  Train  0.332228   \n",
       "2                          {'strategy': 'stratified'}   Test  0.344934   \n",
       "3   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.547084   \n",
       "4   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.551648   \n",
       "5   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.546315   \n",
       "6   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.549966   \n",
       "7   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.572307   \n",
       "8   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.572259   \n",
       "9   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.570722   \n",
       "10  {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.571106   \n",
       "11  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.572691   \n",
       "12  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.572691   \n",
       "13  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.571202   \n",
       "14  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.571202   \n",
       "15  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.572691   \n",
       "16  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.572691   \n",
       "17  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.571106   \n",
       "18  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.571106   \n",
       "19  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.572691   \n",
       "20  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.572691   \n",
       "21  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.571106   \n",
       "22  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.571106   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...   Test  0.561674   \n",
       "24                  {'alpha': 0.0, 'fit_prior': True}  Train  0.546507   \n",
       "25                  {'alpha': 1.0, 'fit_prior': True}  Train  0.546555   \n",
       "26                  {'alpha': 1.0, 'fit_prior': True}   Test  0.627313   \n",
       "27       {'algorithm': 'ball_tree', 'leaf_size': 100}  Train  0.423705   \n",
       "28       {'algorithm': 'ball_tree', 'leaf_size': 200}  Train  0.459354   \n",
       "29         {'algorithm': 'kd_tree', 'leaf_size': 100}  Train  0.424186   \n",
       "30         {'algorithm': 'kd_tree', 'leaf_size': 200}  Train  0.459691   \n",
       "31       {'algorithm': 'ball_tree', 'leaf_size': 200}   Test  0.730396   \n",
       "32  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.545354   \n",
       "33  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.333333   \n",
       "34  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.333333   \n",
       "35  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.552417   \n",
       "36  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.545354   \n",
       "37  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.545354   \n",
       "38  {'criterion': 'entropy', 'min_impurity_decreas...   Test  0.672687   \n",
       "39  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.547372   \n",
       "40  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.545642   \n",
       "41  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.545354   \n",
       "42  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.455367   \n",
       "43  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.447007   \n",
       "44  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.439800   \n",
       "45  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "46  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "47  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...   Test  0.642291   \n",
       "49        {'learning_rate': 0.5, 'n_estimators': 100}  Train  0.568704   \n",
       "50        {'learning_rate': 0.5, 'n_estimators': 200}  Train  0.568127   \n",
       "51        {'learning_rate': 0.5, 'n_estimators': 300}  Train  0.569809   \n",
       "52        {'learning_rate': 1.0, 'n_estimators': 100}  Train  0.571154   \n",
       "53        {'learning_rate': 1.0, 'n_estimators': 200}  Train  0.572980   \n",
       "54        {'learning_rate': 1.0, 'n_estimators': 300}  Train  0.571490   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 200}   Test  0.537885   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "0    0.111111  0.333333  0.166667   \n",
       "1    0.334066  0.332228  0.328899   \n",
       "2    0.627962  0.344934  0.414476   \n",
       "3    0.570674  0.547084  0.544080   \n",
       "4    0.573635  0.551648  0.549465   \n",
       "5    0.569022  0.546315  0.543277   \n",
       "6    0.571083  0.549966  0.547600   \n",
       "7    0.578990  0.572307  0.571836   \n",
       "8    0.578944  0.572259  0.571829   \n",
       "9    0.577591  0.570722  0.570245   \n",
       "10   0.578012  0.571106  0.570612   \n",
       "11   0.579258  0.572691  0.572251   \n",
       "12   0.579258  0.572691  0.572251   \n",
       "13   0.577819  0.571202  0.570752   \n",
       "14   0.577819  0.571202  0.570752   \n",
       "15   0.579258  0.572691  0.572251   \n",
       "16   0.579258  0.572691  0.572251   \n",
       "17   0.577704  0.571106  0.570654   \n",
       "18   0.577704  0.571106  0.570654   \n",
       "19   0.579258  0.572691  0.572251   \n",
       "20   0.579258  0.572691  0.572251   \n",
       "21   0.577704  0.571106  0.570654   \n",
       "22   0.577704  0.571106  0.570654   \n",
       "23   0.732050  0.561674  0.616397   \n",
       "24   0.561480  0.546507  0.544484   \n",
       "25   0.561464  0.546555  0.544560   \n",
       "26   0.748016  0.627313  0.670724   \n",
       "27   0.542384  0.423705  0.354080   \n",
       "28   0.577593  0.459354  0.390079   \n",
       "29   0.542933  0.424186  0.354060   \n",
       "30   0.577470  0.459691  0.390063   \n",
       "31   0.704923  0.730396  0.714027   \n",
       "32   0.569432  0.545354  0.542361   \n",
       "33   0.111111  0.333333  0.166667   \n",
       "34   0.111111  0.333333  0.166667   \n",
       "35   0.584733  0.552417  0.547088   \n",
       "36   0.569432  0.545354  0.542361   \n",
       "37   0.569432  0.545354  0.542361   \n",
       "38   0.773291  0.672687  0.711030   \n",
       "39   0.572821  0.547372  0.543982   \n",
       "40   0.569604  0.545642  0.542641   \n",
       "41   0.569432  0.545354  0.542361   \n",
       "42   0.462533  0.455367  0.401603   \n",
       "43   0.423925  0.447007  0.378632   \n",
       "44   0.423355  0.439800  0.367978   \n",
       "45   0.111111  0.333333  0.166667   \n",
       "46   0.111111  0.333333  0.166667   \n",
       "47   0.111111  0.333333  0.166667   \n",
       "48   0.755409  0.642291  0.683682   \n",
       "49   0.577952  0.568704  0.567771   \n",
       "50   0.575836  0.568127  0.567385   \n",
       "51   0.577283  0.569809  0.569178   \n",
       "52   0.578047  0.571154  0.570715   \n",
       "53   0.579057  0.572980  0.572658   \n",
       "54   0.576975  0.571490  0.571235   \n",
       "55   0.737800  0.537885  0.597876   \n",
       "\n",
       "                                    Confusion Matrix  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2   [[607, 563, 567], [58, 45, 52], [116, 131, 131]]  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  \n",
       "10                                               NaN  \n",
       "11                                               NaN  \n",
       "12                                               NaN  \n",
       "13                                               NaN  \n",
       "14                                               NaN  \n",
       "15                                               NaN  \n",
       "16                                               NaN  \n",
       "17                                               NaN  \n",
       "18                                               NaN  \n",
       "19                                               NaN  \n",
       "20                                               NaN  \n",
       "21                                               NaN  \n",
       "22                                               NaN  \n",
       "23  [[1002, 438, 297], [61, 75, 19], [100, 80, 198]]  \n",
       "24                                               NaN  \n",
       "25                                               NaN  \n",
       "26  [[1163, 313, 261], [63, 73, 19], [101, 89, 188]]  \n",
       "27                                               NaN  \n",
       "28                                               NaN  \n",
       "29                                               NaN  \n",
       "30                                               NaN  \n",
       "31    [[1470, 14, 253], [132, 3, 20], [187, 6, 185]]  \n",
       "32                                               NaN  \n",
       "33                                               NaN  \n",
       "34                                               NaN  \n",
       "35                                               NaN  \n",
       "36                                               NaN  \n",
       "37                                               NaN  \n",
       "38  [[1267, 323, 147], [65, 80, 10], [108, 90, 180]]  \n",
       "39                                               NaN  \n",
       "40                                               NaN  \n",
       "41                                               NaN  \n",
       "42                                               NaN  \n",
       "43                                               NaN  \n",
       "44                                               NaN  \n",
       "45                                               NaN  \n",
       "46                                               NaN  \n",
       "47                                               NaN  \n",
       "48  [[1194, 323, 220], [65, 80, 10], [104, 90, 184]]  \n",
       "49                                               NaN  \n",
       "50                                               NaN  \n",
       "51                                               NaN  \n",
       "52                                               NaN  \n",
       "53                                               NaN  \n",
       "54                                               NaN  \n",
       "55    [[938, 500, 299], [52, 81, 22], [89, 87, 202]]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote_fws = X_train_smote[categorical_cols]\n",
    "X_test_fws        = X_test[categorical_cols]\n",
    "\n",
    "# run balanced FWS dataset\n",
    "model_smote_fws = clf.fit_predict_measure(\n",
    "    'SMOTE_FWS', X_train_smote_fws, X_test_fws, y_train_smote, y_test, y_labels, classifiers)\n",
    "model_smote_fws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.531488</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.500202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.093470</td>\n",
       "      <td>0.163893</td>\n",
       "      <td>0.093470</td>\n",
       "      <td>0.142998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.332228</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.332228</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.459607</td>\n",
       "      <td>0.567136</td>\n",
       "      <td>0.459607</td>\n",
       "      <td>0.411257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.552032</td>\n",
       "      <td>0.577531</td>\n",
       "      <td>0.552032</td>\n",
       "      <td>0.558425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.571274</td>\n",
       "      <td>0.579107</td>\n",
       "      <td>0.571274</td>\n",
       "      <td>0.571831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.730396</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.730396</td>\n",
       "      <td>0.714027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall   F1 Score\n",
       "count  56.000000  56.000000  56.000000  56.000000\n",
       "mean    0.522233   0.531488   0.522233   0.500202\n",
       "std     0.093470   0.163893   0.093470   0.142998\n",
       "min     0.332228   0.111111   0.332228   0.166667\n",
       "25%     0.459607   0.567136   0.459607   0.411257\n",
       "50%     0.552032   0.577531   0.552032   0.558425\n",
       "75%     0.571274   0.579107   0.571274   0.571831\n",
       "max     0.730396   0.773291   0.730396   0.714027"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of balanced FWS classifiers (test and training sets)\n",
    "model_smote_fws.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.730396</td>\n",
       "      <td>0.704923</td>\n",
       "      <td>0.730396</td>\n",
       "      <td>0.714027</td>\n",
       "      <td>[[1470, 14, 253], [132, 3, 20], [187, 6, 185]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.711030</td>\n",
       "      <td>[[1267, 323, 147], [65, 80, 10], [108, 90, 180]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.642291</td>\n",
       "      <td>0.755409</td>\n",
       "      <td>0.642291</td>\n",
       "      <td>0.683682</td>\n",
       "      <td>[[1194, 323, 220], [65, 80, 10], [104, 90, 184]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.627313</td>\n",
       "      <td>0.748016</td>\n",
       "      <td>0.627313</td>\n",
       "      <td>0.670724</td>\n",
       "      <td>[[1163, 313, 261], [63, 73, 19], [101, 89, 188]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.561674</td>\n",
       "      <td>0.732050</td>\n",
       "      <td>0.561674</td>\n",
       "      <td>0.616397</td>\n",
       "      <td>[[1002, 438, 297], [61, 75, 19], [100, 80, 198]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.537885</td>\n",
       "      <td>0.737800</td>\n",
       "      <td>0.537885</td>\n",
       "      <td>0.597876</td>\n",
       "      <td>[[938, 500, 299], [52, 81, 22], [89, 87, 202]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE_FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.344934</td>\n",
       "      <td>0.627962</td>\n",
       "      <td>0.344934</td>\n",
       "      <td>0.414476</td>\n",
       "      <td>[[607, 563, 567], [58, 45, 52], [116, 131, 131]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Data               Classifier  \\\n",
       "31  SMOTE_FWS      K Nearest Neighbors   \n",
       "38  SMOTE_FWS            Decision Tree   \n",
       "48  SMOTE_FWS            Random Forest   \n",
       "26  SMOTE_FWS  Multinomial Naive Bayes   \n",
       "23  SMOTE_FWS      Logistic Regression   \n",
       "55  SMOTE_FWS                Ada Boost   \n",
       "2   SMOTE_FWS                    Dummy   \n",
       "\n",
       "                                           Parameters Split  Accuracy  \\\n",
       "31       {'algorithm': 'ball_tree', 'leaf_size': 200}  Test  0.730396   \n",
       "38  {'criterion': 'entropy', 'min_impurity_decreas...  Test  0.672687   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...  Test  0.642291   \n",
       "26                  {'alpha': 1.0, 'fit_prior': True}  Test  0.627313   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Test  0.561674   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 200}  Test  0.537885   \n",
       "2                          {'strategy': 'stratified'}  Test  0.344934   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "31   0.704923  0.730396  0.714027   \n",
       "38   0.773291  0.672687  0.711030   \n",
       "48   0.755409  0.642291  0.683682   \n",
       "26   0.748016  0.627313  0.670724   \n",
       "23   0.732050  0.561674  0.616397   \n",
       "55   0.737800  0.537885  0.597876   \n",
       "2    0.627962  0.344934  0.414476   \n",
       "\n",
       "                                    Confusion Matrix  \n",
       "31    [[1470, 14, 253], [132, 3, 20], [187, 6, 185]]  \n",
       "38  [[1267, 323, 147], [65, 80, 10], [108, 90, 180]]  \n",
       "48  [[1194, 323, 220], [65, 80, 10], [104, 90, 184]]  \n",
       "26  [[1163, 313, 261], [63, 73, 19], [101, 89, 188]]  \n",
       "23  [[1002, 438, 297], [61, 75, 19], [100, 80, 198]]  \n",
       "55    [[938, 500, 299], [52, 81, 22], [89, 87, 202]]  \n",
       "2   [[607, 563, 567], [58, 45, 52], [116, 131, 131]]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators of balanced FWS dataset\n",
    "model_smote_fws_test = model_smote_fws[model_smote_fws['Split'] == 'Test']\n",
    "model_smote_fws_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Training Model 3:  Balanced FWS + Forest Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:  2.4min remaining:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Decision Tree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    1.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Random Forest\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:   17.7s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   18.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Ada Boost\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  1.3min remaining:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.336552</td>\n",
       "      <td>0.331588</td>\n",
       "      <td>0.336312</td>\n",
       "      <td>0.336754</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.325551</td>\n",
       "      <td>0.617887</td>\n",
       "      <td>0.325551</td>\n",
       "      <td>0.395385</td>\n",
       "      <td>[[577, 575, 585], [51, 51, 53], [122, 145, 111]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.547084</td>\n",
       "      <td>0.570674</td>\n",
       "      <td>0.547084</td>\n",
       "      <td>0.544080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.550495</td>\n",
       "      <td>0.572209</td>\n",
       "      <td>0.550495</td>\n",
       "      <td>0.548311</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.546315</td>\n",
       "      <td>0.569022</td>\n",
       "      <td>0.546315</td>\n",
       "      <td>0.543277</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.548573</td>\n",
       "      <td>0.570187</td>\n",
       "      <td>0.548573</td>\n",
       "      <td>0.545961</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.574277</td>\n",
       "      <td>0.581002</td>\n",
       "      <td>0.574277</td>\n",
       "      <td>0.573704</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.573748</td>\n",
       "      <td>0.580394</td>\n",
       "      <td>0.573748</td>\n",
       "      <td>0.573182</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572643</td>\n",
       "      <td>0.579650</td>\n",
       "      <td>0.572643</td>\n",
       "      <td>0.572115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572307</td>\n",
       "      <td>0.578982</td>\n",
       "      <td>0.572307</td>\n",
       "      <td>0.571775</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.573028</td>\n",
       "      <td>0.579693</td>\n",
       "      <td>0.573028</td>\n",
       "      <td>0.572599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.573076</td>\n",
       "      <td>0.579730</td>\n",
       "      <td>0.573076</td>\n",
       "      <td>0.572646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.578641</td>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.571306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571827</td>\n",
       "      <td>0.578685</td>\n",
       "      <td>0.571827</td>\n",
       "      <td>0.571351</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.573028</td>\n",
       "      <td>0.579693</td>\n",
       "      <td>0.573028</td>\n",
       "      <td>0.572599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.573028</td>\n",
       "      <td>0.579693</td>\n",
       "      <td>0.573028</td>\n",
       "      <td>0.572599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.578641</td>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.571306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.578641</td>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.571306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.573028</td>\n",
       "      <td>0.579693</td>\n",
       "      <td>0.573028</td>\n",
       "      <td>0.572599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.573028</td>\n",
       "      <td>0.579693</td>\n",
       "      <td>0.573028</td>\n",
       "      <td>0.572599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.578641</td>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.571306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.578641</td>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.571306</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.568722</td>\n",
       "      <td>0.740360</td>\n",
       "      <td>0.568722</td>\n",
       "      <td>0.623458</td>\n",
       "      <td>[[1012, 426, 299], [57, 75, 23], [92, 82, 204]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.546363</td>\n",
       "      <td>0.560368</td>\n",
       "      <td>0.546363</td>\n",
       "      <td>0.544499</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.546363</td>\n",
       "      <td>0.560843</td>\n",
       "      <td>0.546363</td>\n",
       "      <td>0.544466</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.607048</td>\n",
       "      <td>0.743012</td>\n",
       "      <td>0.607048</td>\n",
       "      <td>0.654395</td>\n",
       "      <td>[[1117, 338, 282], [61, 73, 21], [99, 91, 188]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.604401</td>\n",
       "      <td>0.631662</td>\n",
       "      <td>0.604401</td>\n",
       "      <td>0.601186</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.607572</td>\n",
       "      <td>0.635848</td>\n",
       "      <td>0.607572</td>\n",
       "      <td>0.604142</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.604449</td>\n",
       "      <td>0.631472</td>\n",
       "      <td>0.604449</td>\n",
       "      <td>0.601201</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.607764</td>\n",
       "      <td>0.635851</td>\n",
       "      <td>0.607764</td>\n",
       "      <td>0.604342</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.647137</td>\n",
       "      <td>0.712581</td>\n",
       "      <td>0.647137</td>\n",
       "      <td>0.668348</td>\n",
       "      <td>[[1217, 119, 401], [96, 19, 40], [127, 18, 233]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.552417</td>\n",
       "      <td>0.584733</td>\n",
       "      <td>0.552417</td>\n",
       "      <td>0.547088</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.711030</td>\n",
       "      <td>[[1267, 323, 147], [65, 80, 10], [108, 90, 180]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.540357</td>\n",
       "      <td>0.558364</td>\n",
       "      <td>0.540357</td>\n",
       "      <td>0.537119</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.539108</td>\n",
       "      <td>0.557039</td>\n",
       "      <td>0.539108</td>\n",
       "      <td>0.535906</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.539925</td>\n",
       "      <td>0.557387</td>\n",
       "      <td>0.539925</td>\n",
       "      <td>0.536706</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.441962</td>\n",
       "      <td>0.414388</td>\n",
       "      <td>0.441962</td>\n",
       "      <td>0.374810</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.454310</td>\n",
       "      <td>0.462280</td>\n",
       "      <td>0.454310</td>\n",
       "      <td>0.401083</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.455367</td>\n",
       "      <td>0.462533</td>\n",
       "      <td>0.455367</td>\n",
       "      <td>0.401603</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.632159</td>\n",
       "      <td>0.751406</td>\n",
       "      <td>0.632159</td>\n",
       "      <td>0.674733</td>\n",
       "      <td>[[1168, 316, 253], [62, 78, 15], [101, 88, 189]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.565533</td>\n",
       "      <td>0.575038</td>\n",
       "      <td>0.565533</td>\n",
       "      <td>0.564844</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.568175</td>\n",
       "      <td>0.575414</td>\n",
       "      <td>0.568175</td>\n",
       "      <td>0.567780</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.570914</td>\n",
       "      <td>0.577515</td>\n",
       "      <td>0.570914</td>\n",
       "      <td>0.570622</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.570241</td>\n",
       "      <td>0.577216</td>\n",
       "      <td>0.570241</td>\n",
       "      <td>0.569826</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.574902</td>\n",
       "      <td>0.580339</td>\n",
       "      <td>0.574902</td>\n",
       "      <td>0.574408</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.579706</td>\n",
       "      <td>0.584667</td>\n",
       "      <td>0.579706</td>\n",
       "      <td>0.579244</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.577974</td>\n",
       "      <td>0.741410</td>\n",
       "      <td>0.577974</td>\n",
       "      <td>0.631160</td>\n",
       "      <td>[[1036, 405, 296], [58, 74, 23], [93, 83, 202]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Data               Classifier  \\\n",
       "0   SMOTE_FWS_FS                    Dummy   \n",
       "1   SMOTE_FWS_FS                    Dummy   \n",
       "2   SMOTE_FWS_FS                    Dummy   \n",
       "3   SMOTE_FWS_FS      Logistic Regression   \n",
       "4   SMOTE_FWS_FS      Logistic Regression   \n",
       "5   SMOTE_FWS_FS      Logistic Regression   \n",
       "6   SMOTE_FWS_FS      Logistic Regression   \n",
       "7   SMOTE_FWS_FS      Logistic Regression   \n",
       "8   SMOTE_FWS_FS      Logistic Regression   \n",
       "9   SMOTE_FWS_FS      Logistic Regression   \n",
       "10  SMOTE_FWS_FS      Logistic Regression   \n",
       "11  SMOTE_FWS_FS      Logistic Regression   \n",
       "12  SMOTE_FWS_FS      Logistic Regression   \n",
       "13  SMOTE_FWS_FS      Logistic Regression   \n",
       "14  SMOTE_FWS_FS      Logistic Regression   \n",
       "15  SMOTE_FWS_FS      Logistic Regression   \n",
       "16  SMOTE_FWS_FS      Logistic Regression   \n",
       "17  SMOTE_FWS_FS      Logistic Regression   \n",
       "18  SMOTE_FWS_FS      Logistic Regression   \n",
       "19  SMOTE_FWS_FS      Logistic Regression   \n",
       "20  SMOTE_FWS_FS      Logistic Regression   \n",
       "21  SMOTE_FWS_FS      Logistic Regression   \n",
       "22  SMOTE_FWS_FS      Logistic Regression   \n",
       "23  SMOTE_FWS_FS      Logistic Regression   \n",
       "24  SMOTE_FWS_FS  Multinomial Naive Bayes   \n",
       "25  SMOTE_FWS_FS  Multinomial Naive Bayes   \n",
       "26  SMOTE_FWS_FS  Multinomial Naive Bayes   \n",
       "27  SMOTE_FWS_FS      K Nearest Neighbors   \n",
       "28  SMOTE_FWS_FS      K Nearest Neighbors   \n",
       "29  SMOTE_FWS_FS      K Nearest Neighbors   \n",
       "30  SMOTE_FWS_FS      K Nearest Neighbors   \n",
       "31  SMOTE_FWS_FS      K Nearest Neighbors   \n",
       "32  SMOTE_FWS_FS            Decision Tree   \n",
       "33  SMOTE_FWS_FS            Decision Tree   \n",
       "34  SMOTE_FWS_FS            Decision Tree   \n",
       "35  SMOTE_FWS_FS            Decision Tree   \n",
       "36  SMOTE_FWS_FS            Decision Tree   \n",
       "37  SMOTE_FWS_FS            Decision Tree   \n",
       "38  SMOTE_FWS_FS            Decision Tree   \n",
       "39  SMOTE_FWS_FS            Random Forest   \n",
       "40  SMOTE_FWS_FS            Random Forest   \n",
       "41  SMOTE_FWS_FS            Random Forest   \n",
       "42  SMOTE_FWS_FS            Random Forest   \n",
       "43  SMOTE_FWS_FS            Random Forest   \n",
       "44  SMOTE_FWS_FS            Random Forest   \n",
       "45  SMOTE_FWS_FS            Random Forest   \n",
       "46  SMOTE_FWS_FS            Random Forest   \n",
       "47  SMOTE_FWS_FS            Random Forest   \n",
       "48  SMOTE_FWS_FS            Random Forest   \n",
       "49  SMOTE_FWS_FS                Ada Boost   \n",
       "50  SMOTE_FWS_FS                Ada Boost   \n",
       "51  SMOTE_FWS_FS                Ada Boost   \n",
       "52  SMOTE_FWS_FS                Ada Boost   \n",
       "53  SMOTE_FWS_FS                Ada Boost   \n",
       "54  SMOTE_FWS_FS                Ada Boost   \n",
       "55  SMOTE_FWS_FS                Ada Boost   \n",
       "\n",
       "                                           Parameters  Split  Accuracy  \\\n",
       "0                       {'strategy': 'most_frequent'}  Train  0.333333   \n",
       "1                          {'strategy': 'stratified'}  Train  0.336552   \n",
       "2                          {'strategy': 'stratified'}   Test  0.325551   \n",
       "3   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.547084   \n",
       "4   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.550495   \n",
       "5   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.546315   \n",
       "6   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.548573   \n",
       "7   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.574277   \n",
       "8   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.573748   \n",
       "9   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.572643   \n",
       "10  {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.572307   \n",
       "11  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.573028   \n",
       "12  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.573076   \n",
       "13  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.571779   \n",
       "14  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.571827   \n",
       "15  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.573028   \n",
       "16  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.573028   \n",
       "17  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.571779   \n",
       "18  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.571779   \n",
       "19  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.573028   \n",
       "20  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.573028   \n",
       "21  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.571779   \n",
       "22  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.571779   \n",
       "23  {'C': 1.0, 'fit_intercept': True, 'multi_class...   Test  0.568722   \n",
       "24                  {'alpha': 0.0, 'fit_prior': True}  Train  0.546363   \n",
       "25                  {'alpha': 1.0, 'fit_prior': True}  Train  0.546363   \n",
       "26                  {'alpha': 0.0, 'fit_prior': True}   Test  0.607048   \n",
       "27       {'algorithm': 'ball_tree', 'leaf_size': 100}  Train  0.604401   \n",
       "28       {'algorithm': 'ball_tree', 'leaf_size': 200}  Train  0.607572   \n",
       "29         {'algorithm': 'kd_tree', 'leaf_size': 100}  Train  0.604449   \n",
       "30         {'algorithm': 'kd_tree', 'leaf_size': 200}  Train  0.607764   \n",
       "31         {'algorithm': 'kd_tree', 'leaf_size': 200}   Test  0.647137   \n",
       "32  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.545354   \n",
       "33  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.333333   \n",
       "34  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.333333   \n",
       "35  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.552417   \n",
       "36  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.545354   \n",
       "37  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.545354   \n",
       "38  {'criterion': 'entropy', 'min_impurity_decreas...   Test  0.672687   \n",
       "39  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.540357   \n",
       "40  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.539108   \n",
       "41  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.539925   \n",
       "42  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.441962   \n",
       "43  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.454310   \n",
       "44  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.455367   \n",
       "45  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "46  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "47  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...   Test  0.632159   \n",
       "49        {'learning_rate': 0.5, 'n_estimators': 100}  Train  0.565533   \n",
       "50        {'learning_rate': 0.5, 'n_estimators': 200}  Train  0.568175   \n",
       "51        {'learning_rate': 0.5, 'n_estimators': 300}  Train  0.570914   \n",
       "52        {'learning_rate': 1.0, 'n_estimators': 100}  Train  0.570241   \n",
       "53        {'learning_rate': 1.0, 'n_estimators': 200}  Train  0.574902   \n",
       "54        {'learning_rate': 1.0, 'n_estimators': 300}  Train  0.579706   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 300}   Test  0.577974   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "0    0.111111  0.333333  0.166667   \n",
       "1    0.331588  0.336312  0.336754   \n",
       "2    0.617887  0.325551  0.395385   \n",
       "3    0.570674  0.547084  0.544080   \n",
       "4    0.572209  0.550495  0.548311   \n",
       "5    0.569022  0.546315  0.543277   \n",
       "6    0.570187  0.548573  0.545961   \n",
       "7    0.581002  0.574277  0.573704   \n",
       "8    0.580394  0.573748  0.573182   \n",
       "9    0.579650  0.572643  0.572115   \n",
       "10   0.578982  0.572307  0.571775   \n",
       "11   0.579693  0.573028  0.572599   \n",
       "12   0.579730  0.573076  0.572646   \n",
       "13   0.578641  0.571779  0.571306   \n",
       "14   0.578685  0.571827  0.571351   \n",
       "15   0.579693  0.573028  0.572599   \n",
       "16   0.579693  0.573028  0.572599   \n",
       "17   0.578641  0.571779  0.571306   \n",
       "18   0.578641  0.571779  0.571306   \n",
       "19   0.579693  0.573028  0.572599   \n",
       "20   0.579693  0.573028  0.572599   \n",
       "21   0.578641  0.571779  0.571306   \n",
       "22   0.578641  0.571779  0.571306   \n",
       "23   0.740360  0.568722  0.623458   \n",
       "24   0.560368  0.546363  0.544499   \n",
       "25   0.560843  0.546363  0.544466   \n",
       "26   0.743012  0.607048  0.654395   \n",
       "27   0.631662  0.604401  0.601186   \n",
       "28   0.635848  0.607572  0.604142   \n",
       "29   0.631472  0.604449  0.601201   \n",
       "30   0.635851  0.607764  0.604342   \n",
       "31   0.712581  0.647137  0.668348   \n",
       "32   0.569432  0.545354  0.542361   \n",
       "33   0.111111  0.333333  0.166667   \n",
       "34   0.111111  0.333333  0.166667   \n",
       "35   0.584733  0.552417  0.547088   \n",
       "36   0.569432  0.545354  0.542361   \n",
       "37   0.569432  0.545354  0.542361   \n",
       "38   0.773291  0.672687  0.711030   \n",
       "39   0.558364  0.540357  0.537119   \n",
       "40   0.557039  0.539108  0.535906   \n",
       "41   0.557387  0.539925  0.536706   \n",
       "42   0.414388  0.441962  0.374810   \n",
       "43   0.462280  0.454310  0.401083   \n",
       "44   0.462533  0.455367  0.401603   \n",
       "45   0.111111  0.333333  0.166667   \n",
       "46   0.111111  0.333333  0.166667   \n",
       "47   0.111111  0.333333  0.166667   \n",
       "48   0.751406  0.632159  0.674733   \n",
       "49   0.575038  0.565533  0.564844   \n",
       "50   0.575414  0.568175  0.567780   \n",
       "51   0.577515  0.570914  0.570622   \n",
       "52   0.577216  0.570241  0.569826   \n",
       "53   0.580339  0.574902  0.574408   \n",
       "54   0.584667  0.579706  0.579244   \n",
       "55   0.741410  0.577974  0.631160   \n",
       "\n",
       "                                    Confusion Matrix  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2   [[577, 575, 585], [51, 51, 53], [122, 145, 111]]  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  \n",
       "10                                               NaN  \n",
       "11                                               NaN  \n",
       "12                                               NaN  \n",
       "13                                               NaN  \n",
       "14                                               NaN  \n",
       "15                                               NaN  \n",
       "16                                               NaN  \n",
       "17                                               NaN  \n",
       "18                                               NaN  \n",
       "19                                               NaN  \n",
       "20                                               NaN  \n",
       "21                                               NaN  \n",
       "22                                               NaN  \n",
       "23   [[1012, 426, 299], [57, 75, 23], [92, 82, 204]]  \n",
       "24                                               NaN  \n",
       "25                                               NaN  \n",
       "26   [[1117, 338, 282], [61, 73, 21], [99, 91, 188]]  \n",
       "27                                               NaN  \n",
       "28                                               NaN  \n",
       "29                                               NaN  \n",
       "30                                               NaN  \n",
       "31  [[1217, 119, 401], [96, 19, 40], [127, 18, 233]]  \n",
       "32                                               NaN  \n",
       "33                                               NaN  \n",
       "34                                               NaN  \n",
       "35                                               NaN  \n",
       "36                                               NaN  \n",
       "37                                               NaN  \n",
       "38  [[1267, 323, 147], [65, 80, 10], [108, 90, 180]]  \n",
       "39                                               NaN  \n",
       "40                                               NaN  \n",
       "41                                               NaN  \n",
       "42                                               NaN  \n",
       "43                                               NaN  \n",
       "44                                               NaN  \n",
       "45                                               NaN  \n",
       "46                                               NaN  \n",
       "47                                               NaN  \n",
       "48  [[1168, 316, 253], [62, 78, 15], [101, 88, 189]]  \n",
       "49                                               NaN  \n",
       "50                                               NaN  \n",
       "51                                               NaN  \n",
       "52                                               NaN  \n",
       "53                                               NaN  \n",
       "54                                               NaN  \n",
       "55   [[1036, 405, 296], [58, 74, 23], [93, 83, 202]]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote_fws_fs = X_train_smote.drop(['Days with AQI', 'Good Days'], axis=1)\n",
    "X_test_fws_fs        = X_test.drop(['Days with AQI', 'Good Days'], axis=1)\n",
    "\n",
    "# run balanced FWS + FS dataset\n",
    "model_smote_fws_fs = clf.fit_predict_measure(\n",
    "    'SMOTE_FWS_FS', X_train_smote_fws_fs, X_test_fws_fs, y_train_smote, y_test, y_labels, classifiers)\n",
    "model_smote_fws_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.532645</td>\n",
       "      <td>0.536815</td>\n",
       "      <td>0.532640</td>\n",
       "      <td>0.516413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090481</td>\n",
       "      <td>0.165707</td>\n",
       "      <td>0.090490</td>\n",
       "      <td>0.139076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.325551</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.325551</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.544105</td>\n",
       "      <td>0.560724</td>\n",
       "      <td>0.544105</td>\n",
       "      <td>0.541051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.570577</td>\n",
       "      <td>0.578641</td>\n",
       "      <td>0.570577</td>\n",
       "      <td>0.570964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.573040</td>\n",
       "      <td>0.580546</td>\n",
       "      <td>0.573040</td>\n",
       "      <td>0.572780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.711030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall   F1 Score\n",
       "count  56.000000  56.000000  56.000000  56.000000\n",
       "mean    0.532645   0.536815   0.532640   0.516413\n",
       "std     0.090481   0.165707   0.090490   0.139076\n",
       "min     0.325551   0.111111   0.325551   0.166667\n",
       "25%     0.544105   0.560724   0.544105   0.541051\n",
       "50%     0.570577   0.578641   0.570577   0.570964\n",
       "75%     0.573040   0.580546   0.573040   0.572780\n",
       "max     0.672687   0.773291   0.672687   0.711030"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of balanced FWS + FS classifiers (test and training sets)\n",
    "model_smote_fws_fs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.711030</td>\n",
       "      <td>[[1267, 323, 147], [65, 80, 10], [108, 90, 180]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.632159</td>\n",
       "      <td>0.751406</td>\n",
       "      <td>0.632159</td>\n",
       "      <td>0.674733</td>\n",
       "      <td>[[1168, 316, 253], [62, 78, 15], [101, 88, 189]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.647137</td>\n",
       "      <td>0.712581</td>\n",
       "      <td>0.647137</td>\n",
       "      <td>0.668348</td>\n",
       "      <td>[[1217, 119, 401], [96, 19, 40], [127, 18, 233]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.607048</td>\n",
       "      <td>0.743012</td>\n",
       "      <td>0.607048</td>\n",
       "      <td>0.654395</td>\n",
       "      <td>[[1117, 338, 282], [61, 73, 21], [99, 91, 188]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.577974</td>\n",
       "      <td>0.741410</td>\n",
       "      <td>0.577974</td>\n",
       "      <td>0.631160</td>\n",
       "      <td>[[1036, 405, 296], [58, 74, 23], [93, 83, 202]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.568722</td>\n",
       "      <td>0.740360</td>\n",
       "      <td>0.568722</td>\n",
       "      <td>0.623458</td>\n",
       "      <td>[[1012, 426, 299], [57, 75, 23], [92, 82, 204]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE_FWS_FS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.325551</td>\n",
       "      <td>0.617887</td>\n",
       "      <td>0.325551</td>\n",
       "      <td>0.395385</td>\n",
       "      <td>[[577, 575, 585], [51, 51, 53], [122, 145, 111]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Data               Classifier  \\\n",
       "38  SMOTE_FWS_FS            Decision Tree   \n",
       "48  SMOTE_FWS_FS            Random Forest   \n",
       "31  SMOTE_FWS_FS      K Nearest Neighbors   \n",
       "26  SMOTE_FWS_FS  Multinomial Naive Bayes   \n",
       "55  SMOTE_FWS_FS                Ada Boost   \n",
       "23  SMOTE_FWS_FS      Logistic Regression   \n",
       "2   SMOTE_FWS_FS                    Dummy   \n",
       "\n",
       "                                           Parameters Split  Accuracy  \\\n",
       "38  {'criterion': 'entropy', 'min_impurity_decreas...  Test  0.672687   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...  Test  0.632159   \n",
       "31         {'algorithm': 'kd_tree', 'leaf_size': 200}  Test  0.647137   \n",
       "26                  {'alpha': 0.0, 'fit_prior': True}  Test  0.607048   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 300}  Test  0.577974   \n",
       "23  {'C': 1.0, 'fit_intercept': True, 'multi_class...  Test  0.568722   \n",
       "2                          {'strategy': 'stratified'}  Test  0.325551   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "38   0.773291  0.672687  0.711030   \n",
       "48   0.751406  0.632159  0.674733   \n",
       "31   0.712581  0.647137  0.668348   \n",
       "26   0.743012  0.607048  0.654395   \n",
       "55   0.741410  0.577974  0.631160   \n",
       "23   0.740360  0.568722  0.623458   \n",
       "2    0.617887  0.325551  0.395385   \n",
       "\n",
       "                                    Confusion Matrix  \n",
       "38  [[1267, 323, 147], [65, 80, 10], [108, 90, 180]]  \n",
       "48  [[1168, 316, 253], [62, 78, 15], [101, 88, 189]]  \n",
       "31  [[1217, 119, 401], [96, 19, 40], [127, 18, 233]]  \n",
       "26   [[1117, 338, 282], [61, 73, 21], [99, 91, 188]]  \n",
       "55   [[1036, 405, 296], [58, 74, 23], [93, 83, 202]]  \n",
       "23   [[1012, 426, 299], [57, 75, 23], [92, 82, 204]]  \n",
       "2   [[577, 575, 585], [51, 51, 53], [122, 145, 111]]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators of balanced FWS + FS dataset\n",
    "model_smote_fws_fs_test = model_smote_fws_fs[model_smote_fws_fs['Split'] == 'Test']\n",
    "model_smote_fws_fs_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Training Model 4:  Balanced FWS + FS + Environmental Protection Agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   46.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:  2.5min remaining:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Decision Tree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    1.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Random Forest\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:   18.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   19.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Ada Boost\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  1.4min remaining:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.335495</td>\n",
       "      <td>0.332111</td>\n",
       "      <td>0.334871</td>\n",
       "      <td>0.334342</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.324229</td>\n",
       "      <td>0.598313</td>\n",
       "      <td>0.324229</td>\n",
       "      <td>0.388860</td>\n",
       "      <td>[[566, 582, 589], [58, 54, 43], [139, 123, 116]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.547084</td>\n",
       "      <td>0.570841</td>\n",
       "      <td>0.547084</td>\n",
       "      <td>0.544101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.549870</td>\n",
       "      <td>0.570595</td>\n",
       "      <td>0.549870</td>\n",
       "      <td>0.547864</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.547084</td>\n",
       "      <td>0.570841</td>\n",
       "      <td>0.547084</td>\n",
       "      <td>0.544101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.548141</td>\n",
       "      <td>0.567908</td>\n",
       "      <td>0.548141</td>\n",
       "      <td>0.545970</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.573604</td>\n",
       "      <td>0.580360</td>\n",
       "      <td>0.573604</td>\n",
       "      <td>0.573113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.574229</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>0.574229</td>\n",
       "      <td>0.573674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.573364</td>\n",
       "      <td>0.580144</td>\n",
       "      <td>0.573364</td>\n",
       "      <td>0.572880</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.573220</td>\n",
       "      <td>0.579866</td>\n",
       "      <td>0.573220</td>\n",
       "      <td>0.572732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572595</td>\n",
       "      <td>0.579196</td>\n",
       "      <td>0.572595</td>\n",
       "      <td>0.572216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.579285</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.572314</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572740</td>\n",
       "      <td>0.579405</td>\n",
       "      <td>0.572740</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.579357</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.572295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572595</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>0.572595</td>\n",
       "      <td>0.572215</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572643</td>\n",
       "      <td>0.579242</td>\n",
       "      <td>0.572643</td>\n",
       "      <td>0.572261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572740</td>\n",
       "      <td>0.579405</td>\n",
       "      <td>0.572740</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.579361</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.572294</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572595</td>\n",
       "      <td>0.579200</td>\n",
       "      <td>0.572595</td>\n",
       "      <td>0.572215</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572643</td>\n",
       "      <td>0.579242</td>\n",
       "      <td>0.572643</td>\n",
       "      <td>0.572261</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572740</td>\n",
       "      <td>0.579405</td>\n",
       "      <td>0.572740</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.579361</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.572294</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.581498</td>\n",
       "      <td>0.743213</td>\n",
       "      <td>0.581498</td>\n",
       "      <td>0.633893</td>\n",
       "      <td>[[1041, 397, 299], [57, 75, 23], [92, 82, 204]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545979</td>\n",
       "      <td>0.560191</td>\n",
       "      <td>0.545979</td>\n",
       "      <td>0.544157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.546171</td>\n",
       "      <td>0.561032</td>\n",
       "      <td>0.546171</td>\n",
       "      <td>0.544366</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.622026</td>\n",
       "      <td>0.745481</td>\n",
       "      <td>0.622026</td>\n",
       "      <td>0.665956</td>\n",
       "      <td>[[1151, 313, 273], [63, 73, 19], [101, 89, 188]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.627944</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.606479</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.610118</td>\n",
       "      <td>0.631393</td>\n",
       "      <td>0.610118</td>\n",
       "      <td>0.608229</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.607908</td>\n",
       "      <td>0.627472</td>\n",
       "      <td>0.607908</td>\n",
       "      <td>0.606279</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.610166</td>\n",
       "      <td>0.631076</td>\n",
       "      <td>0.610166</td>\n",
       "      <td>0.608322</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.644053</td>\n",
       "      <td>0.712286</td>\n",
       "      <td>0.644053</td>\n",
       "      <td>0.666038</td>\n",
       "      <td>[[1209, 120, 408], [96, 19, 40], [125, 19, 234]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.552417</td>\n",
       "      <td>0.584733</td>\n",
       "      <td>0.552417</td>\n",
       "      <td>0.547088</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.569432</td>\n",
       "      <td>0.545354</td>\n",
       "      <td>0.542361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.711030</td>\n",
       "      <td>[[1267, 323, 147], [65, 80, 10], [108, 90, 180]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.540646</td>\n",
       "      <td>0.558109</td>\n",
       "      <td>0.540646</td>\n",
       "      <td>0.537442</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.543336</td>\n",
       "      <td>0.563018</td>\n",
       "      <td>0.543336</td>\n",
       "      <td>0.540235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.541703</td>\n",
       "      <td>0.559852</td>\n",
       "      <td>0.541703</td>\n",
       "      <td>0.538571</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.412799</td>\n",
       "      <td>0.347795</td>\n",
       "      <td>0.412799</td>\n",
       "      <td>0.303859</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.426396</td>\n",
       "      <td>0.384960</td>\n",
       "      <td>0.426396</td>\n",
       "      <td>0.336176</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.455078</td>\n",
       "      <td>0.461717</td>\n",
       "      <td>0.455078</td>\n",
       "      <td>0.401420</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.632599</td>\n",
       "      <td>0.750781</td>\n",
       "      <td>0.632599</td>\n",
       "      <td>0.674933</td>\n",
       "      <td>[[1170, 316, 251], [63, 78, 14], [102, 88, 188]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.567166</td>\n",
       "      <td>0.576454</td>\n",
       "      <td>0.567166</td>\n",
       "      <td>0.566394</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.573796</td>\n",
       "      <td>0.581337</td>\n",
       "      <td>0.573796</td>\n",
       "      <td>0.573136</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.575958</td>\n",
       "      <td>0.581776</td>\n",
       "      <td>0.575958</td>\n",
       "      <td>0.575471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.578743</td>\n",
       "      <td>0.572691</td>\n",
       "      <td>0.572273</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.578601</td>\n",
       "      <td>0.584122</td>\n",
       "      <td>0.578601</td>\n",
       "      <td>0.578055</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.581003</td>\n",
       "      <td>0.585551</td>\n",
       "      <td>0.581003</td>\n",
       "      <td>0.580544</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.575771</td>\n",
       "      <td>0.738057</td>\n",
       "      <td>0.575771</td>\n",
       "      <td>0.628647</td>\n",
       "      <td>[[1032, 406, 299], [61, 73, 21], [95, 81, 202]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Data               Classifier  \\\n",
       "0   SMOTE_FWS_FS_EPA                    Dummy   \n",
       "1   SMOTE_FWS_FS_EPA                    Dummy   \n",
       "2   SMOTE_FWS_FS_EPA                    Dummy   \n",
       "3   SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "4   SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "5   SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "6   SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "7   SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "8   SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "9   SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "10  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "11  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "12  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "13  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "14  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "15  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "16  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "17  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "18  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "19  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "20  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "21  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "22  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "23  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "24  SMOTE_FWS_FS_EPA  Multinomial Naive Bayes   \n",
       "25  SMOTE_FWS_FS_EPA  Multinomial Naive Bayes   \n",
       "26  SMOTE_FWS_FS_EPA  Multinomial Naive Bayes   \n",
       "27  SMOTE_FWS_FS_EPA      K Nearest Neighbors   \n",
       "28  SMOTE_FWS_FS_EPA      K Nearest Neighbors   \n",
       "29  SMOTE_FWS_FS_EPA      K Nearest Neighbors   \n",
       "30  SMOTE_FWS_FS_EPA      K Nearest Neighbors   \n",
       "31  SMOTE_FWS_FS_EPA      K Nearest Neighbors   \n",
       "32  SMOTE_FWS_FS_EPA            Decision Tree   \n",
       "33  SMOTE_FWS_FS_EPA            Decision Tree   \n",
       "34  SMOTE_FWS_FS_EPA            Decision Tree   \n",
       "35  SMOTE_FWS_FS_EPA            Decision Tree   \n",
       "36  SMOTE_FWS_FS_EPA            Decision Tree   \n",
       "37  SMOTE_FWS_FS_EPA            Decision Tree   \n",
       "38  SMOTE_FWS_FS_EPA            Decision Tree   \n",
       "39  SMOTE_FWS_FS_EPA            Random Forest   \n",
       "40  SMOTE_FWS_FS_EPA            Random Forest   \n",
       "41  SMOTE_FWS_FS_EPA            Random Forest   \n",
       "42  SMOTE_FWS_FS_EPA            Random Forest   \n",
       "43  SMOTE_FWS_FS_EPA            Random Forest   \n",
       "44  SMOTE_FWS_FS_EPA            Random Forest   \n",
       "45  SMOTE_FWS_FS_EPA            Random Forest   \n",
       "46  SMOTE_FWS_FS_EPA            Random Forest   \n",
       "47  SMOTE_FWS_FS_EPA            Random Forest   \n",
       "48  SMOTE_FWS_FS_EPA            Random Forest   \n",
       "49  SMOTE_FWS_FS_EPA                Ada Boost   \n",
       "50  SMOTE_FWS_FS_EPA                Ada Boost   \n",
       "51  SMOTE_FWS_FS_EPA                Ada Boost   \n",
       "52  SMOTE_FWS_FS_EPA                Ada Boost   \n",
       "53  SMOTE_FWS_FS_EPA                Ada Boost   \n",
       "54  SMOTE_FWS_FS_EPA                Ada Boost   \n",
       "55  SMOTE_FWS_FS_EPA                Ada Boost   \n",
       "\n",
       "                                           Parameters  Split  Accuracy  \\\n",
       "0                       {'strategy': 'most_frequent'}  Train  0.333333   \n",
       "1                          {'strategy': 'stratified'}  Train  0.335495   \n",
       "2                          {'strategy': 'stratified'}   Test  0.324229   \n",
       "3   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.547084   \n",
       "4   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.549870   \n",
       "5   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.547084   \n",
       "6   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.548141   \n",
       "7   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.573604   \n",
       "8   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.574229   \n",
       "9   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.573364   \n",
       "10  {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.573220   \n",
       "11  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.572595   \n",
       "12  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.572691   \n",
       "13  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.572740   \n",
       "14  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.572691   \n",
       "15  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.572595   \n",
       "16  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.572643   \n",
       "17  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.572740   \n",
       "18  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.572691   \n",
       "19  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.572595   \n",
       "20  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.572643   \n",
       "21  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.572740   \n",
       "22  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.572691   \n",
       "23  {'C': 1.0, 'fit_intercept': True, 'multi_class...   Test  0.581498   \n",
       "24                  {'alpha': 0.0, 'fit_prior': True}  Train  0.545979   \n",
       "25                  {'alpha': 1.0, 'fit_prior': True}  Train  0.546171   \n",
       "26                  {'alpha': 1.0, 'fit_prior': True}   Test  0.622026   \n",
       "27       {'algorithm': 'ball_tree', 'leaf_size': 100}  Train  0.608100   \n",
       "28       {'algorithm': 'ball_tree', 'leaf_size': 200}  Train  0.610118   \n",
       "29         {'algorithm': 'kd_tree', 'leaf_size': 100}  Train  0.607908   \n",
       "30         {'algorithm': 'kd_tree', 'leaf_size': 200}  Train  0.610166   \n",
       "31         {'algorithm': 'kd_tree', 'leaf_size': 200}   Test  0.644053   \n",
       "32  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.545354   \n",
       "33  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.333333   \n",
       "34  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.333333   \n",
       "35  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.552417   \n",
       "36  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.545354   \n",
       "37  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.545354   \n",
       "38  {'criterion': 'entropy', 'min_impurity_decreas...   Test  0.672687   \n",
       "39  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.540646   \n",
       "40  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.543336   \n",
       "41  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.541703   \n",
       "42  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.412799   \n",
       "43  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.426396   \n",
       "44  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.455078   \n",
       "45  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "46  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "47  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...   Test  0.632599   \n",
       "49        {'learning_rate': 0.5, 'n_estimators': 100}  Train  0.567166   \n",
       "50        {'learning_rate': 0.5, 'n_estimators': 200}  Train  0.573796   \n",
       "51        {'learning_rate': 0.5, 'n_estimators': 300}  Train  0.575958   \n",
       "52        {'learning_rate': 1.0, 'n_estimators': 100}  Train  0.572691   \n",
       "53        {'learning_rate': 1.0, 'n_estimators': 200}  Train  0.578601   \n",
       "54        {'learning_rate': 1.0, 'n_estimators': 300}  Train  0.581003   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 300}   Test  0.575771   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "0    0.111111  0.333333  0.166667   \n",
       "1    0.332111  0.334871  0.334342   \n",
       "2    0.598313  0.324229  0.388860   \n",
       "3    0.570841  0.547084  0.544101   \n",
       "4    0.570595  0.549870  0.547864   \n",
       "5    0.570841  0.547084  0.544101   \n",
       "6    0.567908  0.548141  0.545970   \n",
       "7    0.580360  0.573604  0.573113   \n",
       "8    0.580756  0.574229  0.573674   \n",
       "9    0.580144  0.573364  0.572880   \n",
       "10   0.579866  0.573220  0.572732   \n",
       "11   0.579196  0.572595  0.572216   \n",
       "12   0.579285  0.572691  0.572314   \n",
       "13   0.579405  0.572740  0.572347   \n",
       "14   0.579357  0.572691  0.572295   \n",
       "15   0.579200  0.572595  0.572215   \n",
       "16   0.579242  0.572643  0.572261   \n",
       "17   0.579405  0.572740  0.572347   \n",
       "18   0.579361  0.572691  0.572294   \n",
       "19   0.579200  0.572595  0.572215   \n",
       "20   0.579242  0.572643  0.572261   \n",
       "21   0.579405  0.572740  0.572347   \n",
       "22   0.579361  0.572691  0.572294   \n",
       "23   0.743213  0.581498  0.633893   \n",
       "24   0.560191  0.545979  0.544157   \n",
       "25   0.561032  0.546171  0.544366   \n",
       "26   0.745481  0.622026  0.665956   \n",
       "27   0.627944  0.608100  0.606479   \n",
       "28   0.631393  0.610118  0.608229   \n",
       "29   0.627472  0.607908  0.606279   \n",
       "30   0.631076  0.610166  0.608322   \n",
       "31   0.712286  0.644053  0.666038   \n",
       "32   0.569432  0.545354  0.542361   \n",
       "33   0.111111  0.333333  0.166667   \n",
       "34   0.111111  0.333333  0.166667   \n",
       "35   0.584733  0.552417  0.547088   \n",
       "36   0.569432  0.545354  0.542361   \n",
       "37   0.569432  0.545354  0.542361   \n",
       "38   0.773291  0.672687  0.711030   \n",
       "39   0.558109  0.540646  0.537442   \n",
       "40   0.563018  0.543336  0.540235   \n",
       "41   0.559852  0.541703  0.538571   \n",
       "42   0.347795  0.412799  0.303859   \n",
       "43   0.384960  0.426396  0.336176   \n",
       "44   0.461717  0.455078  0.401420   \n",
       "45   0.111111  0.333333  0.166667   \n",
       "46   0.111111  0.333333  0.166667   \n",
       "47   0.111111  0.333333  0.166667   \n",
       "48   0.750781  0.632599  0.674933   \n",
       "49   0.576454  0.567166  0.566394   \n",
       "50   0.581337  0.573796  0.573136   \n",
       "51   0.581776  0.575958  0.575471   \n",
       "52   0.578743  0.572691  0.572273   \n",
       "53   0.584122  0.578601  0.578055   \n",
       "54   0.585551  0.581003  0.580544   \n",
       "55   0.738057  0.575771  0.628647   \n",
       "\n",
       "                                    Confusion Matrix  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2   [[566, 582, 589], [58, 54, 43], [139, 123, 116]]  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  \n",
       "10                                               NaN  \n",
       "11                                               NaN  \n",
       "12                                               NaN  \n",
       "13                                               NaN  \n",
       "14                                               NaN  \n",
       "15                                               NaN  \n",
       "16                                               NaN  \n",
       "17                                               NaN  \n",
       "18                                               NaN  \n",
       "19                                               NaN  \n",
       "20                                               NaN  \n",
       "21                                               NaN  \n",
       "22                                               NaN  \n",
       "23   [[1041, 397, 299], [57, 75, 23], [92, 82, 204]]  \n",
       "24                                               NaN  \n",
       "25                                               NaN  \n",
       "26  [[1151, 313, 273], [63, 73, 19], [101, 89, 188]]  \n",
       "27                                               NaN  \n",
       "28                                               NaN  \n",
       "29                                               NaN  \n",
       "30                                               NaN  \n",
       "31  [[1209, 120, 408], [96, 19, 40], [125, 19, 234]]  \n",
       "32                                               NaN  \n",
       "33                                               NaN  \n",
       "34                                               NaN  \n",
       "35                                               NaN  \n",
       "36                                               NaN  \n",
       "37                                               NaN  \n",
       "38  [[1267, 323, 147], [65, 80, 10], [108, 90, 180]]  \n",
       "39                                               NaN  \n",
       "40                                               NaN  \n",
       "41                                               NaN  \n",
       "42                                               NaN  \n",
       "43                                               NaN  \n",
       "44                                               NaN  \n",
       "45                                               NaN  \n",
       "46                                               NaN  \n",
       "47                                               NaN  \n",
       "48  [[1170, 316, 251], [63, 78, 14], [102, 88, 188]]  \n",
       "49                                               NaN  \n",
       "50                                               NaN  \n",
       "51                                               NaN  \n",
       "52                                               NaN  \n",
       "53                                               NaN  \n",
       "54                                               NaN  \n",
       "55   [[1032, 406, 299], [61, 73, 21], [95, 81, 202]]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote_fws_fs_epa = X_train_smote\n",
    "X_test_fws_fs_epa        = X_test\n",
    "\n",
    "# run balanced FWS + FS + EPA dataset\n",
    "model_smote_fws_fs_epa = clf.fit_predict_measure(\n",
    "    'SMOTE_FWS_FS_EPA', X_train_smote_fws_fs_epa, X_test_fws_fs_epa, y_train_smote, y_test, y_labels, classifiers)\n",
    "model_smote_fws_fs_epa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.532734</td>\n",
       "      <td>0.534085</td>\n",
       "      <td>0.532723</td>\n",
       "      <td>0.515020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.092358</td>\n",
       "      <td>0.167571</td>\n",
       "      <td>0.092382</td>\n",
       "      <td>0.142785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.324229</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.324229</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.544850</td>\n",
       "      <td>0.562522</td>\n",
       "      <td>0.544850</td>\n",
       "      <td>0.541829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.572619</td>\n",
       "      <td>0.579242</td>\n",
       "      <td>0.572619</td>\n",
       "      <td>0.572238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.573905</td>\n",
       "      <td>0.582363</td>\n",
       "      <td>0.573905</td>\n",
       "      <td>0.573270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.711030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall   F1 Score\n",
       "count  56.000000  56.000000  56.000000  56.000000\n",
       "mean    0.532734   0.534085   0.532723   0.515020\n",
       "std     0.092358   0.167571   0.092382   0.142785\n",
       "min     0.324229   0.111111   0.324229   0.166667\n",
       "25%     0.544850   0.562522   0.544850   0.541829\n",
       "50%     0.572619   0.579242   0.572619   0.572238\n",
       "75%     0.573905   0.582363   0.573905   0.573270\n",
       "max     0.672687   0.773291   0.672687   0.711030"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of balanced FWS + FS + EPA classifiers (test and training sets)\n",
    "model_smote_fws_fs_epa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.773291</td>\n",
       "      <td>0.672687</td>\n",
       "      <td>0.711030</td>\n",
       "      <td>[[1267, 323, 147], [65, 80, 10], [108, 90, 180]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.632599</td>\n",
       "      <td>0.750781</td>\n",
       "      <td>0.632599</td>\n",
       "      <td>0.674933</td>\n",
       "      <td>[[1170, 316, 251], [63, 78, 14], [102, 88, 188]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.644053</td>\n",
       "      <td>0.712286</td>\n",
       "      <td>0.644053</td>\n",
       "      <td>0.666038</td>\n",
       "      <td>[[1209, 120, 408], [96, 19, 40], [125, 19, 234]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.622026</td>\n",
       "      <td>0.745481</td>\n",
       "      <td>0.622026</td>\n",
       "      <td>0.665956</td>\n",
       "      <td>[[1151, 313, 273], [63, 73, 19], [101, 89, 188]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.581498</td>\n",
       "      <td>0.743213</td>\n",
       "      <td>0.581498</td>\n",
       "      <td>0.633893</td>\n",
       "      <td>[[1041, 397, 299], [57, 75, 23], [92, 82, 204]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.575771</td>\n",
       "      <td>0.738057</td>\n",
       "      <td>0.575771</td>\n",
       "      <td>0.628647</td>\n",
       "      <td>[[1032, 406, 299], [61, 73, 21], [95, 81, 202]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE_FWS_FS_EPA</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.324229</td>\n",
       "      <td>0.598313</td>\n",
       "      <td>0.324229</td>\n",
       "      <td>0.388860</td>\n",
       "      <td>[[566, 582, 589], [58, 54, 43], [139, 123, 116]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Data               Classifier  \\\n",
       "38  SMOTE_FWS_FS_EPA            Decision Tree   \n",
       "48  SMOTE_FWS_FS_EPA            Random Forest   \n",
       "31  SMOTE_FWS_FS_EPA      K Nearest Neighbors   \n",
       "26  SMOTE_FWS_FS_EPA  Multinomial Naive Bayes   \n",
       "23  SMOTE_FWS_FS_EPA      Logistic Regression   \n",
       "55  SMOTE_FWS_FS_EPA                Ada Boost   \n",
       "2   SMOTE_FWS_FS_EPA                    Dummy   \n",
       "\n",
       "                                           Parameters Split  Accuracy  \\\n",
       "38  {'criterion': 'entropy', 'min_impurity_decreas...  Test  0.672687   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...  Test  0.632599   \n",
       "31         {'algorithm': 'kd_tree', 'leaf_size': 200}  Test  0.644053   \n",
       "26                  {'alpha': 1.0, 'fit_prior': True}  Test  0.622026   \n",
       "23  {'C': 1.0, 'fit_intercept': True, 'multi_class...  Test  0.581498   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 300}  Test  0.575771   \n",
       "2                          {'strategy': 'stratified'}  Test  0.324229   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "38   0.773291  0.672687  0.711030   \n",
       "48   0.750781  0.632599  0.674933   \n",
       "31   0.712286  0.644053  0.666038   \n",
       "26   0.745481  0.622026  0.665956   \n",
       "23   0.743213  0.581498  0.633893   \n",
       "55   0.738057  0.575771  0.628647   \n",
       "2    0.598313  0.324229  0.388860   \n",
       "\n",
       "                                    Confusion Matrix  \n",
       "38  [[1267, 323, 147], [65, 80, 10], [108, 90, 180]]  \n",
       "48  [[1170, 316, 251], [63, 78, 14], [102, 88, 188]]  \n",
       "31  [[1209, 120, 408], [96, 19, 40], [125, 19, 234]]  \n",
       "26  [[1151, 313, 273], [63, 73, 19], [101, 89, 188]]  \n",
       "23   [[1041, 397, 299], [57, 75, 23], [92, 82, 204]]  \n",
       "55   [[1032, 406, 299], [61, 73, 21], [95, 81, 202]]  \n",
       "2   [[566, 582, 589], [58, 54, 43], [139, 123, 116]]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators of balanced FWS + FS + EPA dataset\n",
    "model_smote_fws_fs_epa_test = model_smote_fws_fs_epa[model_smote_fws_fs_epa['Split'] == 'Test']\n",
    "model_smote_fws_fs_epa_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fws.to_pickle(             '../Data/model_fws.pkl')\n",
    "model_smote_fws.to_pickle(       '../Data/model_smote_fws.pkl')\n",
    "model_smote_fws_fs.to_pickle(    '../Data/model_smote_fws_fs.pkl')\n",
    "model_smote_fws_fs_epa.to_pickle('../Data/model_smote_fws_fs_epa.pkl')\n",
    "pd.DataFrame(y_labels).to_pickle('../Data/y_labels.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
