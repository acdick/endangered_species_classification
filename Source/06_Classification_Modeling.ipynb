{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifiers as clf\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "\n",
    "from imblearn.over_sampling  import SMOTENC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Species Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11347, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scientific Name</th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Federal Listing Status</th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "      <th>Days with AQI</th>\n",
       "      <th>Good Days</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>...</th>\n",
       "      <th>State_OR</th>\n",
       "      <th>State_PA</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accipiter gentilis</td>\n",
       "      <td>Northern goshawk</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acipenser fulvescens</td>\n",
       "      <td>Lake sturgeon</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acipenser oxyrinchus (=oxyrhynchus) desotoi</td>\n",
       "      <td>Atlantic sturgeon (Gulf subspecies)</td>\n",
       "      <td>Threatened</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agarodes alabamensis</td>\n",
       "      <td>[Unnamed] caddisfly</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agrimonia incisa</td>\n",
       "      <td>Incised groovebur</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Scientific Name  \\\n",
       "0                           Accipiter gentilis   \n",
       "1                         Acipenser fulvescens   \n",
       "2  Acipenser oxyrinchus (=oxyrhynchus) desotoi   \n",
       "3                         Agarodes alabamensis   \n",
       "4                             Agrimonia incisa   \n",
       "\n",
       "                           Common Name Federal Listing Status  \\\n",
       "0                     Northern goshawk             Not Listed   \n",
       "1                        Lake sturgeon             Not Listed   \n",
       "2  Atlantic sturgeon (Gulf subspecies)             Threatened   \n",
       "3                  [Unnamed] caddisfly             Not Listed   \n",
       "4                    Incised groovebur             Not Listed   \n",
       "\n",
       "   Total Land Area (Thousands of Acres)  \\\n",
       "0                                 32413   \n",
       "1                                 32413   \n",
       "2                                 32413   \n",
       "3                                 32413   \n",
       "4                                 32413   \n",
       "\n",
       "   Forest Land Area (Thousands of Acres)  Days with AQI  Good Days  \\\n",
       "0                                  22877            324        251   \n",
       "1                                  22877            324        251   \n",
       "2                                  22877            324        251   \n",
       "3                                  22877            324        251   \n",
       "4                                  22877            324        251   \n",
       "\n",
       "   Group_Amphibians  Group_Birds  Group_Clams    ...     State_OR  State_PA  \\\n",
       "0                 0            1            0    ...            0         0   \n",
       "1                 0            0            0    ...            0         0   \n",
       "2                 0            0            0    ...            0         0   \n",
       "3                 0            0            0    ...            0         0   \n",
       "4                 0            0            0    ...            0         0   \n",
       "\n",
       "   State_SC  State_TN  State_TX  State_UT  State_VA  State_WA  State_WV  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   State_WY  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = pd.read_pickle(\"../Data/species.pkl\")\n",
    "print(species.shape)\n",
    "species.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Target and Feature Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not Listed', 'Threatened', 'Endangered']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "      <th>Days with AQI</th>\n",
       "      <th>Good Days</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>Group_Crustaceans</th>\n",
       "      <th>Group_Ferns and Allies</th>\n",
       "      <th>Group_Fishes</th>\n",
       "      <th>...</th>\n",
       "      <th>State_OR</th>\n",
       "      <th>State_PA</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32413</td>\n",
       "      <td>22877</td>\n",
       "      <td>324</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Land Area (Thousands of Acres)  \\\n",
       "0                                 32413   \n",
       "1                                 32413   \n",
       "2                                 32413   \n",
       "3                                 32413   \n",
       "4                                 32413   \n",
       "\n",
       "   Forest Land Area (Thousands of Acres)  Days with AQI  Good Days  \\\n",
       "0                                  22877            324        251   \n",
       "1                                  22877            324        251   \n",
       "2                                  22877            324        251   \n",
       "3                                  22877            324        251   \n",
       "4                                  22877            324        251   \n",
       "\n",
       "   Group_Amphibians  Group_Birds  Group_Clams  Group_Crustaceans  \\\n",
       "0                 0            1            0                  0   \n",
       "1                 0            0            0                  0   \n",
       "2                 0            0            0                  0   \n",
       "3                 0            0            0                  0   \n",
       "4                 0            0            0                  0   \n",
       "\n",
       "   Group_Ferns and Allies  Group_Fishes    ...     State_OR  State_PA  \\\n",
       "0                       0             0    ...            0         0   \n",
       "1                       0             1    ...            0         0   \n",
       "2                       0             1    ...            0         0   \n",
       "3                       0             0    ...            0         0   \n",
       "4                       0             0    ...            0         0   \n",
       "\n",
       "   State_SC  State_TN  State_TX  State_UT  State_VA  State_WA  State_WV  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   State_WY  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create target variables\n",
    "y = species['Federal Listing Status']\n",
    "y_labels = list(y.unique())\n",
    "print(y_labels)\n",
    "\n",
    "# Create target variables\n",
    "X = species.drop(['Federal Listing Status', 'Scientific Name', 'Common Name'], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train Normal</th>\n",
       "      <th>Test Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Listed</th>\n",
       "      <td>6947</td>\n",
       "      <td>1728</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.761233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Endangered</th>\n",
       "      <td>1504</td>\n",
       "      <td>380</td>\n",
       "      <td>0.165694</td>\n",
       "      <td>0.167401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threatened</th>\n",
       "      <td>626</td>\n",
       "      <td>162</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.071366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>9077</td>\n",
       "      <td>2270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Train  Test  Train Normal  Test Normal\n",
       "Not Listed   6947  1728      0.765341     0.761233\n",
       "Endangered   1504   380      0.165694     0.167401\n",
       "Threatened    626   162      0.068966     0.071366\n",
       "Total        9077  2270      1.000000     1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# data set statistics\n",
    "data_sets = pd.DataFrame({'Train':        y_train.value_counts(),\n",
    "                          'Test':         y_test.value_counts(),\n",
    "                          'Train Normal': y_train.value_counts() / y_train.count(),\n",
    "                          'Test Normal':  y_test.value_counts()  / y_test.count()})\n",
    "\n",
    "data_sets.loc['Total'] = data_sets.sum().astype(int)\n",
    "data_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "      <th>Days with AQI</th>\n",
       "      <th>Good Days</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>Group_Crustaceans</th>\n",
       "      <th>Group_Ferns and Allies</th>\n",
       "      <th>Group_Fishes</th>\n",
       "      <th>...</th>\n",
       "      <th>State_OR</th>\n",
       "      <th>State_PA</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>4110</td>\n",
       "      <td>1748</td>\n",
       "      <td>362</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>99699</td>\n",
       "      <td>32618</td>\n",
       "      <td>365</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8354</th>\n",
       "      <td>43901</td>\n",
       "      <td>12646</td>\n",
       "      <td>361</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7708</th>\n",
       "      <td>30161</td>\n",
       "      <td>18966</td>\n",
       "      <td>364</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>4110</td>\n",
       "      <td>1748</td>\n",
       "      <td>362</td>\n",
       "      <td>355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total Land Area (Thousands of Acres)  \\\n",
       "5365                                  4110   \n",
       "1681                                 99699   \n",
       "8354                                 43901   \n",
       "7708                                 30161   \n",
       "5333                                  4110   \n",
       "\n",
       "      Forest Land Area (Thousands of Acres)  Days with AQI  Good Days  \\\n",
       "5365                                   1748            362        355   \n",
       "1681                                  32618            365        203   \n",
       "8354                                  12646            361        274   \n",
       "7708                                  18966            364        319   \n",
       "5333                                   1748            362        355   \n",
       "\n",
       "      Group_Amphibians  Group_Birds  Group_Clams  Group_Crustaceans  \\\n",
       "5365                 0            0            0                  0   \n",
       "1681                 0            0            0                  0   \n",
       "8354                 0            0            0                  0   \n",
       "7708                 0            0            0                  0   \n",
       "5333                 0            0            0                  0   \n",
       "\n",
       "      Group_Ferns and Allies  Group_Fishes    ...     State_OR  State_PA  \\\n",
       "5365                       0             0    ...            0         0   \n",
       "1681                       0             0    ...            0         0   \n",
       "8354                       0             0    ...            0         0   \n",
       "7708                       0             0    ...            0         0   \n",
       "5333                       0             0    ...            0         0   \n",
       "\n",
       "      State_SC  State_TN  State_TX  State_UT  State_VA  State_WA  State_WV  \\\n",
       "5365         0         0         0         0         0         0         0   \n",
       "1681         0         0         0         0         0         0         0   \n",
       "8354         0         0         0         0         0         0         0   \n",
       "7708         0         0         0         0         0         0         0   \n",
       "5333         0         0         0         0         0         0         0   \n",
       "\n",
       "      State_WY  \n",
       "5365         0  \n",
       "1681         0  \n",
       "8354         0  \n",
       "7708         0  \n",
       "5333         0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_categorical_cols = ['Total Land Area (Thousands of Acres)',\n",
    "                        'Forest Land Area (Thousands of Acres)',\n",
    "                        'Days with AQI',\n",
    "                        'Good Days']\n",
    "categorical_cols     = ['Group_Amphibians', 'Group_Birds', 'Group_Clams', 'Group_Crustaceans',\n",
    "                        'Group_Ferns and Allies', 'Group_Fishes', 'Group_Flowering Plants',\n",
    "                        'Group_Insects', 'Group_Mammals', 'Group_Reptiles', 'Group_Snails',\n",
    "                        'VIP_I', 'VIP_P', 'VIP_V', 'State_AL', 'State_AR', 'State_AZ',\n",
    "                        'State_CA', 'State_CO', 'State_FL', 'State_GA', 'State_HI', 'State_ID',\n",
    "                        'State_IL', 'State_IN', 'State_KY', 'State_MO', 'State_MS', 'State_NC',\n",
    "                        'State_NM', 'State_NY', 'State_OR', 'State_PA', 'State_SC', 'State_TN',\n",
    "                        'State_TX', 'State_UT', 'State_VA', 'State_WA', 'State_WV', 'State_WY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "      <th>Days with AQI</th>\n",
       "      <th>Good Days</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>Group_Crustaceans</th>\n",
       "      <th>Group_Ferns and Allies</th>\n",
       "      <th>Group_Fishes</th>\n",
       "      <th>...</th>\n",
       "      <th>State_OR</th>\n",
       "      <th>State_PA</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>0.009448</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>0.984211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>0.271368</td>\n",
       "      <td>0.251706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8354</th>\n",
       "      <td>0.118478</td>\n",
       "      <td>0.095963</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>0.638393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7708</th>\n",
       "      <td>0.080829</td>\n",
       "      <td>0.145247</td>\n",
       "      <td>0.994737</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>0.009448</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>0.984211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total Land Area (Thousands of Acres)  \\\n",
       "5365                              0.009448   \n",
       "1681                              0.271368   \n",
       "8354                              0.118478   \n",
       "7708                              0.080829   \n",
       "5333                              0.009448   \n",
       "\n",
       "      Forest Land Area (Thousands of Acres)  Days with AQI  Good Days  \\\n",
       "5365                               0.010980       0.984211   1.000000   \n",
       "1681                               0.251706       1.000000   0.321429   \n",
       "8354                               0.095963       0.978947   0.638393   \n",
       "7708                               0.145247       0.994737   0.839286   \n",
       "5333                               0.010980       0.984211   1.000000   \n",
       "\n",
       "      Group_Amphibians  Group_Birds  Group_Clams  Group_Crustaceans  \\\n",
       "5365                 0            0            0                  0   \n",
       "1681                 0            0            0                  0   \n",
       "8354                 0            0            0                  0   \n",
       "7708                 0            0            0                  0   \n",
       "5333                 0            0            0                  0   \n",
       "\n",
       "      Group_Ferns and Allies  Group_Fishes    ...     State_OR  State_PA  \\\n",
       "5365                       0             0    ...            0         0   \n",
       "1681                       0             0    ...            0         0   \n",
       "8354                       0             0    ...            0         0   \n",
       "7708                       0             0    ...            0         0   \n",
       "5333                       0             0    ...            0         0   \n",
       "\n",
       "      State_SC  State_TN  State_TX  State_UT  State_VA  State_WA  State_WV  \\\n",
       "5365         0         0         0         0         0         0         0   \n",
       "1681         0         0         0         0         0         0         0   \n",
       "8354         0         0         0         0         0         0         0   \n",
       "7708         0         0         0         0         0         0         0   \n",
       "5333         0         0         0         0         0         0         0   \n",
       "\n",
       "      State_WY  \n",
       "5365         0  \n",
       "1681         0  \n",
       "8354         0  \n",
       "7708         0  \n",
       "5333         0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler                        = MinMaxScaler()\n",
    "X_train[non_categorical_cols] = scaler.fit_transform(X_train[non_categorical_cols])\n",
    "X_test[non_categorical_cols]  = scaler.transform(X_test[non_categorical_cols])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model Hyper Parameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter grid search for all classifiers\n",
    "classifiers = []\n",
    "\n",
    "# dummy classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_dummy_classifier(dict(\n",
    "        strategy=['most_frequent','stratified'])))\n",
    "\n",
    "# logistic regression\n",
    "classifiers.append(\n",
    "    clf.grid_search_logistic_regression(dict(\n",
    "        C=[1e-2,1e0,1e2,1e6,1e12],\n",
    "        penalty=['l1', 'l2'],\n",
    "        fit_intercept=[True, False],\n",
    "        multi_class=['ovr'],\n",
    "        solver=['liblinear'])))\n",
    "\n",
    "# multinomial naive bayes classifer\n",
    "classifiers.append(\n",
    "    clf.grid_search_multinomial_nb(dict(\n",
    "        alpha=[0.0,1.0],\n",
    "        fit_prior=[True])))\n",
    "\n",
    "# k nearest neighbors classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_k_neighbors_classifier(dict(\n",
    "#        n_neighbors=[5,11],\n",
    "#        weights=['uniform', 'distance'],\n",
    "        algorithm=['ball_tree','kd_tree'],\n",
    "        leaf_size=[100,200])))\n",
    "\n",
    "# decision tree classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_decision_tree_classifier(dict(\n",
    "        criterion=['gini','entropy'],\n",
    "#        max_depth=[6,8],\n",
    "#        min_samples_leaf=[20,50,100],\n",
    "#        max_features=[20,30,40],\n",
    "        min_impurity_decrease=[0.01,0.03,0.05])))\n",
    "\n",
    "# random forest classifier\n",
    "classifiers.append(\n",
    "    clf.grid_search_random_forest_classifier(dict(\n",
    "        n_estimators=[100,200,300],\n",
    "#        max_depth=[2,3,4],\n",
    "#        min_samples_leaf=[100,200],\n",
    "#        max_features=[10,20],\n",
    "        min_impurity_decrease=[0.01,0.03,0.05])))\n",
    "\n",
    "# ada boost classifer\n",
    "classifiers.append(\n",
    "    clf.grid_search_ada_boost_classifier(dict(\n",
    "        n_estimators=[100,200,300],\n",
    "        learning_rate=[0.5,1.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Training Model 1:  Fish & Wildlife Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0894s.) Setting batch_size=4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.1838s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3329s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0996s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:   22.6s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   27.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Decision Tree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0787s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Random Forest\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:   10.9s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Ada Boost\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:   36.0s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   40.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.622783</td>\n",
       "      <td>0.615931</td>\n",
       "      <td>0.613969</td>\n",
       "      <td>0.619491</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.771400</td>\n",
       "      <td>0.683336</td>\n",
       "      <td>0.771400</td>\n",
       "      <td>0.680196</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.720512</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>[[1706, 0, 22], [149, 0, 13], [298, 0, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.772612</td>\n",
       "      <td>0.746253</td>\n",
       "      <td>0.772612</td>\n",
       "      <td>0.730774</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.771841</td>\n",
       "      <td>0.745799</td>\n",
       "      <td>0.771841</td>\n",
       "      <td>0.730279</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.753231</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.739054</td>\n",
       "      <td>[[1676, 30, 22], [126, 23, 13], [280, 18, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.769527</td>\n",
       "      <td>0.701591</td>\n",
       "      <td>0.769527</td>\n",
       "      <td>0.719172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.769638</td>\n",
       "      <td>0.702025</td>\n",
       "      <td>0.769638</td>\n",
       "      <td>0.719465</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.769307</td>\n",
       "      <td>0.701190</td>\n",
       "      <td>0.769307</td>\n",
       "      <td>0.718861</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.769417</td>\n",
       "      <td>0.701745</td>\n",
       "      <td>0.769417</td>\n",
       "      <td>0.719309</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.779736</td>\n",
       "      <td>0.727587</td>\n",
       "      <td>0.779736</td>\n",
       "      <td>0.734440</td>\n",
       "      <td>[[1657, 7, 64], [131, 7, 24], [265, 9, 106]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.718502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.718502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.718502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.768205</td>\n",
       "      <td>0.610027</td>\n",
       "      <td>0.768205</td>\n",
       "      <td>0.672531</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.718726</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.721851</td>\n",
       "      <td>[[1707, 0, 21], [149, 0, 13], [302, 0, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789248</td>\n",
       "      <td>0.750128</td>\n",
       "      <td>0.789248</td>\n",
       "      <td>0.725834</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789248</td>\n",
       "      <td>0.750198</td>\n",
       "      <td>0.789248</td>\n",
       "      <td>0.725877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.788917</td>\n",
       "      <td>0.749699</td>\n",
       "      <td>0.788917</td>\n",
       "      <td>0.725304</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.788917</td>\n",
       "      <td>0.749699</td>\n",
       "      <td>0.788917</td>\n",
       "      <td>0.725304</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.788917</td>\n",
       "      <td>0.749699</td>\n",
       "      <td>0.788917</td>\n",
       "      <td>0.725304</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.720512</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>[[1706, 0, 22], [149, 0, 13], [298, 0, 82]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data               Classifier  \\\n",
       "0   FWS                    Dummy   \n",
       "1   FWS                    Dummy   \n",
       "2   FWS                    Dummy   \n",
       "3   FWS      Logistic Regression   \n",
       "4   FWS      Logistic Regression   \n",
       "5   FWS      Logistic Regression   \n",
       "6   FWS      Logistic Regression   \n",
       "7   FWS      Logistic Regression   \n",
       "8   FWS      Logistic Regression   \n",
       "9   FWS      Logistic Regression   \n",
       "10  FWS      Logistic Regression   \n",
       "11  FWS      Logistic Regression   \n",
       "12  FWS      Logistic Regression   \n",
       "13  FWS      Logistic Regression   \n",
       "14  FWS      Logistic Regression   \n",
       "15  FWS      Logistic Regression   \n",
       "16  FWS      Logistic Regression   \n",
       "17  FWS      Logistic Regression   \n",
       "18  FWS      Logistic Regression   \n",
       "19  FWS      Logistic Regression   \n",
       "20  FWS      Logistic Regression   \n",
       "21  FWS      Logistic Regression   \n",
       "22  FWS      Logistic Regression   \n",
       "23  FWS      Logistic Regression   \n",
       "24  FWS  Multinomial Naive Bayes   \n",
       "25  FWS  Multinomial Naive Bayes   \n",
       "26  FWS  Multinomial Naive Bayes   \n",
       "27  FWS      K Nearest Neighbors   \n",
       "28  FWS      K Nearest Neighbors   \n",
       "29  FWS      K Nearest Neighbors   \n",
       "30  FWS      K Nearest Neighbors   \n",
       "31  FWS      K Nearest Neighbors   \n",
       "32  FWS            Decision Tree   \n",
       "33  FWS            Decision Tree   \n",
       "34  FWS            Decision Tree   \n",
       "35  FWS            Decision Tree   \n",
       "36  FWS            Decision Tree   \n",
       "37  FWS            Decision Tree   \n",
       "38  FWS            Decision Tree   \n",
       "39  FWS            Random Forest   \n",
       "40  FWS            Random Forest   \n",
       "41  FWS            Random Forest   \n",
       "42  FWS            Random Forest   \n",
       "43  FWS            Random Forest   \n",
       "44  FWS            Random Forest   \n",
       "45  FWS            Random Forest   \n",
       "46  FWS            Random Forest   \n",
       "47  FWS            Random Forest   \n",
       "48  FWS            Random Forest   \n",
       "49  FWS                Ada Boost   \n",
       "50  FWS                Ada Boost   \n",
       "51  FWS                Ada Boost   \n",
       "52  FWS                Ada Boost   \n",
       "53  FWS                Ada Boost   \n",
       "54  FWS                Ada Boost   \n",
       "55  FWS                Ada Boost   \n",
       "\n",
       "                                           Parameters  Split  Accuracy  \\\n",
       "0                       {'strategy': 'most_frequent'}  Train  0.765341   \n",
       "1                          {'strategy': 'stratified'}  Train  0.622783   \n",
       "2                       {'strategy': 'most_frequent'}   Test  0.761233   \n",
       "3   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.765341   \n",
       "4   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.765341   \n",
       "5   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.765341   \n",
       "6   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.771400   \n",
       "7   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.789027   \n",
       "8   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.789027   \n",
       "9   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.789027   \n",
       "10  {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.789027   \n",
       "11  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.789137   \n",
       "12  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.789137   \n",
       "13  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.789137   \n",
       "14  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.789137   \n",
       "15  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.789137   \n",
       "16  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.789137   \n",
       "17  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.789137   \n",
       "18  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.789137   \n",
       "19  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.789137   \n",
       "20  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.789137   \n",
       "21  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.789137   \n",
       "22  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.789137   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...   Test  0.787665   \n",
       "24                  {'alpha': 0.0, 'fit_prior': True}  Train  0.772612   \n",
       "25                  {'alpha': 1.0, 'fit_prior': True}  Train  0.771841   \n",
       "26                  {'alpha': 0.0, 'fit_prior': True}   Test  0.784581   \n",
       "27       {'algorithm': 'ball_tree', 'leaf_size': 100}  Train  0.769527   \n",
       "28       {'algorithm': 'ball_tree', 'leaf_size': 200}  Train  0.769638   \n",
       "29         {'algorithm': 'kd_tree', 'leaf_size': 100}  Train  0.769307   \n",
       "30         {'algorithm': 'kd_tree', 'leaf_size': 200}  Train  0.769417   \n",
       "31       {'algorithm': 'ball_tree', 'leaf_size': 200}   Test  0.779736   \n",
       "32  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.785392   \n",
       "33  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.765341   \n",
       "34  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.765341   \n",
       "35  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.785392   \n",
       "36  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.785392   \n",
       "37  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.768205   \n",
       "38  {'criterion': 'gini', 'min_impurity_decrease':...   Test  0.786344   \n",
       "39  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.765341   \n",
       "40  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.765341   \n",
       "41  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.765341   \n",
       "42  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.765341   \n",
       "43  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.765341   \n",
       "44  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.765341   \n",
       "45  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.765341   \n",
       "46  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.765341   \n",
       "47  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.765341   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...   Test  0.761233   \n",
       "49        {'learning_rate': 0.5, 'n_estimators': 100}  Train  0.789137   \n",
       "50        {'learning_rate': 0.5, 'n_estimators': 200}  Train  0.789248   \n",
       "51        {'learning_rate': 0.5, 'n_estimators': 300}  Train  0.789248   \n",
       "52        {'learning_rate': 1.0, 'n_estimators': 100}  Train  0.788917   \n",
       "53        {'learning_rate': 1.0, 'n_estimators': 200}  Train  0.788917   \n",
       "54        {'learning_rate': 1.0, 'n_estimators': 300}  Train  0.788917   \n",
       "55        {'learning_rate': 0.5, 'n_estimators': 300}   Test  0.787665   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "0    0.585747  0.765341  0.663608   \n",
       "1    0.615931  0.613969  0.619491   \n",
       "2    0.579476  0.761233  0.658035   \n",
       "3    0.585747  0.765341  0.663608   \n",
       "4    0.585747  0.765341  0.663608   \n",
       "5    0.585747  0.765341  0.663608   \n",
       "6    0.683336  0.771400  0.680196   \n",
       "7    0.724311  0.789027  0.725039   \n",
       "8    0.724311  0.789027  0.725039   \n",
       "9    0.724311  0.789027  0.725039   \n",
       "10   0.724311  0.789027  0.725039   \n",
       "11   0.724582  0.789137  0.725121   \n",
       "12   0.724582  0.789137  0.725121   \n",
       "13   0.724582  0.789137  0.725121   \n",
       "14   0.724582  0.789137  0.725121   \n",
       "15   0.724582  0.789137  0.725121   \n",
       "16   0.724582  0.789137  0.725121   \n",
       "17   0.724582  0.789137  0.725121   \n",
       "18   0.724582  0.789137  0.725121   \n",
       "19   0.724582  0.789137  0.725121   \n",
       "20   0.724582  0.789137  0.725121   \n",
       "21   0.724582  0.789137  0.725121   \n",
       "22   0.724582  0.789137  0.725121   \n",
       "23   0.720512  0.787665  0.724481   \n",
       "24   0.746253  0.772612  0.730774   \n",
       "25   0.745799  0.771841  0.730279   \n",
       "26   0.753231  0.784581  0.739054   \n",
       "27   0.701591  0.769527  0.719172   \n",
       "28   0.702025  0.769638  0.719465   \n",
       "29   0.701190  0.769307  0.718861   \n",
       "30   0.701745  0.769417  0.719309   \n",
       "31   0.727587  0.779736  0.734440   \n",
       "32   0.719259  0.785392  0.718502   \n",
       "33   0.585747  0.765341  0.663608   \n",
       "34   0.585747  0.765341  0.663608   \n",
       "35   0.719259  0.785392  0.718502   \n",
       "36   0.719259  0.785392  0.718502   \n",
       "37   0.610027  0.768205  0.672531   \n",
       "38   0.718726  0.786344  0.721851   \n",
       "39   0.585747  0.765341  0.663608   \n",
       "40   0.585747  0.765341  0.663608   \n",
       "41   0.585747  0.765341  0.663608   \n",
       "42   0.585747  0.765341  0.663608   \n",
       "43   0.585747  0.765341  0.663608   \n",
       "44   0.585747  0.765341  0.663608   \n",
       "45   0.585747  0.765341  0.663608   \n",
       "46   0.585747  0.765341  0.663608   \n",
       "47   0.585747  0.765341  0.663608   \n",
       "48   0.579476  0.761233  0.658035   \n",
       "49   0.724582  0.789137  0.725121   \n",
       "50   0.750128  0.789248  0.725834   \n",
       "51   0.750198  0.789248  0.725877   \n",
       "52   0.749699  0.788917  0.725304   \n",
       "53   0.749699  0.788917  0.725304   \n",
       "54   0.749699  0.788917  0.725304   \n",
       "55   0.720512  0.787665  0.724481   \n",
       "\n",
       "                                  Confusion Matrix  \n",
       "0                                              NaN  \n",
       "1                                              NaN  \n",
       "2         [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  \n",
       "3                                              NaN  \n",
       "4                                              NaN  \n",
       "5                                              NaN  \n",
       "6                                              NaN  \n",
       "7                                              NaN  \n",
       "8                                              NaN  \n",
       "9                                              NaN  \n",
       "10                                             NaN  \n",
       "11                                             NaN  \n",
       "12                                             NaN  \n",
       "13                                             NaN  \n",
       "14                                             NaN  \n",
       "15                                             NaN  \n",
       "16                                             NaN  \n",
       "17                                             NaN  \n",
       "18                                             NaN  \n",
       "19                                             NaN  \n",
       "20                                             NaN  \n",
       "21                                             NaN  \n",
       "22                                             NaN  \n",
       "23     [[1706, 0, 22], [149, 0, 13], [298, 0, 82]]  \n",
       "24                                             NaN  \n",
       "25                                             NaN  \n",
       "26  [[1676, 30, 22], [126, 23, 13], [280, 18, 82]]  \n",
       "27                                             NaN  \n",
       "28                                             NaN  \n",
       "29                                             NaN  \n",
       "30                                             NaN  \n",
       "31    [[1657, 7, 64], [131, 7, 24], [265, 9, 106]]  \n",
       "32                                             NaN  \n",
       "33                                             NaN  \n",
       "34                                             NaN  \n",
       "35                                             NaN  \n",
       "36                                             NaN  \n",
       "37                                             NaN  \n",
       "38     [[1707, 0, 21], [149, 0, 13], [302, 0, 78]]  \n",
       "39                                             NaN  \n",
       "40                                             NaN  \n",
       "41                                             NaN  \n",
       "42                                             NaN  \n",
       "43                                             NaN  \n",
       "44                                             NaN  \n",
       "45                                             NaN  \n",
       "46                                             NaN  \n",
       "47                                             NaN  \n",
       "48        [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  \n",
       "49                                             NaN  \n",
       "50                                             NaN  \n",
       "51                                             NaN  \n",
       "52                                             NaN  \n",
       "53                                             NaN  \n",
       "54                                             NaN  \n",
       "55     [[1706, 0, 22], [149, 0, 13], [298, 0, 82]]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fws = X_train[categorical_cols]\n",
    "X_test_fws  = X_test[categorical_cols]\n",
    "\n",
    "# run FWS dataset\n",
    "model_fws = clf.fit_predict_measure(\n",
    "    'FWS', X_train_fws, X_test_fws, y_train, y_test, y_labels, classifiers)\n",
    "model_fws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.775529</td>\n",
       "      <td>0.678886</td>\n",
       "      <td>0.775372</td>\n",
       "      <td>0.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.067169</td>\n",
       "      <td>0.024554</td>\n",
       "      <td>0.031164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.622783</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.613969</td>\n",
       "      <td>0.619491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.784987</td>\n",
       "      <td>0.719885</td>\n",
       "      <td>0.784987</td>\n",
       "      <td>0.723166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.789248</td>\n",
       "      <td>0.753231</td>\n",
       "      <td>0.789248</td>\n",
       "      <td>0.739054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall   F1 Score\n",
       "count  56.000000  56.000000  56.000000  56.000000\n",
       "mean    0.775529   0.678886   0.775372   0.702400\n",
       "std     0.023506   0.067169   0.024554   0.031164\n",
       "min     0.622783   0.579476   0.613969   0.619491\n",
       "25%     0.765341   0.585747   0.765341   0.663608\n",
       "50%     0.784987   0.719885   0.784987   0.723166\n",
       "75%     0.789137   0.724582   0.789137   0.725121\n",
       "max     0.789248   0.753231   0.789248   0.739054"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of FWS classifiers (test and training sets)\n",
    "model_fws.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.753231</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.739054</td>\n",
       "      <td>[[1676, 30, 22], [126, 23, 13], [280, 18, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FWS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.779736</td>\n",
       "      <td>0.727587</td>\n",
       "      <td>0.779736</td>\n",
       "      <td>0.734440</td>\n",
       "      <td>[[1657, 7, 64], [131, 7, 24], [265, 9, 106]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.720512</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>[[1706, 0, 22], [149, 0, 13], [298, 0, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.720512</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>[[1706, 0, 22], [149, 0, 13], [298, 0, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.718726</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.721851</td>\n",
       "      <td>[[1707, 0, 21], [149, 0, 13], [302, 0, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FWS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data               Classifier  \\\n",
       "26  FWS  Multinomial Naive Bayes   \n",
       "31  FWS      K Nearest Neighbors   \n",
       "23  FWS      Logistic Regression   \n",
       "55  FWS                Ada Boost   \n",
       "38  FWS            Decision Tree   \n",
       "2   FWS                    Dummy   \n",
       "48  FWS            Random Forest   \n",
       "\n",
       "                                           Parameters Split  Accuracy  \\\n",
       "26                  {'alpha': 0.0, 'fit_prior': True}  Test  0.784581   \n",
       "31       {'algorithm': 'ball_tree', 'leaf_size': 200}  Test  0.779736   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Test  0.787665   \n",
       "55        {'learning_rate': 0.5, 'n_estimators': 300}  Test  0.787665   \n",
       "38  {'criterion': 'gini', 'min_impurity_decrease':...  Test  0.786344   \n",
       "2                       {'strategy': 'most_frequent'}  Test  0.761233   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...  Test  0.761233   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "26   0.753231  0.784581  0.739054   \n",
       "31   0.727587  0.779736  0.734440   \n",
       "23   0.720512  0.787665  0.724481   \n",
       "55   0.720512  0.787665  0.724481   \n",
       "38   0.718726  0.786344  0.721851   \n",
       "2    0.579476  0.761233  0.658035   \n",
       "48   0.579476  0.761233  0.658035   \n",
       "\n",
       "                                  Confusion Matrix  \n",
       "26  [[1676, 30, 22], [126, 23, 13], [280, 18, 82]]  \n",
       "31    [[1657, 7, 64], [131, 7, 24], [265, 9, 106]]  \n",
       "23     [[1706, 0, 22], [149, 0, 13], [298, 0, 82]]  \n",
       "55     [[1706, 0, 22], [149, 0, 13], [298, 0, 82]]  \n",
       "38     [[1707, 0, 21], [149, 0, 13], [302, 0, 78]]  \n",
       "2         [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  \n",
       "48        [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators of FWS dataset\n",
    "model_fws_test = model_fws[model_fws['Split'] == 'Test']\n",
    "model_fws_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Training Model 2:  FWS + Forest Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1125s.) Setting batch_size=2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.3147s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   13.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0887s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:   30.4s remaining:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   32.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Decision Tree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0731s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Random Forest\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:   11.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Ada Boost\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:   38.8s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   44.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.616173</td>\n",
       "      <td>0.617731</td>\n",
       "      <td>0.620800</td>\n",
       "      <td>0.623921</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.772282</td>\n",
       "      <td>0.722466</td>\n",
       "      <td>0.772282</td>\n",
       "      <td>0.682287</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.720512</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>[[1706, 0, 22], [149, 0, 13], [298, 0, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.772282</td>\n",
       "      <td>0.745618</td>\n",
       "      <td>0.772282</td>\n",
       "      <td>0.730543</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.771400</td>\n",
       "      <td>0.745311</td>\n",
       "      <td>0.771400</td>\n",
       "      <td>0.730094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.753231</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.739054</td>\n",
       "      <td>[[1676, 30, 22], [126, 23, 13], [280, 18, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.766332</td>\n",
       "      <td>0.702210</td>\n",
       "      <td>0.766332</td>\n",
       "      <td>0.719886</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765892</td>\n",
       "      <td>0.702007</td>\n",
       "      <td>0.765892</td>\n",
       "      <td>0.720175</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.767104</td>\n",
       "      <td>0.704071</td>\n",
       "      <td>0.767104</td>\n",
       "      <td>0.720569</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.766443</td>\n",
       "      <td>0.702822</td>\n",
       "      <td>0.766443</td>\n",
       "      <td>0.720599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.760793</td>\n",
       "      <td>0.703036</td>\n",
       "      <td>0.760793</td>\n",
       "      <td>0.717845</td>\n",
       "      <td>[[1617, 6, 105], [135, 4, 23], [268, 6, 106]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.718502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.718502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.718502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.768205</td>\n",
       "      <td>0.610027</td>\n",
       "      <td>0.768205</td>\n",
       "      <td>0.672531</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.718726</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.721851</td>\n",
       "      <td>[[1707, 0, 21], [149, 0, 13], [302, 0, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724634</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725109</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.788917</td>\n",
       "      <td>0.745342</td>\n",
       "      <td>0.788917</td>\n",
       "      <td>0.725723</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.752367</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.726026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.788697</td>\n",
       "      <td>0.749467</td>\n",
       "      <td>0.788697</td>\n",
       "      <td>0.725511</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.749966</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.726085</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.788807</td>\n",
       "      <td>0.750104</td>\n",
       "      <td>0.788807</td>\n",
       "      <td>0.726400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.720792</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.724654</td>\n",
       "      <td>[[1706, 0, 22], [149, 0, 13], [297, 1, 82]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Data               Classifier  \\\n",
       "0   FWS_FS                    Dummy   \n",
       "1   FWS_FS                    Dummy   \n",
       "2   FWS_FS                    Dummy   \n",
       "3   FWS_FS      Logistic Regression   \n",
       "4   FWS_FS      Logistic Regression   \n",
       "5   FWS_FS      Logistic Regression   \n",
       "6   FWS_FS      Logistic Regression   \n",
       "7   FWS_FS      Logistic Regression   \n",
       "8   FWS_FS      Logistic Regression   \n",
       "9   FWS_FS      Logistic Regression   \n",
       "10  FWS_FS      Logistic Regression   \n",
       "11  FWS_FS      Logistic Regression   \n",
       "12  FWS_FS      Logistic Regression   \n",
       "13  FWS_FS      Logistic Regression   \n",
       "14  FWS_FS      Logistic Regression   \n",
       "15  FWS_FS      Logistic Regression   \n",
       "16  FWS_FS      Logistic Regression   \n",
       "17  FWS_FS      Logistic Regression   \n",
       "18  FWS_FS      Logistic Regression   \n",
       "19  FWS_FS      Logistic Regression   \n",
       "20  FWS_FS      Logistic Regression   \n",
       "21  FWS_FS      Logistic Regression   \n",
       "22  FWS_FS      Logistic Regression   \n",
       "23  FWS_FS      Logistic Regression   \n",
       "24  FWS_FS  Multinomial Naive Bayes   \n",
       "25  FWS_FS  Multinomial Naive Bayes   \n",
       "26  FWS_FS  Multinomial Naive Bayes   \n",
       "27  FWS_FS      K Nearest Neighbors   \n",
       "28  FWS_FS      K Nearest Neighbors   \n",
       "29  FWS_FS      K Nearest Neighbors   \n",
       "30  FWS_FS      K Nearest Neighbors   \n",
       "31  FWS_FS      K Nearest Neighbors   \n",
       "32  FWS_FS            Decision Tree   \n",
       "33  FWS_FS            Decision Tree   \n",
       "34  FWS_FS            Decision Tree   \n",
       "35  FWS_FS            Decision Tree   \n",
       "36  FWS_FS            Decision Tree   \n",
       "37  FWS_FS            Decision Tree   \n",
       "38  FWS_FS            Decision Tree   \n",
       "39  FWS_FS            Random Forest   \n",
       "40  FWS_FS            Random Forest   \n",
       "41  FWS_FS            Random Forest   \n",
       "42  FWS_FS            Random Forest   \n",
       "43  FWS_FS            Random Forest   \n",
       "44  FWS_FS            Random Forest   \n",
       "45  FWS_FS            Random Forest   \n",
       "46  FWS_FS            Random Forest   \n",
       "47  FWS_FS            Random Forest   \n",
       "48  FWS_FS            Random Forest   \n",
       "49  FWS_FS                Ada Boost   \n",
       "50  FWS_FS                Ada Boost   \n",
       "51  FWS_FS                Ada Boost   \n",
       "52  FWS_FS                Ada Boost   \n",
       "53  FWS_FS                Ada Boost   \n",
       "54  FWS_FS                Ada Boost   \n",
       "55  FWS_FS                Ada Boost   \n",
       "\n",
       "                                           Parameters  Split  Accuracy  \\\n",
       "0                       {'strategy': 'most_frequent'}  Train  0.765341   \n",
       "1                          {'strategy': 'stratified'}  Train  0.616173   \n",
       "2                       {'strategy': 'most_frequent'}   Test  0.761233   \n",
       "3   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.765341   \n",
       "4   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.765341   \n",
       "5   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.765341   \n",
       "6   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.772282   \n",
       "7   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.789027   \n",
       "8   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.789027   \n",
       "9   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.789027   \n",
       "10  {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.789027   \n",
       "11  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.789137   \n",
       "12  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.789137   \n",
       "13  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.789137   \n",
       "14  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.789137   \n",
       "15  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.789137   \n",
       "16  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.789137   \n",
       "17  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.789137   \n",
       "18  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.789137   \n",
       "19  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.789137   \n",
       "20  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.789137   \n",
       "21  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.789137   \n",
       "22  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.789137   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...   Test  0.787665   \n",
       "24                  {'alpha': 0.0, 'fit_prior': True}  Train  0.772282   \n",
       "25                  {'alpha': 1.0, 'fit_prior': True}  Train  0.771400   \n",
       "26                  {'alpha': 0.0, 'fit_prior': True}   Test  0.784581   \n",
       "27       {'algorithm': 'ball_tree', 'leaf_size': 100}  Train  0.766332   \n",
       "28       {'algorithm': 'ball_tree', 'leaf_size': 200}  Train  0.765892   \n",
       "29         {'algorithm': 'kd_tree', 'leaf_size': 100}  Train  0.767104   \n",
       "30         {'algorithm': 'kd_tree', 'leaf_size': 200}  Train  0.766443   \n",
       "31         {'algorithm': 'kd_tree', 'leaf_size': 200}   Test  0.760793   \n",
       "32  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.785392   \n",
       "33  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.765341   \n",
       "34  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.765341   \n",
       "35  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.785392   \n",
       "36  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.785392   \n",
       "37  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.768205   \n",
       "38  {'criterion': 'gini', 'min_impurity_decrease':...   Test  0.786344   \n",
       "39  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.765341   \n",
       "40  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.765341   \n",
       "41  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.765341   \n",
       "42  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.765341   \n",
       "43  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.765341   \n",
       "44  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.765341   \n",
       "45  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.765341   \n",
       "46  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.765341   \n",
       "47  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.765341   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...   Test  0.761233   \n",
       "49        {'learning_rate': 0.5, 'n_estimators': 100}  Train  0.789027   \n",
       "50        {'learning_rate': 0.5, 'n_estimators': 200}  Train  0.788917   \n",
       "51        {'learning_rate': 0.5, 'n_estimators': 300}  Train  0.789027   \n",
       "52        {'learning_rate': 1.0, 'n_estimators': 100}  Train  0.788697   \n",
       "53        {'learning_rate': 1.0, 'n_estimators': 200}  Train  0.789027   \n",
       "54        {'learning_rate': 1.0, 'n_estimators': 300}  Train  0.788807   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 300}   Test  0.787665   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "0    0.585747  0.765341  0.663608   \n",
       "1    0.617731  0.620800  0.623921   \n",
       "2    0.579476  0.761233  0.658035   \n",
       "3    0.585747  0.765341  0.663608   \n",
       "4    0.585747  0.765341  0.663608   \n",
       "5    0.585747  0.765341  0.663608   \n",
       "6    0.722466  0.772282  0.682287   \n",
       "7    0.724311  0.789027  0.725039   \n",
       "8    0.724311  0.789027  0.725039   \n",
       "9    0.724311  0.789027  0.725039   \n",
       "10   0.724311  0.789027  0.725039   \n",
       "11   0.724582  0.789137  0.725121   \n",
       "12   0.724582  0.789137  0.725121   \n",
       "13   0.724582  0.789137  0.725121   \n",
       "14   0.724582  0.789137  0.725121   \n",
       "15   0.724582  0.789137  0.725121   \n",
       "16   0.724582  0.789137  0.725121   \n",
       "17   0.724582  0.789137  0.725121   \n",
       "18   0.724582  0.789137  0.725121   \n",
       "19   0.724582  0.789137  0.725121   \n",
       "20   0.724582  0.789137  0.725121   \n",
       "21   0.724582  0.789137  0.725121   \n",
       "22   0.724582  0.789137  0.725121   \n",
       "23   0.720512  0.787665  0.724481   \n",
       "24   0.745618  0.772282  0.730543   \n",
       "25   0.745311  0.771400  0.730094   \n",
       "26   0.753231  0.784581  0.739054   \n",
       "27   0.702210  0.766332  0.719886   \n",
       "28   0.702007  0.765892  0.720175   \n",
       "29   0.704071  0.767104  0.720569   \n",
       "30   0.702822  0.766443  0.720599   \n",
       "31   0.703036  0.760793  0.717845   \n",
       "32   0.719259  0.785392  0.718502   \n",
       "33   0.585747  0.765341  0.663608   \n",
       "34   0.585747  0.765341  0.663608   \n",
       "35   0.719259  0.785392  0.718502   \n",
       "36   0.719259  0.785392  0.718502   \n",
       "37   0.610027  0.768205  0.672531   \n",
       "38   0.718726  0.786344  0.721851   \n",
       "39   0.585747  0.765341  0.663608   \n",
       "40   0.585747  0.765341  0.663608   \n",
       "41   0.585747  0.765341  0.663608   \n",
       "42   0.585747  0.765341  0.663608   \n",
       "43   0.585747  0.765341  0.663608   \n",
       "44   0.585747  0.765341  0.663608   \n",
       "45   0.585747  0.765341  0.663608   \n",
       "46   0.585747  0.765341  0.663608   \n",
       "47   0.585747  0.765341  0.663608   \n",
       "48   0.579476  0.761233  0.658035   \n",
       "49   0.724634  0.789027  0.725109   \n",
       "50   0.745342  0.788917  0.725723   \n",
       "51   0.752367  0.789027  0.726026   \n",
       "52   0.749467  0.788697  0.725511   \n",
       "53   0.749966  0.789027  0.726085   \n",
       "54   0.750104  0.788807  0.726400   \n",
       "55   0.720792  0.787665  0.724654   \n",
       "\n",
       "                                  Confusion Matrix  \n",
       "0                                              NaN  \n",
       "1                                              NaN  \n",
       "2         [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  \n",
       "3                                              NaN  \n",
       "4                                              NaN  \n",
       "5                                              NaN  \n",
       "6                                              NaN  \n",
       "7                                              NaN  \n",
       "8                                              NaN  \n",
       "9                                              NaN  \n",
       "10                                             NaN  \n",
       "11                                             NaN  \n",
       "12                                             NaN  \n",
       "13                                             NaN  \n",
       "14                                             NaN  \n",
       "15                                             NaN  \n",
       "16                                             NaN  \n",
       "17                                             NaN  \n",
       "18                                             NaN  \n",
       "19                                             NaN  \n",
       "20                                             NaN  \n",
       "21                                             NaN  \n",
       "22                                             NaN  \n",
       "23     [[1706, 0, 22], [149, 0, 13], [298, 0, 82]]  \n",
       "24                                             NaN  \n",
       "25                                             NaN  \n",
       "26  [[1676, 30, 22], [126, 23, 13], [280, 18, 82]]  \n",
       "27                                             NaN  \n",
       "28                                             NaN  \n",
       "29                                             NaN  \n",
       "30                                             NaN  \n",
       "31   [[1617, 6, 105], [135, 4, 23], [268, 6, 106]]  \n",
       "32                                             NaN  \n",
       "33                                             NaN  \n",
       "34                                             NaN  \n",
       "35                                             NaN  \n",
       "36                                             NaN  \n",
       "37                                             NaN  \n",
       "38     [[1707, 0, 21], [149, 0, 13], [302, 0, 78]]  \n",
       "39                                             NaN  \n",
       "40                                             NaN  \n",
       "41                                             NaN  \n",
       "42                                             NaN  \n",
       "43                                             NaN  \n",
       "44                                             NaN  \n",
       "45                                             NaN  \n",
       "46                                             NaN  \n",
       "47                                             NaN  \n",
       "48        [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  \n",
       "49                                             NaN  \n",
       "50                                             NaN  \n",
       "51                                             NaN  \n",
       "52                                             NaN  \n",
       "53                                             NaN  \n",
       "54                                             NaN  \n",
       "55     [[1706, 0, 22], [149, 0, 13], [297, 1, 82]]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fws_fs = X_train.drop(['Days with AQI', 'Good Days'], axis=1)\n",
    "X_test_fws_fs  = X_test.drop(['Days with AQI', 'Good Days'], axis=1)\n",
    "\n",
    "# run FWS + FS dataset\n",
    "model_fws_fs = clf.fit_predict_measure(\n",
    "    'FWS_FS', X_train_fws_fs, X_test_fws_fs, y_train, y_test, y_labels, classifiers)\n",
    "model_fws_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.774842</td>\n",
       "      <td>0.679207</td>\n",
       "      <td>0.774925</td>\n",
       "      <td>0.702333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.024415</td>\n",
       "      <td>0.067125</td>\n",
       "      <td>0.023870</td>\n",
       "      <td>0.030767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.616173</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.620800</td>\n",
       "      <td>0.623921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.784987</td>\n",
       "      <td>0.719885</td>\n",
       "      <td>0.784987</td>\n",
       "      <td>0.721225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.753231</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.739054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall   F1 Score\n",
       "count  56.000000  56.000000  56.000000  56.000000\n",
       "mean    0.774842   0.679207   0.774925   0.702333\n",
       "std     0.024415   0.067125   0.023870   0.030767\n",
       "min     0.616173   0.579476   0.620800   0.623921\n",
       "25%     0.765341   0.585747   0.765341   0.663608\n",
       "50%     0.784987   0.719885   0.784987   0.721225\n",
       "75%     0.789027   0.724582   0.789027   0.725121\n",
       "max     0.789137   0.753231   0.789137   0.739054"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of FWS + FS classifiers (test and training sets)\n",
    "model_fws_fs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.753231</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.739054</td>\n",
       "      <td>[[1676, 30, 22], [126, 23, 13], [280, 18, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.720792</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.724654</td>\n",
       "      <td>[[1706, 0, 22], [149, 0, 13], [297, 1, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.720512</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>[[1706, 0, 22], [149, 0, 13], [298, 0, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.718726</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.721851</td>\n",
       "      <td>[[1707, 0, 21], [149, 0, 13], [302, 0, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.760793</td>\n",
       "      <td>0.703036</td>\n",
       "      <td>0.760793</td>\n",
       "      <td>0.717845</td>\n",
       "      <td>[[1617, 6, 105], [135, 4, 23], [268, 6, 106]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FWS_FS</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Data               Classifier  \\\n",
       "26  FWS_FS  Multinomial Naive Bayes   \n",
       "55  FWS_FS                Ada Boost   \n",
       "23  FWS_FS      Logistic Regression   \n",
       "38  FWS_FS            Decision Tree   \n",
       "31  FWS_FS      K Nearest Neighbors   \n",
       "2   FWS_FS                    Dummy   \n",
       "48  FWS_FS            Random Forest   \n",
       "\n",
       "                                           Parameters Split  Accuracy  \\\n",
       "26                  {'alpha': 0.0, 'fit_prior': True}  Test  0.784581   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 300}  Test  0.787665   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Test  0.787665   \n",
       "38  {'criterion': 'gini', 'min_impurity_decrease':...  Test  0.786344   \n",
       "31         {'algorithm': 'kd_tree', 'leaf_size': 200}  Test  0.760793   \n",
       "2                       {'strategy': 'most_frequent'}  Test  0.761233   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...  Test  0.761233   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "26   0.753231  0.784581  0.739054   \n",
       "55   0.720792  0.787665  0.724654   \n",
       "23   0.720512  0.787665  0.724481   \n",
       "38   0.718726  0.786344  0.721851   \n",
       "31   0.703036  0.760793  0.717845   \n",
       "2    0.579476  0.761233  0.658035   \n",
       "48   0.579476  0.761233  0.658035   \n",
       "\n",
       "                                  Confusion Matrix  \n",
       "26  [[1676, 30, 22], [126, 23, 13], [280, 18, 82]]  \n",
       "55     [[1706, 0, 22], [149, 0, 13], [297, 1, 82]]  \n",
       "23     [[1706, 0, 22], [149, 0, 13], [298, 0, 82]]  \n",
       "38     [[1707, 0, 21], [149, 0, 13], [302, 0, 78]]  \n",
       "31   [[1617, 6, 105], [135, 4, 23], [268, 6, 106]]  \n",
       "2         [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  \n",
       "48        [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators of FWS + FS dataset\n",
    "model_fws_fs_test = model_fws_fs[model_fws_fs['Split'] == 'Test']\n",
    "model_fws_fs_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Training Model 3:  FWS + FS + Environmental Protection Agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1104s.) Setting batch_size=2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0499s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done  85 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   32.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1193s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:   30.1s remaining:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   32.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Decision Tree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0591s.) Setting batch_size=6.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  30 | elapsed:    0.2s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Random Forest\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:   10.4s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Ada Boost\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:   38.2s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   42.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.614961</td>\n",
       "      <td>0.614287</td>\n",
       "      <td>0.612097</td>\n",
       "      <td>0.623732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.761375</td>\n",
       "      <td>0.611878</td>\n",
       "      <td>0.761375</td>\n",
       "      <td>0.664447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765231</td>\n",
       "      <td>0.585727</td>\n",
       "      <td>0.765231</td>\n",
       "      <td>0.663553</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.725121</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.720512</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>[[1706, 0, 22], [149, 0, 13], [298, 0, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.772171</td>\n",
       "      <td>0.745318</td>\n",
       "      <td>0.772171</td>\n",
       "      <td>0.730464</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.771290</td>\n",
       "      <td>0.745011</td>\n",
       "      <td>0.771290</td>\n",
       "      <td>0.730016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.753231</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.739054</td>\n",
       "      <td>[[1676, 30, 22], [126, 23, 13], [280, 18, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.697777</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.719936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.766112</td>\n",
       "      <td>0.699410</td>\n",
       "      <td>0.766112</td>\n",
       "      <td>0.720842</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765451</td>\n",
       "      <td>0.697804</td>\n",
       "      <td>0.765451</td>\n",
       "      <td>0.720105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.767104</td>\n",
       "      <td>0.700679</td>\n",
       "      <td>0.767104</td>\n",
       "      <td>0.721662</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.768722</td>\n",
       "      <td>0.715217</td>\n",
       "      <td>0.768722</td>\n",
       "      <td>0.722568</td>\n",
       "      <td>[[1638, 6, 84], [137, 5, 20], [274, 4, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.718502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.718502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>0.785392</td>\n",
       "      <td>0.718502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.768205</td>\n",
       "      <td>0.610027</td>\n",
       "      <td>0.768205</td>\n",
       "      <td>0.672531</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.718726</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.721851</td>\n",
       "      <td>[[1707, 0, 21], [149, 0, 13], [302, 0, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724634</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725109</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.788807</td>\n",
       "      <td>0.731500</td>\n",
       "      <td>0.788807</td>\n",
       "      <td>0.725461</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.752367</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.726026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.788697</td>\n",
       "      <td>0.744562</td>\n",
       "      <td>0.788697</td>\n",
       "      <td>0.725874</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.788587</td>\n",
       "      <td>0.748539</td>\n",
       "      <td>0.788587</td>\n",
       "      <td>0.726096</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.788366</td>\n",
       "      <td>0.742389</td>\n",
       "      <td>0.788366</td>\n",
       "      <td>0.725810</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787225</td>\n",
       "      <td>0.721000</td>\n",
       "      <td>0.787225</td>\n",
       "      <td>0.724606</td>\n",
       "      <td>[[1705, 1, 22], [149, 0, 13], [296, 2, 82]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data               Classifier  \\\n",
       "0   FWS_FS_EPA                    Dummy   \n",
       "1   FWS_FS_EPA                    Dummy   \n",
       "2   FWS_FS_EPA                    Dummy   \n",
       "3   FWS_FS_EPA      Logistic Regression   \n",
       "4   FWS_FS_EPA      Logistic Regression   \n",
       "5   FWS_FS_EPA      Logistic Regression   \n",
       "6   FWS_FS_EPA      Logistic Regression   \n",
       "7   FWS_FS_EPA      Logistic Regression   \n",
       "8   FWS_FS_EPA      Logistic Regression   \n",
       "9   FWS_FS_EPA      Logistic Regression   \n",
       "10  FWS_FS_EPA      Logistic Regression   \n",
       "11  FWS_FS_EPA      Logistic Regression   \n",
       "12  FWS_FS_EPA      Logistic Regression   \n",
       "13  FWS_FS_EPA      Logistic Regression   \n",
       "14  FWS_FS_EPA      Logistic Regression   \n",
       "15  FWS_FS_EPA      Logistic Regression   \n",
       "16  FWS_FS_EPA      Logistic Regression   \n",
       "17  FWS_FS_EPA      Logistic Regression   \n",
       "18  FWS_FS_EPA      Logistic Regression   \n",
       "19  FWS_FS_EPA      Logistic Regression   \n",
       "20  FWS_FS_EPA      Logistic Regression   \n",
       "21  FWS_FS_EPA      Logistic Regression   \n",
       "22  FWS_FS_EPA      Logistic Regression   \n",
       "23  FWS_FS_EPA      Logistic Regression   \n",
       "24  FWS_FS_EPA  Multinomial Naive Bayes   \n",
       "25  FWS_FS_EPA  Multinomial Naive Bayes   \n",
       "26  FWS_FS_EPA  Multinomial Naive Bayes   \n",
       "27  FWS_FS_EPA      K Nearest Neighbors   \n",
       "28  FWS_FS_EPA      K Nearest Neighbors   \n",
       "29  FWS_FS_EPA      K Nearest Neighbors   \n",
       "30  FWS_FS_EPA      K Nearest Neighbors   \n",
       "31  FWS_FS_EPA      K Nearest Neighbors   \n",
       "32  FWS_FS_EPA            Decision Tree   \n",
       "33  FWS_FS_EPA            Decision Tree   \n",
       "34  FWS_FS_EPA            Decision Tree   \n",
       "35  FWS_FS_EPA            Decision Tree   \n",
       "36  FWS_FS_EPA            Decision Tree   \n",
       "37  FWS_FS_EPA            Decision Tree   \n",
       "38  FWS_FS_EPA            Decision Tree   \n",
       "39  FWS_FS_EPA            Random Forest   \n",
       "40  FWS_FS_EPA            Random Forest   \n",
       "41  FWS_FS_EPA            Random Forest   \n",
       "42  FWS_FS_EPA            Random Forest   \n",
       "43  FWS_FS_EPA            Random Forest   \n",
       "44  FWS_FS_EPA            Random Forest   \n",
       "45  FWS_FS_EPA            Random Forest   \n",
       "46  FWS_FS_EPA            Random Forest   \n",
       "47  FWS_FS_EPA            Random Forest   \n",
       "48  FWS_FS_EPA            Random Forest   \n",
       "49  FWS_FS_EPA                Ada Boost   \n",
       "50  FWS_FS_EPA                Ada Boost   \n",
       "51  FWS_FS_EPA                Ada Boost   \n",
       "52  FWS_FS_EPA                Ada Boost   \n",
       "53  FWS_FS_EPA                Ada Boost   \n",
       "54  FWS_FS_EPA                Ada Boost   \n",
       "55  FWS_FS_EPA                Ada Boost   \n",
       "\n",
       "                                           Parameters  Split  Accuracy  \\\n",
       "0                       {'strategy': 'most_frequent'}  Train  0.765341   \n",
       "1                          {'strategy': 'stratified'}  Train  0.614961   \n",
       "2                       {'strategy': 'most_frequent'}   Test  0.761233   \n",
       "3   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.765341   \n",
       "4   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.765341   \n",
       "5   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.761375   \n",
       "6   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.765231   \n",
       "7   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.789027   \n",
       "8   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.789027   \n",
       "9   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.789027   \n",
       "10  {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.789027   \n",
       "11  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.789137   \n",
       "12  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.789137   \n",
       "13  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.789137   \n",
       "14  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.789137   \n",
       "15  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.789137   \n",
       "16  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.789137   \n",
       "17  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.789137   \n",
       "18  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.789137   \n",
       "19  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.789137   \n",
       "20  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.789137   \n",
       "21  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.789137   \n",
       "22  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.789137   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...   Test  0.787665   \n",
       "24                  {'alpha': 0.0, 'fit_prior': True}  Train  0.772171   \n",
       "25                  {'alpha': 1.0, 'fit_prior': True}  Train  0.771290   \n",
       "26                  {'alpha': 0.0, 'fit_prior': True}   Test  0.784581   \n",
       "27       {'algorithm': 'ball_tree', 'leaf_size': 100}  Train  0.765341   \n",
       "28       {'algorithm': 'ball_tree', 'leaf_size': 200}  Train  0.766112   \n",
       "29         {'algorithm': 'kd_tree', 'leaf_size': 100}  Train  0.765451   \n",
       "30         {'algorithm': 'kd_tree', 'leaf_size': 200}  Train  0.767104   \n",
       "31         {'algorithm': 'kd_tree', 'leaf_size': 200}   Test  0.768722   \n",
       "32  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.785392   \n",
       "33  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.765341   \n",
       "34  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.765341   \n",
       "35  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.785392   \n",
       "36  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.785392   \n",
       "37  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.768205   \n",
       "38  {'criterion': 'gini', 'min_impurity_decrease':...   Test  0.786344   \n",
       "39  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.765341   \n",
       "40  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.765341   \n",
       "41  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.765341   \n",
       "42  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.765341   \n",
       "43  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.765341   \n",
       "44  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.765341   \n",
       "45  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.765341   \n",
       "46  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.765341   \n",
       "47  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.765341   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...   Test  0.761233   \n",
       "49        {'learning_rate': 0.5, 'n_estimators': 100}  Train  0.789027   \n",
       "50        {'learning_rate': 0.5, 'n_estimators': 200}  Train  0.788807   \n",
       "51        {'learning_rate': 0.5, 'n_estimators': 300}  Train  0.789027   \n",
       "52        {'learning_rate': 1.0, 'n_estimators': 100}  Train  0.788697   \n",
       "53        {'learning_rate': 1.0, 'n_estimators': 200}  Train  0.788587   \n",
       "54        {'learning_rate': 1.0, 'n_estimators': 300}  Train  0.788366   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 200}   Test  0.787225   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "0    0.585747  0.765341  0.663608   \n",
       "1    0.614287  0.612097  0.623732   \n",
       "2    0.579476  0.761233  0.658035   \n",
       "3    0.585747  0.765341  0.663608   \n",
       "4    0.585747  0.765341  0.663608   \n",
       "5    0.611878  0.761375  0.664447   \n",
       "6    0.585727  0.765231  0.663553   \n",
       "7    0.724311  0.789027  0.725039   \n",
       "8    0.724311  0.789027  0.725039   \n",
       "9    0.724311  0.789027  0.725039   \n",
       "10   0.724311  0.789027  0.725039   \n",
       "11   0.724582  0.789137  0.725121   \n",
       "12   0.724582  0.789137  0.725121   \n",
       "13   0.724582  0.789137  0.725121   \n",
       "14   0.724582  0.789137  0.725121   \n",
       "15   0.724582  0.789137  0.725121   \n",
       "16   0.724582  0.789137  0.725121   \n",
       "17   0.724582  0.789137  0.725121   \n",
       "18   0.724582  0.789137  0.725121   \n",
       "19   0.724582  0.789137  0.725121   \n",
       "20   0.724582  0.789137  0.725121   \n",
       "21   0.724582  0.789137  0.725121   \n",
       "22   0.724582  0.789137  0.725121   \n",
       "23   0.720512  0.787665  0.724481   \n",
       "24   0.745318  0.772171  0.730464   \n",
       "25   0.745011  0.771290  0.730016   \n",
       "26   0.753231  0.784581  0.739054   \n",
       "27   0.697777  0.765341  0.719936   \n",
       "28   0.699410  0.766112  0.720842   \n",
       "29   0.697804  0.765451  0.720105   \n",
       "30   0.700679  0.767104  0.721662   \n",
       "31   0.715217  0.768722  0.722568   \n",
       "32   0.719259  0.785392  0.718502   \n",
       "33   0.585747  0.765341  0.663608   \n",
       "34   0.585747  0.765341  0.663608   \n",
       "35   0.719259  0.785392  0.718502   \n",
       "36   0.719259  0.785392  0.718502   \n",
       "37   0.610027  0.768205  0.672531   \n",
       "38   0.718726  0.786344  0.721851   \n",
       "39   0.585747  0.765341  0.663608   \n",
       "40   0.585747  0.765341  0.663608   \n",
       "41   0.585747  0.765341  0.663608   \n",
       "42   0.585747  0.765341  0.663608   \n",
       "43   0.585747  0.765341  0.663608   \n",
       "44   0.585747  0.765341  0.663608   \n",
       "45   0.585747  0.765341  0.663608   \n",
       "46   0.585747  0.765341  0.663608   \n",
       "47   0.585747  0.765341  0.663608   \n",
       "48   0.579476  0.761233  0.658035   \n",
       "49   0.724634  0.789027  0.725109   \n",
       "50   0.731500  0.788807  0.725461   \n",
       "51   0.752367  0.789027  0.726026   \n",
       "52   0.744562  0.788697  0.725874   \n",
       "53   0.748539  0.788587  0.726096   \n",
       "54   0.742389  0.788366  0.725810   \n",
       "55   0.721000  0.787225  0.724606   \n",
       "\n",
       "                                  Confusion Matrix  \n",
       "0                                              NaN  \n",
       "1                                              NaN  \n",
       "2         [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  \n",
       "3                                              NaN  \n",
       "4                                              NaN  \n",
       "5                                              NaN  \n",
       "6                                              NaN  \n",
       "7                                              NaN  \n",
       "8                                              NaN  \n",
       "9                                              NaN  \n",
       "10                                             NaN  \n",
       "11                                             NaN  \n",
       "12                                             NaN  \n",
       "13                                             NaN  \n",
       "14                                             NaN  \n",
       "15                                             NaN  \n",
       "16                                             NaN  \n",
       "17                                             NaN  \n",
       "18                                             NaN  \n",
       "19                                             NaN  \n",
       "20                                             NaN  \n",
       "21                                             NaN  \n",
       "22                                             NaN  \n",
       "23     [[1706, 0, 22], [149, 0, 13], [298, 0, 82]]  \n",
       "24                                             NaN  \n",
       "25                                             NaN  \n",
       "26  [[1676, 30, 22], [126, 23, 13], [280, 18, 82]]  \n",
       "27                                             NaN  \n",
       "28                                             NaN  \n",
       "29                                             NaN  \n",
       "30                                             NaN  \n",
       "31    [[1638, 6, 84], [137, 5, 20], [274, 4, 102]]  \n",
       "32                                             NaN  \n",
       "33                                             NaN  \n",
       "34                                             NaN  \n",
       "35                                             NaN  \n",
       "36                                             NaN  \n",
       "37                                             NaN  \n",
       "38     [[1707, 0, 21], [149, 0, 13], [302, 0, 78]]  \n",
       "39                                             NaN  \n",
       "40                                             NaN  \n",
       "41                                             NaN  \n",
       "42                                             NaN  \n",
       "43                                             NaN  \n",
       "44                                             NaN  \n",
       "45                                             NaN  \n",
       "46                                             NaN  \n",
       "47                                             NaN  \n",
       "48        [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  \n",
       "49                                             NaN  \n",
       "50                                             NaN  \n",
       "51                                             NaN  \n",
       "52                                             NaN  \n",
       "53                                             NaN  \n",
       "54                                             NaN  \n",
       "55     [[1705, 1, 22], [149, 0, 13], [296, 2, 82]]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fws_fs_epa = X_train\n",
    "X_test_fws_fs_epa  = X_test\n",
    "\n",
    "# run FWS + FS + EPA dataset\n",
    "model_fws_fs_epa = clf.fit_predict_measure(\n",
    "    'FWS_FS_EPA', X_train_fws_fs_epa, X_test_fws_fs_epa, y_train, y_test, y_labels, classifiers)\n",
    "model_fws_fs_epa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.774705</td>\n",
       "      <td>0.676607</td>\n",
       "      <td>0.774654</td>\n",
       "      <td>0.702106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.067015</td>\n",
       "      <td>0.024902</td>\n",
       "      <td>0.031133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.614961</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.612097</td>\n",
       "      <td>0.623732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.585747</td>\n",
       "      <td>0.765341</td>\n",
       "      <td>0.663608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.784987</td>\n",
       "      <td>0.719259</td>\n",
       "      <td>0.784987</td>\n",
       "      <td>0.722209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.724582</td>\n",
       "      <td>0.789027</td>\n",
       "      <td>0.725121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.753231</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.739054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall   F1 Score\n",
       "count  56.000000  56.000000  56.000000  56.000000\n",
       "mean    0.774705   0.676607   0.774654   0.702106\n",
       "std     0.024562   0.067015   0.024902   0.031133\n",
       "min     0.614961   0.579476   0.612097   0.623732\n",
       "25%     0.765341   0.585747   0.765341   0.663608\n",
       "50%     0.784987   0.719259   0.784987   0.722209\n",
       "75%     0.789027   0.724582   0.789027   0.725121\n",
       "max     0.789137   0.753231   0.789137   0.739054"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of FWS + FS + EPA classifiers (test and training sets)\n",
    "model_fws_fs_epa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.753231</td>\n",
       "      <td>0.784581</td>\n",
       "      <td>0.739054</td>\n",
       "      <td>[[1676, 30, 22], [126, 23, 13], [280, 18, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787225</td>\n",
       "      <td>0.721000</td>\n",
       "      <td>0.787225</td>\n",
       "      <td>0.724606</td>\n",
       "      <td>[[1705, 1, 22], [149, 0, 13], [296, 2, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.720512</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>[[1706, 0, 22], [149, 0, 13], [298, 0, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.768722</td>\n",
       "      <td>0.715217</td>\n",
       "      <td>0.768722</td>\n",
       "      <td>0.722568</td>\n",
       "      <td>[[1638, 6, 84], [137, 5, 20], [274, 4, 102]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.718726</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.721851</td>\n",
       "      <td>[[1707, 0, 21], [149, 0, 13], [302, 0, 78]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FWS_FS_EPA</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.579476</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>[[1728, 0, 0], [162, 0, 0], [380, 0, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data               Classifier  \\\n",
       "26  FWS_FS_EPA  Multinomial Naive Bayes   \n",
       "55  FWS_FS_EPA                Ada Boost   \n",
       "23  FWS_FS_EPA      Logistic Regression   \n",
       "31  FWS_FS_EPA      K Nearest Neighbors   \n",
       "38  FWS_FS_EPA            Decision Tree   \n",
       "2   FWS_FS_EPA                    Dummy   \n",
       "48  FWS_FS_EPA            Random Forest   \n",
       "\n",
       "                                           Parameters Split  Accuracy  \\\n",
       "26                  {'alpha': 0.0, 'fit_prior': True}  Test  0.784581   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 200}  Test  0.787225   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Test  0.787665   \n",
       "31         {'algorithm': 'kd_tree', 'leaf_size': 200}  Test  0.768722   \n",
       "38  {'criterion': 'gini', 'min_impurity_decrease':...  Test  0.786344   \n",
       "2                       {'strategy': 'most_frequent'}  Test  0.761233   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...  Test  0.761233   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "26   0.753231  0.784581  0.739054   \n",
       "55   0.721000  0.787225  0.724606   \n",
       "23   0.720512  0.787665  0.724481   \n",
       "31   0.715217  0.768722  0.722568   \n",
       "38   0.718726  0.786344  0.721851   \n",
       "2    0.579476  0.761233  0.658035   \n",
       "48   0.579476  0.761233  0.658035   \n",
       "\n",
       "                                  Confusion Matrix  \n",
       "26  [[1676, 30, 22], [126, 23, 13], [280, 18, 82]]  \n",
       "55     [[1705, 1, 22], [149, 0, 13], [296, 2, 82]]  \n",
       "23     [[1706, 0, 22], [149, 0, 13], [298, 0, 82]]  \n",
       "31    [[1638, 6, 84], [137, 5, 20], [274, 4, 102]]  \n",
       "38     [[1707, 0, 21], [149, 0, 13], [302, 0, 78]]  \n",
       "2         [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  \n",
       "48        [[1728, 0, 0], [162, 0, 0], [380, 0, 0]]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators of FWS + FS + EPA dataset\n",
    "model_fws_fs_epa_test = model_fws_fs_epa[model_fws_fs_epa['Split'] == 'Test']\n",
    "model_fws_fs_epa_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance with SMOTENC Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train Normal</th>\n",
       "      <th>Test Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Endangered</th>\n",
       "      <td>6947</td>\n",
       "      <td>380</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.167401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Listed</th>\n",
       "      <td>6947</td>\n",
       "      <td>1728</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.761233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threatened</th>\n",
       "      <td>6947</td>\n",
       "      <td>162</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.071366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>20841</td>\n",
       "      <td>2270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Train  Test  Train Normal  Test Normal\n",
       "Endangered   6947   380      0.333333     0.167401\n",
       "Not Listed   6947  1728      0.333333     0.761233\n",
       "Threatened   6947   162      0.333333     0.071366\n",
       "Total       20841  2270      1.000000     1.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balance classes with SMOTENC oversampling\n",
    "smote = SMOTENC(categorical_features=list(range(4,len(X_train.columns))))\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "X_train_smote = pd.DataFrame(X_train_smote, columns=X_train.columns)\n",
    "y_train_smote = pd.Series(y_train_smote)\n",
    "\n",
    "# balanced data set statistics\n",
    "smote_sets = pd.DataFrame({'Train':        y_train_smote.value_counts(),\n",
    "                           'Test':         y_test.value_counts(),\n",
    "                           'Train Normal': y_train_smote.value_counts() / y_train_smote.count(),\n",
    "                           'Test Normal':  y_test.value_counts()        / y_test.count()})\n",
    "\n",
    "smote_sets.loc['Total'] = smote_sets.sum().astype(int)\n",
    "smote_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Land Area (Thousands of Acres)</th>\n",
       "      <th>Forest Land Area (Thousands of Acres)</th>\n",
       "      <th>Days with AQI</th>\n",
       "      <th>Good Days</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>Group_Crustaceans</th>\n",
       "      <th>Group_Ferns and Allies</th>\n",
       "      <th>Group_Fishes</th>\n",
       "      <th>...</th>\n",
       "      <th>State_OR</th>\n",
       "      <th>State_PA</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "      <td>20841.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.133113</td>\n",
       "      <td>0.147117</td>\n",
       "      <td>0.926231</td>\n",
       "      <td>0.633637</td>\n",
       "      <td>0.007869</td>\n",
       "      <td>0.082002</td>\n",
       "      <td>0.080514</td>\n",
       "      <td>0.009740</td>\n",
       "      <td>0.009548</td>\n",
       "      <td>0.084113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031668</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.012715</td>\n",
       "      <td>0.029605</td>\n",
       "      <td>0.037906</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.007197</td>\n",
       "      <td>0.005806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.128553</td>\n",
       "      <td>0.126816</td>\n",
       "      <td>0.181730</td>\n",
       "      <td>0.236077</td>\n",
       "      <td>0.088360</td>\n",
       "      <td>0.274374</td>\n",
       "      <td>0.272094</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>0.097251</td>\n",
       "      <td>0.277564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175120</td>\n",
       "      <td>0.079632</td>\n",
       "      <td>0.112046</td>\n",
       "      <td>0.169499</td>\n",
       "      <td>0.190974</td>\n",
       "      <td>0.161567</td>\n",
       "      <td>0.158729</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.084533</td>\n",
       "      <td>0.075977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.067439</td>\n",
       "      <td>0.070693</td>\n",
       "      <td>0.952632</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.092573</td>\n",
       "      <td>0.138767</td>\n",
       "      <td>0.984211</td>\n",
       "      <td>0.638393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.179938</td>\n",
       "      <td>0.190491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total Land Area (Thousands of Acres)  \\\n",
       "count                          20841.000000   \n",
       "mean                               0.133113   \n",
       "std                                0.128553   \n",
       "min                                0.000000   \n",
       "25%                                0.067439   \n",
       "50%                                0.092573   \n",
       "75%                                0.179938   \n",
       "max                                1.000000   \n",
       "\n",
       "       Forest Land Area (Thousands of Acres)  Days with AQI     Good Days  \\\n",
       "count                           20841.000000   20841.000000  20841.000000   \n",
       "mean                                0.147117       0.926231      0.633637   \n",
       "std                                 0.126816       0.181730      0.236077   \n",
       "min                                 0.000000       0.000000      0.000000   \n",
       "25%                                 0.070693       0.952632      0.517857   \n",
       "50%                                 0.138767       0.984211      0.638393   \n",
       "75%                                 0.190491       1.000000      0.781250   \n",
       "max                                 1.000000       1.000000      1.000000   \n",
       "\n",
       "       Group_Amphibians   Group_Birds   Group_Clams  Group_Crustaceans  \\\n",
       "count      20841.000000  20841.000000  20841.000000       20841.000000   \n",
       "mean           0.007869      0.082002      0.080514           0.009740   \n",
       "std            0.088360      0.274374      0.272094           0.098214   \n",
       "min            0.000000      0.000000      0.000000           0.000000   \n",
       "25%            0.000000      0.000000      0.000000           0.000000   \n",
       "50%            0.000000      0.000000      0.000000           0.000000   \n",
       "75%            0.000000      0.000000      0.000000           0.000000   \n",
       "max            1.000000      1.000000      1.000000           1.000000   \n",
       "\n",
       "       Group_Ferns and Allies  Group_Fishes      ...           State_OR  \\\n",
       "count            20841.000000  20841.000000      ...       20841.000000   \n",
       "mean                 0.009548      0.084113      ...           0.031668   \n",
       "std                  0.097251      0.277564      ...           0.175120   \n",
       "min                  0.000000      0.000000      ...           0.000000   \n",
       "25%                  0.000000      0.000000      ...           0.000000   \n",
       "50%                  0.000000      0.000000      ...           0.000000   \n",
       "75%                  0.000000      0.000000      ...           0.000000   \n",
       "max                  1.000000      1.000000      ...           1.000000   \n",
       "\n",
       "           State_PA      State_SC      State_TN      State_TX      State_UT  \\\n",
       "count  20841.000000  20841.000000  20841.000000  20841.000000  20841.000000   \n",
       "mean       0.006382      0.012715      0.029605      0.037906      0.026822   \n",
       "std        0.079632      0.112046      0.169499      0.190974      0.161567   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           State_VA      State_WA      State_WV      State_WY  \n",
       "count  20841.000000  20841.000000  20841.000000  20841.000000  \n",
       "mean       0.025862      0.020009      0.007197      0.005806  \n",
       "std        0.158729      0.140033      0.084533      0.075977  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000      0.000000  \n",
       "max        1.000000      1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 45 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check balanced model\n",
    "X_train_smote.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1a2ee208>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot comparison of unbalanced and balanced training sets\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16,8))\n",
    "\n",
    "sns.countplot(y_train,       order=y_train.value_counts().index, alpha=0.8, ax = axes[0,0])\n",
    "sns.countplot(y_train_smote, order=y_train.value_counts().index, alpha=0.8, ax = axes[0,1])\n",
    "\n",
    "sns.scatterplot(x=X_train.columns[0],       y=X_train.columns[1],       data=X_train,       ax = axes[1,0])\n",
    "sns.scatterplot(x=X_train_smote.columns[0], y=X_train_smote.columns[1], data=X_train_smote, ax = axes[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Dummy\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Logistic Regression\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: K Nearest Neighbors\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:  2.5min remaining:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Decision Tree\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    1.4s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Random Forest\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:   18.9s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   20.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running jobs: Ada Boost\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  1.4min remaining:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.331414</td>\n",
       "      <td>0.335113</td>\n",
       "      <td>0.327815</td>\n",
       "      <td>0.328347</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.335242</td>\n",
       "      <td>0.608031</td>\n",
       "      <td>0.335242</td>\n",
       "      <td>0.403189</td>\n",
       "      <td>[[596, 566, 566], [53, 50, 59], [137, 128, 115]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.543928</td>\n",
       "      <td>0.570595</td>\n",
       "      <td>0.543928</td>\n",
       "      <td>0.541756</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': True, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.549062</td>\n",
       "      <td>0.571798</td>\n",
       "      <td>0.549062</td>\n",
       "      <td>0.548199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.543928</td>\n",
       "      <td>0.570595</td>\n",
       "      <td>0.543928</td>\n",
       "      <td>0.541756</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'fit_intercept': False, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.548198</td>\n",
       "      <td>0.570521</td>\n",
       "      <td>0.548198</td>\n",
       "      <td>0.547269</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.592730</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.582146</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': True, 'multi_class...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.582554</td>\n",
       "      <td>0.593288</td>\n",
       "      <td>0.582554</td>\n",
       "      <td>0.582836</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.581978</td>\n",
       "      <td>0.592909</td>\n",
       "      <td>0.581978</td>\n",
       "      <td>0.582328</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1.0, 'fit_intercept': False, 'multi_clas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.582746</td>\n",
       "      <td>0.593493</td>\n",
       "      <td>0.582746</td>\n",
       "      <td>0.583024</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.582937</td>\n",
       "      <td>0.593725</td>\n",
       "      <td>0.582937</td>\n",
       "      <td>0.583272</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.582985</td>\n",
       "      <td>0.593765</td>\n",
       "      <td>0.582985</td>\n",
       "      <td>0.583318</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.592856</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.582155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': False, 'multi_cl...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.592856</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.582155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.582937</td>\n",
       "      <td>0.593725</td>\n",
       "      <td>0.582937</td>\n",
       "      <td>0.583272</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': True, 'multi...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.582985</td>\n",
       "      <td>0.593765</td>\n",
       "      <td>0.582985</td>\n",
       "      <td>0.583318</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.592856</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.582155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000.0, 'fit_intercept': False, 'mult...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.592856</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.582155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.582937</td>\n",
       "      <td>0.593725</td>\n",
       "      <td>0.582937</td>\n",
       "      <td>0.583272</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': True, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.582985</td>\n",
       "      <td>0.593765</td>\n",
       "      <td>0.582985</td>\n",
       "      <td>0.583318</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.592856</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.582155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 1000000000000.0, 'fit_intercept': False,...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.592856</td>\n",
       "      <td>0.581786</td>\n",
       "      <td>0.582155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.617621</td>\n",
       "      <td>0.727225</td>\n",
       "      <td>0.617621</td>\n",
       "      <td>0.656758</td>\n",
       "      <td>[[1141, 299, 288], [64, 71, 27], [126, 64, 190]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.546951</td>\n",
       "      <td>0.562218</td>\n",
       "      <td>0.546951</td>\n",
       "      <td>0.546234</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 1.0, 'fit_prior': True}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.546135</td>\n",
       "      <td>0.561155</td>\n",
       "      <td>0.546135</td>\n",
       "      <td>0.545535</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.611894</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.611894</td>\n",
       "      <td>0.654658</td>\n",
       "      <td>[[1134, 328, 266], [66, 75, 21], [117, 83, 180]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.553764</td>\n",
       "      <td>0.589322</td>\n",
       "      <td>0.553764</td>\n",
       "      <td>0.549310</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.555156</td>\n",
       "      <td>0.593489</td>\n",
       "      <td>0.555156</td>\n",
       "      <td>0.550811</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.553620</td>\n",
       "      <td>0.589051</td>\n",
       "      <td>0.553620</td>\n",
       "      <td>0.549157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'leaf_size': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.555156</td>\n",
       "      <td>0.593261</td>\n",
       "      <td>0.555156</td>\n",
       "      <td>0.550780</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.680176</td>\n",
       "      <td>0.690107</td>\n",
       "      <td>0.680176</td>\n",
       "      <td>0.684886</td>\n",
       "      <td>[[1380, 142, 206], [93, 35, 34], [223, 28, 129]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.544744</td>\n",
       "      <td>0.572181</td>\n",
       "      <td>0.544744</td>\n",
       "      <td>0.542678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.417974</td>\n",
       "      <td>0.351409</td>\n",
       "      <td>0.417974</td>\n",
       "      <td>0.311132</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'gini', 'min_impurity_decrease':...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.552661</td>\n",
       "      <td>0.589138</td>\n",
       "      <td>0.552661</td>\n",
       "      <td>0.548500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.544744</td>\n",
       "      <td>0.572181</td>\n",
       "      <td>0.544744</td>\n",
       "      <td>0.542678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.526078</td>\n",
       "      <td>0.529033</td>\n",
       "      <td>0.526078</td>\n",
       "      <td>0.506118</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.676211</td>\n",
       "      <td>0.754039</td>\n",
       "      <td>0.676211</td>\n",
       "      <td>0.706695</td>\n",
       "      <td>[[1295, 288, 145], [73, 75, 14], [133, 82, 165]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.538554</td>\n",
       "      <td>0.560119</td>\n",
       "      <td>0.538554</td>\n",
       "      <td>0.536192</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.537498</td>\n",
       "      <td>0.558216</td>\n",
       "      <td>0.537498</td>\n",
       "      <td>0.535075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.536251</td>\n",
       "      <td>0.557049</td>\n",
       "      <td>0.536251</td>\n",
       "      <td>0.534002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.349217</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.310535</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.349217</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.310535</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.03, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.349217</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.310535</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.05, 'n_estimators'...</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.629956</td>\n",
       "      <td>0.735247</td>\n",
       "      <td>0.629956</td>\n",
       "      <td>0.669199</td>\n",
       "      <td>[[1182, 306, 240], [68, 75, 19], [120, 87, 173]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.575932</td>\n",
       "      <td>0.587145</td>\n",
       "      <td>0.575932</td>\n",
       "      <td>0.575924</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.576892</td>\n",
       "      <td>0.586283</td>\n",
       "      <td>0.576892</td>\n",
       "      <td>0.577148</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.587555</td>\n",
       "      <td>0.578667</td>\n",
       "      <td>0.579081</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.579867</td>\n",
       "      <td>0.587532</td>\n",
       "      <td>0.579867</td>\n",
       "      <td>0.580248</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 200}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.581114</td>\n",
       "      <td>0.588096</td>\n",
       "      <td>0.581114</td>\n",
       "      <td>0.581577</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.581450</td>\n",
       "      <td>0.588624</td>\n",
       "      <td>0.581450</td>\n",
       "      <td>0.581799</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.597797</td>\n",
       "      <td>0.718965</td>\n",
       "      <td>0.597797</td>\n",
       "      <td>0.640137</td>\n",
       "      <td>[[1097, 325, 306], [65, 65, 32], [128, 57, 195]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Data               Classifier  \\\n",
       "0   FWS_FS_EPA_SMOTE                    Dummy   \n",
       "1   FWS_FS_EPA_SMOTE                    Dummy   \n",
       "2   FWS_FS_EPA_SMOTE                    Dummy   \n",
       "3   FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "4   FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "5   FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "6   FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "7   FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "8   FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "9   FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "10  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "11  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "12  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "13  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "14  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "15  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "16  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "17  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "18  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "19  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "20  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "21  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "22  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "23  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "24  FWS_FS_EPA_SMOTE  Multinomial Naive Bayes   \n",
       "25  FWS_FS_EPA_SMOTE  Multinomial Naive Bayes   \n",
       "26  FWS_FS_EPA_SMOTE  Multinomial Naive Bayes   \n",
       "27  FWS_FS_EPA_SMOTE      K Nearest Neighbors   \n",
       "28  FWS_FS_EPA_SMOTE      K Nearest Neighbors   \n",
       "29  FWS_FS_EPA_SMOTE      K Nearest Neighbors   \n",
       "30  FWS_FS_EPA_SMOTE      K Nearest Neighbors   \n",
       "31  FWS_FS_EPA_SMOTE      K Nearest Neighbors   \n",
       "32  FWS_FS_EPA_SMOTE            Decision Tree   \n",
       "33  FWS_FS_EPA_SMOTE            Decision Tree   \n",
       "34  FWS_FS_EPA_SMOTE            Decision Tree   \n",
       "35  FWS_FS_EPA_SMOTE            Decision Tree   \n",
       "36  FWS_FS_EPA_SMOTE            Decision Tree   \n",
       "37  FWS_FS_EPA_SMOTE            Decision Tree   \n",
       "38  FWS_FS_EPA_SMOTE            Decision Tree   \n",
       "39  FWS_FS_EPA_SMOTE            Random Forest   \n",
       "40  FWS_FS_EPA_SMOTE            Random Forest   \n",
       "41  FWS_FS_EPA_SMOTE            Random Forest   \n",
       "42  FWS_FS_EPA_SMOTE            Random Forest   \n",
       "43  FWS_FS_EPA_SMOTE            Random Forest   \n",
       "44  FWS_FS_EPA_SMOTE            Random Forest   \n",
       "45  FWS_FS_EPA_SMOTE            Random Forest   \n",
       "46  FWS_FS_EPA_SMOTE            Random Forest   \n",
       "47  FWS_FS_EPA_SMOTE            Random Forest   \n",
       "48  FWS_FS_EPA_SMOTE            Random Forest   \n",
       "49  FWS_FS_EPA_SMOTE                Ada Boost   \n",
       "50  FWS_FS_EPA_SMOTE                Ada Boost   \n",
       "51  FWS_FS_EPA_SMOTE                Ada Boost   \n",
       "52  FWS_FS_EPA_SMOTE                Ada Boost   \n",
       "53  FWS_FS_EPA_SMOTE                Ada Boost   \n",
       "54  FWS_FS_EPA_SMOTE                Ada Boost   \n",
       "55  FWS_FS_EPA_SMOTE                Ada Boost   \n",
       "\n",
       "                                           Parameters  Split  Accuracy  \\\n",
       "0                       {'strategy': 'most_frequent'}  Train  0.333333   \n",
       "1                          {'strategy': 'stratified'}  Train  0.331414   \n",
       "2                          {'strategy': 'stratified'}   Test  0.335242   \n",
       "3   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.543928   \n",
       "4   {'C': 0.01, 'fit_intercept': True, 'multi_clas...  Train  0.549062   \n",
       "5   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.543928   \n",
       "6   {'C': 0.01, 'fit_intercept': False, 'multi_cla...  Train  0.548198   \n",
       "7   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.581786   \n",
       "8   {'C': 1.0, 'fit_intercept': True, 'multi_class...  Train  0.582554   \n",
       "9   {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.581978   \n",
       "10  {'C': 1.0, 'fit_intercept': False, 'multi_clas...  Train  0.582746   \n",
       "11  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.582937   \n",
       "12  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Train  0.582985   \n",
       "13  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.581786   \n",
       "14  {'C': 100.0, 'fit_intercept': False, 'multi_cl...  Train  0.581786   \n",
       "15  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.582937   \n",
       "16  {'C': 1000000.0, 'fit_intercept': True, 'multi...  Train  0.582985   \n",
       "17  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.581786   \n",
       "18  {'C': 1000000.0, 'fit_intercept': False, 'mult...  Train  0.581786   \n",
       "19  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.582937   \n",
       "20  {'C': 1000000000000.0, 'fit_intercept': True, ...  Train  0.582985   \n",
       "21  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.581786   \n",
       "22  {'C': 1000000000000.0, 'fit_intercept': False,...  Train  0.581786   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...   Test  0.617621   \n",
       "24                  {'alpha': 0.0, 'fit_prior': True}  Train  0.546951   \n",
       "25                  {'alpha': 1.0, 'fit_prior': True}  Train  0.546135   \n",
       "26                  {'alpha': 0.0, 'fit_prior': True}   Test  0.611894   \n",
       "27       {'algorithm': 'ball_tree', 'leaf_size': 100}  Train  0.553764   \n",
       "28       {'algorithm': 'ball_tree', 'leaf_size': 200}  Train  0.555156   \n",
       "29         {'algorithm': 'kd_tree', 'leaf_size': 100}  Train  0.553620   \n",
       "30         {'algorithm': 'kd_tree', 'leaf_size': 200}  Train  0.555156   \n",
       "31       {'algorithm': 'ball_tree', 'leaf_size': 200}   Test  0.680176   \n",
       "32  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.544744   \n",
       "33  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.417974   \n",
       "34  {'criterion': 'gini', 'min_impurity_decrease':...  Train  0.333333   \n",
       "35  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.552661   \n",
       "36  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.544744   \n",
       "37  {'criterion': 'entropy', 'min_impurity_decreas...  Train  0.526078   \n",
       "38  {'criterion': 'entropy', 'min_impurity_decreas...   Test  0.676211   \n",
       "39  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.538554   \n",
       "40  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.537498   \n",
       "41  {'min_impurity_decrease': 0.01, 'n_estimators'...  Train  0.536251   \n",
       "42  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.416919   \n",
       "43  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.416919   \n",
       "44  {'min_impurity_decrease': 0.03, 'n_estimators'...  Train  0.416919   \n",
       "45  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "46  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "47  {'min_impurity_decrease': 0.05, 'n_estimators'...  Train  0.333333   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...   Test  0.629956   \n",
       "49        {'learning_rate': 0.5, 'n_estimators': 100}  Train  0.575932   \n",
       "50        {'learning_rate': 0.5, 'n_estimators': 200}  Train  0.576892   \n",
       "51        {'learning_rate': 0.5, 'n_estimators': 300}  Train  0.578667   \n",
       "52        {'learning_rate': 1.0, 'n_estimators': 100}  Train  0.579867   \n",
       "53        {'learning_rate': 1.0, 'n_estimators': 200}  Train  0.581114   \n",
       "54        {'learning_rate': 1.0, 'n_estimators': 300}  Train  0.581450   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 300}   Test  0.597797   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "0    0.111111  0.333333  0.166667   \n",
       "1    0.335113  0.327815  0.328347   \n",
       "2    0.608031  0.335242  0.403189   \n",
       "3    0.570595  0.543928  0.541756   \n",
       "4    0.571798  0.549062  0.548199   \n",
       "5    0.570595  0.543928  0.541756   \n",
       "6    0.570521  0.548198  0.547269   \n",
       "7    0.592730  0.581786  0.582146   \n",
       "8    0.593288  0.582554  0.582836   \n",
       "9    0.592909  0.581978  0.582328   \n",
       "10   0.593493  0.582746  0.583024   \n",
       "11   0.593725  0.582937  0.583272   \n",
       "12   0.593765  0.582985  0.583318   \n",
       "13   0.592856  0.581786  0.582155   \n",
       "14   0.592856  0.581786  0.582155   \n",
       "15   0.593725  0.582937  0.583272   \n",
       "16   0.593765  0.582985  0.583318   \n",
       "17   0.592856  0.581786  0.582155   \n",
       "18   0.592856  0.581786  0.582155   \n",
       "19   0.593725  0.582937  0.583272   \n",
       "20   0.593765  0.582985  0.583318   \n",
       "21   0.592856  0.581786  0.582155   \n",
       "22   0.592856  0.581786  0.582155   \n",
       "23   0.727225  0.617621  0.656758   \n",
       "24   0.562218  0.546951  0.546234   \n",
       "25   0.561155  0.546135  0.545535   \n",
       "26   0.730994  0.611894  0.654658   \n",
       "27   0.589322  0.553764  0.549310   \n",
       "28   0.593489  0.555156  0.550811   \n",
       "29   0.589051  0.553620  0.549157   \n",
       "30   0.593261  0.555156  0.550780   \n",
       "31   0.690107  0.680176  0.684886   \n",
       "32   0.572181  0.544744  0.542678   \n",
       "33   0.351409  0.417974  0.311132   \n",
       "34   0.111111  0.333333  0.166667   \n",
       "35   0.589138  0.552661  0.548500   \n",
       "36   0.572181  0.544744  0.542678   \n",
       "37   0.529033  0.526078  0.506118   \n",
       "38   0.754039  0.676211  0.706695   \n",
       "39   0.560119  0.538554  0.536192   \n",
       "40   0.558216  0.537498  0.535075   \n",
       "41   0.557049  0.536251  0.534002   \n",
       "42   0.349217  0.416919  0.310535   \n",
       "43   0.349217  0.416919  0.310535   \n",
       "44   0.349217  0.416919  0.310535   \n",
       "45   0.111111  0.333333  0.166667   \n",
       "46   0.111111  0.333333  0.166667   \n",
       "47   0.111111  0.333333  0.166667   \n",
       "48   0.735247  0.629956  0.669199   \n",
       "49   0.587145  0.575932  0.575924   \n",
       "50   0.586283  0.576892  0.577148   \n",
       "51   0.587555  0.578667  0.579081   \n",
       "52   0.587532  0.579867  0.580248   \n",
       "53   0.588096  0.581114  0.581577   \n",
       "54   0.588624  0.581450  0.581799   \n",
       "55   0.718965  0.597797  0.640137   \n",
       "\n",
       "                                    Confusion Matrix  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2   [[596, 566, 566], [53, 50, 59], [137, 128, 115]]  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  \n",
       "10                                               NaN  \n",
       "11                                               NaN  \n",
       "12                                               NaN  \n",
       "13                                               NaN  \n",
       "14                                               NaN  \n",
       "15                                               NaN  \n",
       "16                                               NaN  \n",
       "17                                               NaN  \n",
       "18                                               NaN  \n",
       "19                                               NaN  \n",
       "20                                               NaN  \n",
       "21                                               NaN  \n",
       "22                                               NaN  \n",
       "23  [[1141, 299, 288], [64, 71, 27], [126, 64, 190]]  \n",
       "24                                               NaN  \n",
       "25                                               NaN  \n",
       "26  [[1134, 328, 266], [66, 75, 21], [117, 83, 180]]  \n",
       "27                                               NaN  \n",
       "28                                               NaN  \n",
       "29                                               NaN  \n",
       "30                                               NaN  \n",
       "31  [[1380, 142, 206], [93, 35, 34], [223, 28, 129]]  \n",
       "32                                               NaN  \n",
       "33                                               NaN  \n",
       "34                                               NaN  \n",
       "35                                               NaN  \n",
       "36                                               NaN  \n",
       "37                                               NaN  \n",
       "38  [[1295, 288, 145], [73, 75, 14], [133, 82, 165]]  \n",
       "39                                               NaN  \n",
       "40                                               NaN  \n",
       "41                                               NaN  \n",
       "42                                               NaN  \n",
       "43                                               NaN  \n",
       "44                                               NaN  \n",
       "45                                               NaN  \n",
       "46                                               NaN  \n",
       "47                                               NaN  \n",
       "48  [[1182, 306, 240], [68, 75, 19], [120, 87, 173]]  \n",
       "49                                               NaN  \n",
       "50                                               NaN  \n",
       "51                                               NaN  \n",
       "52                                               NaN  \n",
       "53                                               NaN  \n",
       "54                                               NaN  \n",
       "55  [[1097, 325, 306], [65, 65, 32], [128, 57, 195]]  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run balanced dataset\n",
    "model_fws_fs_epa_smote = clf.fit_predict_measure(\n",
    "    'FWS_FS_EPA_SMOTE', X_train_smote, X_test, y_train_smote, y_test, y_labels, classifiers)\n",
    "model_fws_fs_epa_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.533636</td>\n",
       "      <td>0.535384</td>\n",
       "      <td>0.533572</td>\n",
       "      <td>0.514907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.091179</td>\n",
       "      <td>0.159533</td>\n",
       "      <td>0.091326</td>\n",
       "      <td>0.140008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.331414</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.327815</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.538290</td>\n",
       "      <td>0.560896</td>\n",
       "      <td>0.538290</td>\n",
       "      <td>0.535913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.565544</td>\n",
       "      <td>0.588837</td>\n",
       "      <td>0.565544</td>\n",
       "      <td>0.563367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.582122</td>\n",
       "      <td>0.593490</td>\n",
       "      <td>0.582122</td>\n",
       "      <td>0.582455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.680176</td>\n",
       "      <td>0.754039</td>\n",
       "      <td>0.680176</td>\n",
       "      <td>0.706695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall   F1 Score\n",
       "count  56.000000  56.000000  56.000000  56.000000\n",
       "mean    0.533636   0.535384   0.533572   0.514907\n",
       "std     0.091179   0.159533   0.091326   0.140008\n",
       "min     0.331414   0.111111   0.327815   0.166667\n",
       "25%     0.538290   0.560896   0.538290   0.535913\n",
       "50%     0.565544   0.588837   0.565544   0.563367\n",
       "75%     0.582122   0.593490   0.582122   0.582455\n",
       "max     0.680176   0.754039   0.680176   0.706695"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistics of balanced classifiers (test and training sets)\n",
    "model_fws_fs_epa_smote.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Split</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'criterion': 'entropy', 'min_impurity_decreas...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.676211</td>\n",
       "      <td>0.754039</td>\n",
       "      <td>0.676211</td>\n",
       "      <td>0.706695</td>\n",
       "      <td>[[1295, 288, 145], [73, 75, 14], [133, 82, 165]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>K Nearest Neighbors</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'leaf_size': 200}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.680176</td>\n",
       "      <td>0.690107</td>\n",
       "      <td>0.680176</td>\n",
       "      <td>0.684886</td>\n",
       "      <td>[[1380, 142, 206], [93, 35, 34], [223, 28, 129]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'min_impurity_decrease': 0.01, 'n_estimators'...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.629956</td>\n",
       "      <td>0.735247</td>\n",
       "      <td>0.629956</td>\n",
       "      <td>0.669199</td>\n",
       "      <td>[[1182, 306, 240], [68, 75, 19], [120, 87, 173]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 100.0, 'fit_intercept': True, 'multi_cla...</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.617621</td>\n",
       "      <td>0.727225</td>\n",
       "      <td>0.617621</td>\n",
       "      <td>0.656758</td>\n",
       "      <td>[[1141, 299, 288], [64, 71, 27], [126, 64, 190]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>{'alpha': 0.0, 'fit_prior': True}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.611894</td>\n",
       "      <td>0.730994</td>\n",
       "      <td>0.611894</td>\n",
       "      <td>0.654658</td>\n",
       "      <td>[[1134, 328, 266], [66, 75, 21], [117, 83, 180]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Ada Boost</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 300}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.597797</td>\n",
       "      <td>0.718965</td>\n",
       "      <td>0.597797</td>\n",
       "      <td>0.640137</td>\n",
       "      <td>[[1097, 325, 306], [65, 65, 32], [128, 57, 195]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FWS_FS_EPA_SMOTE</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.335242</td>\n",
       "      <td>0.608031</td>\n",
       "      <td>0.335242</td>\n",
       "      <td>0.403189</td>\n",
       "      <td>[[596, 566, 566], [53, 50, 59], [137, 128, 115]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Data               Classifier  \\\n",
       "38  FWS_FS_EPA_SMOTE            Decision Tree   \n",
       "31  FWS_FS_EPA_SMOTE      K Nearest Neighbors   \n",
       "48  FWS_FS_EPA_SMOTE            Random Forest   \n",
       "23  FWS_FS_EPA_SMOTE      Logistic Regression   \n",
       "26  FWS_FS_EPA_SMOTE  Multinomial Naive Bayes   \n",
       "55  FWS_FS_EPA_SMOTE                Ada Boost   \n",
       "2   FWS_FS_EPA_SMOTE                    Dummy   \n",
       "\n",
       "                                           Parameters Split  Accuracy  \\\n",
       "38  {'criterion': 'entropy', 'min_impurity_decreas...  Test  0.676211   \n",
       "31       {'algorithm': 'ball_tree', 'leaf_size': 200}  Test  0.680176   \n",
       "48  {'min_impurity_decrease': 0.01, 'n_estimators'...  Test  0.629956   \n",
       "23  {'C': 100.0, 'fit_intercept': True, 'multi_cla...  Test  0.617621   \n",
       "26                  {'alpha': 0.0, 'fit_prior': True}  Test  0.611894   \n",
       "55        {'learning_rate': 1.0, 'n_estimators': 300}  Test  0.597797   \n",
       "2                          {'strategy': 'stratified'}  Test  0.335242   \n",
       "\n",
       "    Precision    Recall  F1 Score  \\\n",
       "38   0.754039  0.676211  0.706695   \n",
       "31   0.690107  0.680176  0.684886   \n",
       "48   0.735247  0.629956  0.669199   \n",
       "23   0.727225  0.617621  0.656758   \n",
       "26   0.730994  0.611894  0.654658   \n",
       "55   0.718965  0.597797  0.640137   \n",
       "2    0.608031  0.335242  0.403189   \n",
       "\n",
       "                                    Confusion Matrix  \n",
       "38  [[1295, 288, 145], [73, 75, 14], [133, 82, 165]]  \n",
       "31  [[1380, 142, 206], [93, 35, 34], [223, 28, 129]]  \n",
       "48  [[1182, 306, 240], [68, 75, 19], [120, 87, 173]]  \n",
       "23  [[1141, 299, 288], [64, 71, 27], [126, 64, 190]]  \n",
       "26  [[1134, 328, 266], [66, 75, 21], [117, 83, 180]]  \n",
       "55  [[1097, 325, 306], [65, 65, 32], [128, 57, 195]]  \n",
       "2   [[596, 566, 566], [53, 50, 59], [137, 128, 115]]  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators of balanced dataset\n",
    "model_fws_fs_epa_smote_test = model_fws_fs_epa_smote[model_fws_fs_epa_smote['Split'] == 'Test']\n",
    "model_fws_fs_epa_smote_test.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fws.to_pickle('../Data/model_fws.pkl')\n",
    "model_fws_fs.to_pickle('../Data/model_fws_fs.pkl')\n",
    "model_fws_fs_epa.to_pickle('../Data/model_fws_fs_epa.pkl')\n",
    "model_fws_fs_epa_smote.to_pickle('../Data/model_fws_fs_epa_smote.pkl')\n",
    "pd.DataFrame(y_labels).to_pickle('../Data/y_labels.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
