{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifiers as clf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Species Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scientific Name</th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Federal Listing Status</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>Group_Crustaceans</th>\n",
       "      <th>Group_Ferns and Allies</th>\n",
       "      <th>Group_Fishes</th>\n",
       "      <th>Group_Flowering Plants</th>\n",
       "      <th>...</th>\n",
       "      <th>State_OR</th>\n",
       "      <th>State_PA</th>\n",
       "      <th>State_SC</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accipiter gentilis</td>\n",
       "      <td>Northern goshawk</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acipenser fulvescens</td>\n",
       "      <td>Lake sturgeon</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acipenser oxyrinchus (=oxyrhynchus) desotoi</td>\n",
       "      <td>Atlantic sturgeon (Gulf subspecies)</td>\n",
       "      <td>Threatened</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agarodes alabamensis</td>\n",
       "      <td>[Unnamed] caddisfly</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agrimonia incisa</td>\n",
       "      <td>Incised groovebur</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Scientific Name  \\\n",
       "0                           Accipiter gentilis   \n",
       "1                         Acipenser fulvescens   \n",
       "2  Acipenser oxyrinchus (=oxyrhynchus) desotoi   \n",
       "3                         Agarodes alabamensis   \n",
       "4                             Agrimonia incisa   \n",
       "\n",
       "                           Common Name Federal Listing Status  \\\n",
       "0                     Northern goshawk             Not Listed   \n",
       "1                        Lake sturgeon             Not Listed   \n",
       "2  Atlantic sturgeon (Gulf subspecies)             Threatened   \n",
       "3                  [Unnamed] caddisfly             Not Listed   \n",
       "4                    Incised groovebur             Not Listed   \n",
       "\n",
       "   Group_Amphibians  Group_Birds  Group_Clams  Group_Crustaceans  \\\n",
       "0                 0            1            0                  0   \n",
       "1                 0            0            0                  0   \n",
       "2                 0            0            0                  0   \n",
       "3                 0            0            0                  0   \n",
       "4                 0            0            0                  0   \n",
       "\n",
       "   Group_Ferns and Allies  Group_Fishes  Group_Flowering Plants    ...     \\\n",
       "0                       0             0                       0    ...      \n",
       "1                       0             1                       0    ...      \n",
       "2                       0             1                       0    ...      \n",
       "3                       0             0                       0    ...      \n",
       "4                       0             0                       1    ...      \n",
       "\n",
       "   State_OR  State_PA  State_SC  State_TN  State_TX  State_UT  State_VA  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   State_WA  State_WV  State_WY  \n",
       "0         0         0         0  \n",
       "1         0         0         0  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "4         0         0         0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = pd.read_pickle(\"../Data/species.pkl\")\n",
    "species.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Target and Feature Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target and feature variables\n",
    "y = species['Federal Listing Status']\n",
    "X = species.drop(['Federal Listing Status', 'Scientific Name', 'Common Name'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 9389\n",
      "Endangered:    0.16210459047821918\n",
      "Not Listed:    0.7714346575780169\n",
      "Threatened:    0.06646075194376398\n",
      "Test Data:     2348\n",
      "Endangered:    0.16056218057921637\n",
      "Not Listed:    0.7653321976149915\n",
      "Threatened:    0.07410562180579217\n"
     ]
    }
   ],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# federal listing status\n",
    "print('Training Data: ' + str(y_train.count()))\n",
    "print('Endangered:    ' + str((y_train == 'Endangered').sum() / y_train.count()))\n",
    "print('Not Listed:    ' + str((y_train == 'Not Listed').sum() / y_train.count()))\n",
    "print('Threatened:    ' + str((y_train == 'Threatened').sum() / y_train.count()))\n",
    "\n",
    "# federal listing status\n",
    "print('Test Data:     ' + str(y_test.count()))\n",
    "print('Endangered:    ' + str((y_test == 'Endangered').sum() / y_test.count()))\n",
    "print('Not Listed:    ' + str((y_test == 'Not Listed').sum() / y_test.count()))\n",
    "print('Threatened:    ' + str((y_test == 'Threatened').sum() / y_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Classification Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for all classifiers\n",
    "classifiers = []\n",
    "\n",
    "# dummy classifier\n",
    "classifiers.append({'Model': 'Dummy',\n",
    "                    'Classifier': DummyClassifier(strategy='most_frequent')})\n",
    "\n",
    "# logistic regression classifer\n",
    "classifiers.append({'Model': 'Logistic Regression',\n",
    "                    'Classifier': LogisticRegression(C=1e12,\n",
    "                                                     penalty='l1',\n",
    "                                                     multi_class='ovr',\n",
    "                                                     solver='liblinear',\n",
    "                                                     n_jobs=-1)})\n",
    "\n",
    "# k nearest neighbors classifer\n",
    "classifiers.append({'Model': 'K Nearest Neighbors',\n",
    "                    'Classifier': KNeighborsClassifier(n_neighbors=5)})\n",
    "\n",
    "# decision tree classifer\n",
    "classifiers.append({'Model': 'Decision Tree',\n",
    "                    'Classifier': DecisionTreeClassifier(criterion='gini',\n",
    "                                                         max_depth=9,\n",
    "                                                         max_features=0.9)})\n",
    "\n",
    "# random forest classifer\n",
    "classifiers.append({'Model': 'Random Forest',\n",
    "                    'Classifier': RandomForestClassifier(n_estimators=100,\n",
    "                                                         criterion='gini',\n",
    "                                                         max_depth=5,\n",
    "                                                         max_features=0.6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifiers, metrics = clf.classify(classifiers, X_train, X_test, y_train, y_test)\n",
    "\n",
    "baseline = pd.DataFrame(metrics, columns=['Model',\n",
    "                                          'Split',\n",
    "                                          'Accuracy',\n",
    "                                          'Precision',\n",
    "                                          'Recall',\n",
    "                                          'F1 Score'])\n",
    "baseline['Configuration'] = 'Baseline'\n",
    "models = baseline.copy()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.pivot(index='Model', columns='Split').drop(\n",
    "    'Configuration', axis=1).sort_values(by=('F1 Score','Train'), ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance with SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# federal listing status\n",
    "print(y_train.count())\n",
    "print('Endangered: ' + str((y_train == 'Endangered').sum() / y_train.count()))\n",
    "print('Not Listed: ' + str((y_train == 'Not Listed').sum() / y_train.count()))\n",
    "print('Threatened: ' + str((y_train == 'Threatened').sum() / y_train.count()))\n",
    "\n",
    "# plot class imbalance\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.countplot(y_train,\n",
    "              order=y_train.value_counts().index,\n",
    "              alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(y_train.unique())\n",
    "values = np.ones((3), dtype=int) * (y_train == 'Not Listed').sum()\n",
    "sample_ratio = dict(zip(keys, values))\n",
    "sample_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species['Federal Listing Status'].unique()\n",
    "\n",
    "smote = SMOTE(ratio=sample_ratio)\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "# federal listing status\n",
    "print(len(y_train_smote))\n",
    "print('Endangered: ' + str((y_train_smote == 'Endangered').sum() / len(y_train_smote)))\n",
    "print('Not Listed: ' + str((y_train_smote == 'Not Listed').sum() / len(y_train_smote)))\n",
    "print('Threatened: ' + str((y_train_smote == 'Threatened').sum() / len(y_train_smote)))\n",
    "\n",
    "# plot class imbalance\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.countplot(y_train_smote,\n",
    "              order=y_train.value_counts().index,\n",
    "              alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers, metrics = clf.classify(classifiers, X_train_smote, X_test, y_train_smote, y_test)\n",
    "\n",
    "balanced = pd.DataFrame(metrics, columns=['Model',\n",
    "                                          'Split',\n",
    "                                          'Accuracy',\n",
    "                                          'Precision',\n",
    "                                          'Recall',\n",
    "                                          'F1 Score'])\n",
    "\n",
    "balanced['Configuration'] = 'Balanced'\n",
    "models = models.append(balanced, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "balanced.pivot(index='Model', columns='Split').drop(\n",
    "    'Configuration', axis=1).sort_values(by=('F1 Score','Train'), ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned and Balanced Grid Search Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for all grid searches\n",
    "grid_searches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression parameters\n",
    "parameters_log = dict(penalty=['l1', 'l2'],\n",
    "                      C=[1e-2, 1e0, 1e2, 1e6, 1e12],\n",
    "                      fit_intercept=[True, False],\n",
    "                      multi_class=['ovr'],\n",
    "                      solver=['liblinear'])\n",
    "\n",
    "grid_searches.append({'Model': 'Logistic Regression',\n",
    "                    'Classifier': GridSearchCV(LogisticRegression(),\n",
    "                                               parameters_log,\n",
    "                                               cv=5,\n",
    "                                               scoring='f1_weighted',\n",
    "                                               verbose=10,\n",
    "                                               n_jobs=-1)})\n",
    "\n",
    "# k nearest neighbors parameters\n",
    "parameters_knn = dict(n_neighbors=[5,11],\n",
    "                      weights=['uniform', 'distance'],\n",
    "                      algorithm=['ball_tree','kd_tree'],\n",
    "                      leaf_size=[100,200])\n",
    "\n",
    "grid_searches.append({'Model': 'K Nearest Neighbors',\n",
    "                    'Classifier': GridSearchCV(KNeighborsClassifier(),\n",
    "                                               parameters_knn,\n",
    "                                               cv=5,\n",
    "                                               scoring='f1_weighted',\n",
    "                                               verbose=10,\n",
    "                                               n_jobs=-1)})\n",
    "\n",
    "# decision tree parameters\n",
    "parameters_tree = dict(criterion=['gini','entropy'],\n",
    "                       max_depth=[6,8],\n",
    "                       min_samples_leaf=[20,50,100],\n",
    "                       max_features=[20,30,40],\n",
    "                       min_impurity_decrease=[0.01,0.03,0.05])\n",
    "\n",
    "grid_searches.append({'Model': 'Decision Tree',\n",
    "                    'Classifier': GridSearchCV(DecisionTreeClassifier(),\n",
    "                                               parameters_tree,\n",
    "                                               cv=5,\n",
    "                                               scoring='f1_weighted',\n",
    "                                               verbose=10,\n",
    "                                               n_jobs=-1)})\n",
    "\n",
    "# random forest parameters\n",
    "parameters_forest = dict(n_estimators=[100,200,300],\n",
    "                         max_depth=[2,3,4],\n",
    "                         min_samples_leaf=[100,200],\n",
    "                         max_features=[10,20],\n",
    "                         min_impurity_decrease=[0.01,0.03,0.05])\n",
    "\n",
    "grid_searches.append({'Model': 'Random Forest',\n",
    "                    'Classifier': GridSearchCV(RandomForestClassifier(),\n",
    "                                               parameters_forest,\n",
    "                                               cv=5,\n",
    "                                               scoring='f1_weighted',\n",
    "                                               verbose=10,\n",
    "                                               n_jobs=-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_searches, metrics = clf.grid_search(grid_searches, X_train_smote, X_test, y_train_smote, y_test, X.columns)\n",
    "\n",
    "tuned = pd.DataFrame(metrics, columns=['Model',\n",
    "                                       'Split',\n",
    "                                       'Accuracy',\n",
    "                                       'Precision',\n",
    "                                       'Recall',\n",
    "                                       'F1 Score'])\n",
    "\n",
    "tuned['Configuration'] = 'Balanced and Tuned'\n",
    "models = models.append(tuned, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned.pivot(index='Model', columns='Split').drop(\n",
    "    'Configuration', axis=1).sort_values(by=('F1 Score','Train'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced.pivot(index='Model', columns='Split').drop(\n",
    "    'Configuration', axis=1).sort_values(by=('F1 Score','Train'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.pivot(index='Model', columns='Split').drop(\n",
    "    'Configuration', axis=1).sort_values(by=('F1 Score','Train'), ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.to_pickle(\"../Data/models.pkl\")\n",
    "baseline.to_pickle(\"../Data/baseline.pkl\")\n",
    "balanced.to_pickle(\"../Data/balanced.pkl\")\n",
    "tuned.to_pickle(\"../Data/tuned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grid_searches, open( \"../Data/grid_searches.pkl\", \"wb\" ))\n",
    "pickle.dump(metrics, open( \"../Data/metrics.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
