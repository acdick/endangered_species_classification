{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifiers as clf\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling  import SMOTE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Species Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scientific Name</th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Federal Listing Status</th>\n",
       "      <th>Group_Amphibians</th>\n",
       "      <th>Group_Annelid Worms</th>\n",
       "      <th>Group_Arachnids</th>\n",
       "      <th>Group_Birds</th>\n",
       "      <th>Group_Clams</th>\n",
       "      <th>Group_Conifers and Cycads</th>\n",
       "      <th>Group_Corals</th>\n",
       "      <th>...</th>\n",
       "      <th>State_SD</th>\n",
       "      <th>State_TN</th>\n",
       "      <th>State_TX</th>\n",
       "      <th>State_UT</th>\n",
       "      <th>State_VA</th>\n",
       "      <th>State_VT</th>\n",
       "      <th>State_WA</th>\n",
       "      <th>State_WI</th>\n",
       "      <th>State_WV</th>\n",
       "      <th>State_WY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accipiter gentilis</td>\n",
       "      <td>Northern goshawk</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acipenser fulvescens</td>\n",
       "      <td>Lake sturgeon</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acipenser oxyrinchus (=oxyrhynchus) desotoi</td>\n",
       "      <td>Atlantic sturgeon (Gulf subspecies)</td>\n",
       "      <td>Threatened</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agarodes alabamensis</td>\n",
       "      <td>[Unnamed] caddisfly</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agrimonia incisa</td>\n",
       "      <td>Incised groovebur</td>\n",
       "      <td>Not Listed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Scientific Name  \\\n",
       "0                           Accipiter gentilis   \n",
       "1                         Acipenser fulvescens   \n",
       "2  Acipenser oxyrinchus (=oxyrhynchus) desotoi   \n",
       "3                         Agarodes alabamensis   \n",
       "4                             Agrimonia incisa   \n",
       "\n",
       "                           Common Name Federal Listing Status  \\\n",
       "0                     Northern goshawk             Not Listed   \n",
       "1                        Lake sturgeon             Not Listed   \n",
       "2  Atlantic sturgeon (Gulf subspecies)             Threatened   \n",
       "3                  [Unnamed] caddisfly             Not Listed   \n",
       "4                    Incised groovebur             Not Listed   \n",
       "\n",
       "   Group_Amphibians  Group_Annelid Worms  Group_Arachnids  Group_Birds  \\\n",
       "0                 0                    0                0            1   \n",
       "1                 0                    0                0            0   \n",
       "2                 0                    0                0            0   \n",
       "3                 0                    0                0            0   \n",
       "4                 0                    0                0            0   \n",
       "\n",
       "   Group_Clams  Group_Conifers and Cycads  Group_Corals    ...     State_SD  \\\n",
       "0            0                          0             0    ...            0   \n",
       "1            0                          0             0    ...            0   \n",
       "2            0                          0             0    ...            0   \n",
       "3            0                          0             0    ...            0   \n",
       "4            0                          0             0    ...            0   \n",
       "\n",
       "   State_TN  State_TX  State_UT  State_VA  State_VT  State_WA  State_WI  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   State_WV  State_WY  \n",
       "0         0         0  \n",
       "1         0         0  \n",
       "2         0         0  \n",
       "3         0         0  \n",
       "4         0         0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = pd.read_pickle(\"../Data/species.pkl\")\n",
    "species.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Target and Feature Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variables\n",
    "y = species['Federal Listing Status']\n",
    "y_labels = list(y.unique())\n",
    "\n",
    "# Create target variables\n",
    "X = species.drop(['Federal Listing Status', 'Scientific Name', 'Common Name'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train Normal</th>\n",
       "      <th>Test Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not Listed</th>\n",
       "      <td>7242</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.771328</td>\n",
       "      <td>0.765758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Endangered</th>\n",
       "      <td>1518</td>\n",
       "      <td>381</td>\n",
       "      <td>0.161679</td>\n",
       "      <td>0.162266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threatened</th>\n",
       "      <td>629</td>\n",
       "      <td>169</td>\n",
       "      <td>0.066993</td>\n",
       "      <td>0.071976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>9389</td>\n",
       "      <td>2348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Train  Test  Train Normal  Test Normal\n",
       "Not Listed   7242  1798      0.771328     0.765758\n",
       "Endangered   1518   381      0.161679     0.162266\n",
       "Threatened    629   169      0.066993     0.071976\n",
       "Total        9389  2348      1.000000     1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# data set statistics\n",
    "data_sets = pd.DataFrame({'Train':        y_train.value_counts(),\n",
    "                          'Test':         y_test.value_counts(),\n",
    "                          'Train Normal': y_train.value_counts() / y_train.count(),\n",
    "                          'Test Normal':  y_test.value_counts()  / y_test.count()})\n",
    "\n",
    "data_sets.loc['Total'] = data_sets.sum().astype(int)\n",
    "data_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Classification Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scoring metrics for all classifiers\n",
    "scoring = ['accuracy', 'f1_weighted']\n",
    "\n",
    "# define parameter grid search for all classifiers\n",
    "classifiers = []\n",
    "\n",
    "classifiers.append(clf.grid_search_dummy_classifier(dict(\n",
    "                          strategy=['most_frequent','stratified']), scoring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Baseline Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_f1_weighted</th>\n",
       "      <th>Model</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'strategy': 'most_frequent'}</td>\n",
       "      <td>0.771328</td>\n",
       "      <td>0.671753</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'strategy': 'stratified'}</td>\n",
       "      <td>0.633188</td>\n",
       "      <td>0.632351</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          params  mean_test_accuracy  mean_test_f1_weighted  \\\n",
       "0  {'strategy': 'most_frequent'}            0.771328               0.671753   \n",
       "1     {'strategy': 'stratified'}            0.633188               0.632351   \n",
       "\n",
       "      Model Classifier  Split  \n",
       "0  Baseline      Dummy  Train  \n",
       "1  Baseline      Dummy  Train  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run baseline dataset\n",
    "baseline = clf.fit_predict_measure('Baseline', X_train, X_test, y_train, y_test, y_labels, classifiers)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.pivot(index='Model', columns='Split').drop(\n",
    "    'Configuration', axis=1).sort_values(by=('F1 Score','Train'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train, classifiers[0]['y_hat_train'], labels=list(y.unique()))\n",
    "cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "sns.heatmap(cm,\n",
    "            cmap='Blues',cbar=False,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            linewidths=.5,\n",
    "            xticklabels=list(y.unique()),\n",
    "            yticklabels=list(y.unique()),square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for all classifiers\n",
    "classifiers = []\n",
    "\n",
    "# dummy classifier\n",
    "classifiers.append({'Model': 'Dummy',\n",
    "                    'Classifier': DummyClassifier(strategy='most_frequent')})\n",
    "\n",
    "# logistic regression classifer\n",
    "classifiers.append({'Model': 'Logistic Regression',\n",
    "                    'Classifier': LogisticRegression(C=1e12,\n",
    "                                                     penalty='l1',\n",
    "                                                     multi_class='ovr',\n",
    "                                                     solver='liblinear',\n",
    "                                                     n_jobs=-1)})\n",
    "\n",
    "# k nearest neighbors classifer\n",
    "classifiers.append({'Model': 'K Nearest Neighbors',\n",
    "                    'Classifier': KNeighborsClassifier(n_neighbors=5)})\n",
    "\n",
    "# decision tree classifer\n",
    "classifiers.append({'Model': 'Decision Tree',\n",
    "                    'Classifier': DecisionTreeClassifier(criterion='gini',\n",
    "                                                         max_depth=9,\n",
    "                                                         max_features=0.9)})\n",
    "\n",
    "# random forest classifer\n",
    "classifiers.append({'Model': 'Random Forest',\n",
    "                    'Classifier': RandomForestClassifier(n_estimators=100,\n",
    "                                                         criterion='gini',\n",
    "                                                         max_depth=5,\n",
    "                                                         max_features=0.6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifiers, metrics = clf.classify(classifiers, X_train, X_test, y_train, y_test)\n",
    "\n",
    "baseline = pd.DataFrame(metrics, columns=['Model',\n",
    "                                          'Split',\n",
    "                                          'Accuracy',\n",
    "                                          'Precision',\n",
    "                                          'Recall',\n",
    "                                          'F1 Score'])\n",
    "baseline['Configuration'] = 'Baseline'\n",
    "models = baseline.copy()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.pivot(index='Model', columns='Split').drop(\n",
    "    'Configuration', axis=1).sort_values(by=('F1 Score','Train'), ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance with SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# federal listing status\n",
    "print(y_train.count())\n",
    "print('Endangered: ' + str((y_train == 'Endangered').sum() / y_train.count()))\n",
    "print('Not Listed: ' + str((y_train == 'Not Listed').sum() / y_train.count()))\n",
    "print('Threatened: ' + str((y_train == 'Threatened').sum() / y_train.count()))\n",
    "\n",
    "# plot class imbalance\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.countplot(y_train,\n",
    "              order=y_train.value_counts().index,\n",
    "              alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(y_train.unique())\n",
    "values = np.ones((3), dtype=int) * (y_train == 'Not Listed').sum()\n",
    "sample_ratio = dict(zip(keys, values))\n",
    "sample_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species['Federal Listing Status'].unique()\n",
    "\n",
    "smote = SMOTE(ratio=sample_ratio)\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "# federal listing status\n",
    "print(len(y_train_smote))\n",
    "print('Endangered: ' + str((y_train_smote == 'Endangered').sum() / len(y_train_smote)))\n",
    "print('Not Listed: ' + str((y_train_smote == 'Not Listed').sum() / len(y_train_smote)))\n",
    "print('Threatened: ' + str((y_train_smote == 'Threatened').sum() / len(y_train_smote)))\n",
    "\n",
    "# plot class imbalance\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.countplot(y_train_smote,\n",
    "              order=y_train.value_counts().index,\n",
    "              alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers, metrics = clf.classify(classifiers, X_train_smote, X_test, y_train_smote, y_test)\n",
    "\n",
    "balanced = pd.DataFrame(metrics, columns=['Model',\n",
    "                                          'Split',\n",
    "                                          'Accuracy',\n",
    "                                          'Precision',\n",
    "                                          'Recall',\n",
    "                                          'F1 Score'])\n",
    "\n",
    "balanced['Configuration'] = 'Balanced'\n",
    "models = models.append(balanced, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "balanced.pivot(index='Model', columns='Split').drop(\n",
    "    'Configuration', axis=1).sort_values(by=('F1 Score','Train'), ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned and Balanced Grid Search Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for all grid searches\n",
    "grid_searches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression parameters\n",
    "parameters_log = dict(penalty=['l1', 'l2'],\n",
    "                      C=[1e-2, 1e0, 1e2, 1e6, 1e12],\n",
    "                      fit_intercept=[True, False],\n",
    "                      multi_class=['ovr'],\n",
    "                      solver=['liblinear'])\n",
    "\n",
    "grid_searches.append({'Model': 'Logistic Regression',\n",
    "                    'Classifier': GridSearchCV(LogisticRegression(),\n",
    "                                               parameters_log,\n",
    "                                               cv=5,\n",
    "                                               scoring='f1_weighted',\n",
    "                                               verbose=10,\n",
    "                                               n_jobs=-1)})\n",
    "\n",
    "# k nearest neighbors parameters\n",
    "parameters_knn = dict(n_neighbors=[5,11],\n",
    "                      weights=['uniform', 'distance'],\n",
    "                      algorithm=['ball_tree','kd_tree'],\n",
    "                      leaf_size=[100,200])\n",
    "\n",
    "grid_searches.append({'Model': 'K Nearest Neighbors',\n",
    "                    'Classifier': GridSearchCV(KNeighborsClassifier(),\n",
    "                                               parameters_knn,\n",
    "                                               cv=5,\n",
    "                                               scoring='f1_weighted',\n",
    "                                               verbose=10,\n",
    "                                               n_jobs=-1)})\n",
    "\n",
    "# decision tree parameters\n",
    "parameters_tree = dict(criterion=['gini','entropy'],\n",
    "                       max_depth=[6,8],\n",
    "                       min_samples_leaf=[20,50,100],\n",
    "                       max_features=[20,30,40],\n",
    "                       min_impurity_decrease=[0.01,0.03,0.05])\n",
    "\n",
    "grid_searches.append({'Model': 'Decision Tree',\n",
    "                    'Classifier': GridSearchCV(DecisionTreeClassifier(),\n",
    "                                               parameters_tree,\n",
    "                                               cv=5,\n",
    "                                               scoring='f1_weighted',\n",
    "                                               verbose=10,\n",
    "                                               n_jobs=-1)})\n",
    "\n",
    "# random forest parameters\n",
    "parameters_forest = dict(n_estimators=[100,200,300],\n",
    "                         max_depth=[2,3,4],\n",
    "                         min_samples_leaf=[100,200],\n",
    "                         max_features=[10,20],\n",
    "                         min_impurity_decrease=[0.01,0.03,0.05])\n",
    "\n",
    "grid_searches.append({'Model': 'Random Forest',\n",
    "                    'Classifier': GridSearchCV(RandomForestClassifier(),\n",
    "                                               parameters_forest,\n",
    "                                               cv=5,\n",
    "                                               scoring='f1_weighted',\n",
    "                                               verbose=10,\n",
    "                                               n_jobs=-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_searches, metrics = clf.grid_search(grid_searches, X_train_smote, X_test, y_train_smote, y_test, X.columns)\n",
    "\n",
    "tuned = pd.DataFrame(metrics, columns=['Model',\n",
    "                                       'Split',\n",
    "                                       'Accuracy',\n",
    "                                       'Precision',\n",
    "                                       'Recall',\n",
    "                                       'F1 Score'])\n",
    "\n",
    "tuned['Configuration'] = 'Balanced and Tuned'\n",
    "models = models.append(tuned, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned.pivot(index='Model', columns='Split').drop(\n",
    "    'Configuration', axis=1).sort_values(by=('F1 Score','Train'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced.pivot(index='Model', columns='Split').drop(\n",
    "    'Configuration', axis=1).sort_values(by=('F1 Score','Train'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.pivot(index='Model', columns='Split').drop(\n",
    "    'Configuration', axis=1).sort_values(by=('F1 Score','Train'), ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.to_pickle(\"../Data/models.pkl\")\n",
    "baseline.to_pickle(\"../Data/baseline.pkl\")\n",
    "balanced.to_pickle(\"../Data/balanced.pkl\")\n",
    "tuned.to_pickle(\"../Data/tuned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grid_searches, open( \"../Data/grid_searches.pkl\", \"wb\" ))\n",
    "pickle.dump(metrics, open( \"../Data/metrics.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
